{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "- 2-layer Recurrent Neural Network\n",
    "  - Vanilla RNN\n",
    "  - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training/Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_train_test.emo_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "# unzip dataset folder\n",
    "# dataset = zipfile.ZipFile(\"data_train_test.zip\")\n",
    "# dataset.extractall()\n",
    "# glove = zipfile.ZipFile(\"glove.6B.zip\")\n",
    "# glove.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set glove file\n",
    "glove_file_50 = \"glove.6B.50d.txt\"\n",
    "words_to_index_50, index_to_words_50, word_to_vec_map_50 = read_glove_vecs(glove_file_50)\n",
    "\n",
    "glove_file_100 = \"glove.6B.100d.txt\"\n",
    "words_to_index_100, index_to_words_100, word_to_vec_map_100 = read_glove_vecs(glove_file_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Train X data=============\n",
      "['never talk to me again' 'I am proud of your achievements'\n",
      " 'It is the worst day in my life' 'Miss you so much' 'food is life'\n",
      " 'I love you mum' 'Stop saying bullshit'\n",
      " 'congratulations on your acceptance' 'The assignment is too long '\n",
      " 'I want to go play']\n",
      "train X data's shape: (132,)\n",
      "=============Train Y data=============\n",
      "[3 2 3 0 4 0 3 2 3 1]\n",
      "train Y data's shape: (132,)\n",
      "=============Test X data=============\n",
      "['I want to eat\\t' 'he did not answer\\t' 'he got a very nice raise\\t'\n",
      " 'she got me a nice present\\t' 'ha ha ha it was so funny\\t'\n",
      " 'he is a good friend\\t' 'I am upset\\t'\n",
      " 'We had such a lovely dinner tonight\\t' 'where is the food\\t'\n",
      " 'Stop making this joke ha ha ha\\t']\n",
      "test X data's shape: (56,)\n",
      "=============Test Y data=============\n",
      "[4 3 2 2 2 2 3 2 4 2]\n",
      "test Y data's shape: (56,)\n"
     ]
    }
   ],
   "source": [
    "# set train test data\n",
    "train_dataset = \"./data_train_test/train_emoji.csv\"\n",
    "test_dataset = \"./data_train_test/test_emoji.csv\"\n",
    "\n",
    "train_x, train_y = read_csv(train_dataset)\n",
    "test_x, test_y = read_csv(test_dataset)\n",
    "\n",
    "print(\"=============Train X data=============\")\n",
    "print(train_x[:10])\n",
    "print(\"train X data's shape: {}\".format(train_x.shape))\n",
    "print(\"=============Train Y data=============\")\n",
    "print(train_y[:10])\n",
    "print(\"train Y data's shape: {}\".format(train_y.shape))\n",
    "\n",
    "print(\"=============Test X data=============\")\n",
    "print(test_x[:10])\n",
    "print(\"test X data's shape: {}\".format(test_x.shape))\n",
    "print(\"=============Test Y data=============\")\n",
    "print(test_y[:10])\n",
    "print(\"test Y data's shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Train X data Embedding=============\n",
      "['never', 'talk', 'to', 'me', 'again']\n",
      "[array([[ 0.095387 , -0.16865  , -0.11514  , -0.51114  ,  0.38331  ,\n",
      "         0.22658  , -0.78504  ,  0.67626  , -0.66857  ,  0.18847  ,\n",
      "         0.19963  ,  0.58351  , -0.86134  , -0.39472  ,  1.1571   ,\n",
      "         0.51657  ,  0.11706  ,  0.0062629, -0.2593   , -0.33371  ,\n",
      "        -0.47957  ,  0.6211   ,  0.66831  , -0.058046 ,  0.81305  ,\n",
      "        -2.341    , -0.75437  ,  0.2167   ,  0.78012  , -0.81362  ,\n",
      "         2.9368   ,  0.13466  , -0.38043  , -0.59615  , -0.093113 ,\n",
      "        -0.2843   ,  0.28314  ,  0.59791  , -0.20751  , -0.43841  ,\n",
      "        -0.34187  , -0.21166  , -0.082453 ,  0.44007  , -0.3365   ,\n",
      "        -0.091078 , -0.45859  , -0.42103  , -0.53817  ,  0.13738  ]]), array([[-0.034604,  0.41087 , -0.097368, -0.19548 , -0.05855 , -0.2581  ,\n",
      "        -0.85141 ,  0.19582 , -0.76829 ,  0.37035 , -0.63907 ,  0.30593 ,\n",
      "        -0.38117 ,  0.40505 ,  0.90915 ,  0.54359 , -0.088861,  0.17422 ,\n",
      "         0.33587 , -0.36806 ,  0.32399 ,  1.056   ,  0.68695 ,  0.81261 ,\n",
      "         0.74166 , -1.7618  , -0.085259,  0.34565 ,  0.55371 , -0.24026 ,\n",
      "         2.8321  ,  0.80733 , -0.59279 , -0.52127 , -0.60045 , -0.39173 ,\n",
      "        -0.27123 , -0.52009 , -0.4718  , -0.46781 , -0.046203,  0.39371 ,\n",
      "        -0.78866 ,  0.43174 ,  0.52053 ,  0.028046, -0.013935,  0.56204 ,\n",
      "        -0.5977  ,  0.95068 ]]), array([[ 0.68047 , -0.039263,  0.30186 , -0.17792 ,  0.42962 ,  0.032246,\n",
      "        -0.41376 ,  0.13228 , -0.29847 , -0.085253,  0.17118 ,  0.22419 ,\n",
      "        -0.10046 , -0.43653 ,  0.33418 ,  0.67846 ,  0.057204, -0.34448 ,\n",
      "        -0.42785 , -0.43275 ,  0.55963 ,  0.10032 ,  0.18677 , -0.26854 ,\n",
      "         0.037334, -2.0932  ,  0.22171 , -0.39868 ,  0.20912 , -0.55725 ,\n",
      "         3.8826  ,  0.47466 , -0.95658 , -0.37788 ,  0.20869 , -0.32752 ,\n",
      "         0.12751 ,  0.088359,  0.16351 , -0.21634 , -0.094375,  0.018324,\n",
      "         0.21048 , -0.03088 , -0.19722 ,  0.082279, -0.09434 , -0.073297,\n",
      "        -0.064699, -0.26044 ]]), array([[-0.14525 ,  0.31265 ,  0.15184 , -0.63708 ,  0.63553 , -0.50295 ,\n",
      "        -0.23214 ,  0.52892 , -0.58629 ,  0.53935 , -0.3055  ,  1.0357  ,\n",
      "        -0.77989 , -0.19387 ,  1.2215  ,  0.24521 ,  0.26144 ,  0.22439 ,\n",
      "         0.15584 , -0.79146 , -0.65262 ,  1.3211  ,  0.76618 ,  0.38234 ,\n",
      "         1.4453  , -2.2643  , -1.1505  ,  0.50373 ,  1.2651  , -1.5903  ,\n",
      "         3.0518  ,  0.84118 , -0.69543 ,  0.29985 , -0.49151 , -0.22312 ,\n",
      "         0.59528 , -0.076347,  0.52358 , -0.50134 ,  0.22483 ,  0.01546 ,\n",
      "        -0.088005,  0.21282 ,  0.28545 , -0.15976 , -0.16777 , -0.50895 ,\n",
      "         0.14322 ,  1.0118  ]]), array([[-0.11008 , -0.42842 ,  0.023023, -0.66241 , -0.011844, -0.21112 ,\n",
      "        -0.77791 ,  0.82479 , -0.70825 , -0.22962 ,  0.14064 ,  0.30398 ,\n",
      "        -1.1173  , -0.18641 ,  0.82667 ,  0.44993 , -0.11678 , -0.47856 ,\n",
      "        -0.94898 , -0.14977 ,  0.19157 ,  0.10528 ,  0.66893 ,  0.02207 ,\n",
      "         0.52699 , -1.9035  ,  0.18775 ,  0.26756 ,  0.48347 , -0.28322 ,\n",
      "         3.1586  ,  0.44772 , -0.34549 , -0.31892 , -0.16631 , -0.22289 ,\n",
      "         0.26832 ,  0.4367  , -0.20443 , -0.61761 , -0.41918 , -0.22599 ,\n",
      "        -0.47885 , -0.40102 , -0.37106 ,  0.24178 ,  0.1351  , -0.81978 ,\n",
      "        -0.041543, -0.30139 ]])]\n",
      "=============Test X data Embedding=============\n",
      "['I', 'want', 'to', 'eat']\n",
      "[array([[ 1.1891e-01,  1.5255e-01, -8.2073e-02, -7.4144e-01,  7.5917e-01,\n",
      "        -4.8328e-01, -3.1009e-01,  5.1476e-01, -9.8708e-01,  6.1757e-04,\n",
      "        -1.5043e-01,  8.3770e-01, -1.0797e+00, -5.1460e-01,  1.3188e+00,\n",
      "         6.2007e-01,  1.3779e-01,  4.7108e-01, -7.2874e-02, -7.2675e-01,\n",
      "        -7.4116e-01,  7.5263e-01,  8.8180e-01,  2.9561e-01,  1.3548e+00,\n",
      "        -2.5701e+00, -1.3523e+00,  4.5880e-01,  1.0068e+00, -1.1856e+00,\n",
      "         3.4737e+00,  7.7898e-01, -7.2929e-01,  2.5102e-01, -2.6156e-01,\n",
      "        -3.4684e-01,  5.5841e-01,  7.5098e-01,  4.9830e-01, -2.6823e-01,\n",
      "        -2.7443e-03, -1.8298e-02, -2.8096e-01,  5.5318e-01,  3.7706e-02,\n",
      "         1.8555e-01, -1.5025e-01, -5.7512e-01, -2.6671e-01,  9.2121e-01]]), array([[ 0.13627 , -0.054478,  0.3703  , -0.41574 ,  0.60568 , -0.42729 ,\n",
      "        -0.50151 ,  0.35923 , -0.49154 ,  0.21827 , -0.15193 ,  0.52536 ,\n",
      "        -0.24206 ,  0.023875,  0.8225  ,  1.089   ,  0.98825 , -0.17803 ,\n",
      "         0.77806 , -1.0647  , -0.28742 ,  0.50458 ,  0.21612 ,  0.65681 ,\n",
      "         0.34295 , -2.1084  , -0.82557 , -0.31966 ,  0.87567 , -1.0679  ,\n",
      "         3.3802  ,  1.2084  , -1.272   , -0.15921 , -0.25237 , -0.2696  ,\n",
      "        -0.18756 , -0.35523 ,  0.084172, -0.56539 , -0.24081 ,  0.15926 ,\n",
      "         0.3287  ,  0.54591 ,  0.29897 ,  0.18948 , -0.57113 ,  0.17399 ,\n",
      "        -0.19338 ,  0.51921 ]]), array([[ 0.68047 , -0.039263,  0.30186 , -0.17792 ,  0.42962 ,  0.032246,\n",
      "        -0.41376 ,  0.13228 , -0.29847 , -0.085253,  0.17118 ,  0.22419 ,\n",
      "        -0.10046 , -0.43653 ,  0.33418 ,  0.67846 ,  0.057204, -0.34448 ,\n",
      "        -0.42785 , -0.43275 ,  0.55963 ,  0.10032 ,  0.18677 , -0.26854 ,\n",
      "         0.037334, -2.0932  ,  0.22171 , -0.39868 ,  0.20912 , -0.55725 ,\n",
      "         3.8826  ,  0.47466 , -0.95658 , -0.37788 ,  0.20869 , -0.32752 ,\n",
      "         0.12751 ,  0.088359,  0.16351 , -0.21634 , -0.094375,  0.018324,\n",
      "         0.21048 , -0.03088 , -0.19722 ,  0.082279, -0.09434 , -0.073297,\n",
      "        -0.064699, -0.26044 ]]), array([[ 6.4295e-01, -4.2946e-01, -5.4277e-01, -1.0307e+00,  1.2056e+00,\n",
      "        -2.7174e-01, -6.3561e-01, -1.5065e-02,  3.7856e-01,  4.6474e-02,\n",
      "        -1.3102e-01,  6.0500e-01,  1.6391e+00,  2.3940e-01,  1.2128e+00,\n",
      "         8.3178e-01,  7.3893e-01,  1.5200e-01, -1.4175e-01, -8.8384e-01,\n",
      "         2.0829e-02, -3.2545e-01,  1.8035e+00,  1.0045e+00,  5.8484e-01,\n",
      "        -6.2031e-01, -4.3296e-01,  2.3562e-01,  1.3027e+00, -8.1264e-01,\n",
      "         2.3158e+00,  1.1030e+00, -6.0608e-01,  1.0101e+00, -2.2426e-01,\n",
      "         1.8908e-02, -1.0931e-01,  3.8350e-01,  7.7362e-01, -8.1927e-02,\n",
      "        -3.4040e-01, -1.5143e-03, -5.6640e-02,  8.7359e-01,  1.4805e+00,\n",
      "         6.9421e-01, -3.0966e-01, -9.0826e-01,  3.7277e-03,  8.4550e-01]])]\n"
     ]
    }
   ],
   "source": [
    "train_x_length = len(train_x)\n",
    "test_x_length = len(test_x)\n",
    "\n",
    "train_x_emb_50 = [[] for _ in range(train_x_length)]\n",
    "test_x_emb_50 = [[] for _ in range(test_x_length)]\n",
    "\n",
    "for i in range(train_x_length):\n",
    "    token = train_x[i].split()\n",
    "    for j in range(len(token)):\n",
    "        train_x_emb_50[i].append(word_to_vec_map_50[token[j].lower()].reshape(1, -1))\n",
    "    if i == 0:\n",
    "        print(\"=============Train X data Embedding=============\")\n",
    "        print(token)\n",
    "        print(train_x_emb_50[i])\n",
    "        \n",
    "for i in range(test_x_length):\n",
    "    token = test_x[i].split()\n",
    "    for j in range(len(token)):\n",
    "        test_x_emb_50[i].append(word_to_vec_map_50[token[j].lower()].reshape(1, -1))\n",
    "    if i == 0:\n",
    "        print(\"=============Test X data Embedding=============\")\n",
    "        print(token)\n",
    "        print(test_x_emb_50[i])\n",
    "    \n",
    "        \n",
    "train_x_emb_50 = np.array(train_x_emb_50)\n",
    "test_x_emb_50 = np.array(test_x_emb_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Train X data Embedding=============\n",
      "['never', 'talk', 'to', 'me', 'again']\n",
      "[array([[ 0.28308  ,  0.3328   ,  0.50003  , -0.2043   , -0.34403  ,\n",
      "         0.10466  ,  0.25852  ,  0.11798  ,  0.50594  , -0.22371  ,\n",
      "         0.52499  ,  0.59336  ,  0.52034  ,  0.38505  , -0.094194 ,\n",
      "        -0.27289  ,  0.3719   ,  0.71022  , -0.78723  ,  0.142    ,\n",
      "         0.23843  ,  0.17683  , -0.13     , -0.51327  ,  0.13746  ,\n",
      "         0.092858 , -0.47914  , -1.0342   ,  0.51481  , -0.4158   ,\n",
      "         0.17622  ,  1.0603   ,  0.038309 ,  0.47409  ,  0.34532  ,\n",
      "         0.10244  , -0.10949  ,  0.031997 , -0.03563  , -0.073314 ,\n",
      "        -0.61494  , -0.0056377,  0.40174  , -0.47975  , -0.053224 ,\n",
      "        -0.23983  ,  0.64644  , -0.48115  ,  0.73126  , -1.4097   ,\n",
      "         0.15377  , -0.093436 ,  0.42553  ,  1.0389   ,  0.35117  ,\n",
      "        -2.2379   , -0.2496   ,  0.24372  ,  0.92944  ,  0.87231  ,\n",
      "         0.24636  ,  0.85973  , -0.72904  , -0.30587  ,  1.1191   ,\n",
      "        -0.16524  ,  0.65312  ,  0.22118  , -0.53921  , -0.034287 ,\n",
      "         0.39948  , -0.34075  ,  0.048538 , -0.023853 , -0.076588 ,\n",
      "         0.06669  , -0.16751  , -0.2614   , -0.8065   ,  0.36449  ,\n",
      "         0.18566  , -0.03655  , -0.56927  , -0.093071 , -2.0503   ,\n",
      "        -0.50041  , -0.0049648, -0.33624  , -0.17233  , -0.19766  ,\n",
      "        -0.35015  , -0.63284  ,  0.12563  ,  0.022786 , -0.56203  ,\n",
      "         0.21945  , -0.4995   ,  0.031549 , -0.22464  ,  0.48508  ]]), array([[-7.9761e-02,  1.9551e-01,  3.0579e-01, -2.1571e-01, -4.9017e-01,\n",
      "         4.6350e-01, -1.5171e-01, -1.6002e-01,  1.3081e-01, -6.5718e-01,\n",
      "        -1.1343e-01,  1.0231e-01,  1.1583e-01,  2.0241e-03,  1.8107e-01,\n",
      "        -1.8263e-01, -4.2386e-01,  5.6726e-02, -3.0419e-01,  1.5828e-01,\n",
      "        -1.1820e-01,  1.8624e-01, -5.2731e-01, -5.9154e-01,  7.1546e-02,\n",
      "         1.9633e-01, -4.9147e-02, -3.3004e-01,  5.0489e-01,  5.1138e-01,\n",
      "        -5.0726e-01,  7.9255e-01,  1.7890e-01,  3.5001e-01, -7.2015e-02,\n",
      "         8.9293e-01, -2.7286e-01, -5.7761e-01,  1.8615e-01, -9.8489e-02,\n",
      "        -6.1398e-01,  6.1104e-02, -3.3847e-01, -2.9190e-01, -7.1794e-01,\n",
      "        -3.7329e-01, -3.2193e-01, -3.8184e-01,  4.9009e-02, -1.2856e+00,\n",
      "         3.1266e-02,  1.2953e-01,  1.1391e-01,  6.9458e-01,  3.3839e-01,\n",
      "        -2.1965e+00,  8.4632e-02,  7.6947e-02,  9.7508e-01,  3.2743e-01,\n",
      "         2.8664e-01,  7.9778e-01, -4.9729e-01, -1.1200e+00,  9.1580e-01,\n",
      "         8.9064e-02,  1.1378e+00,  3.3187e-01, -1.8245e-01,  1.7541e-01,\n",
      "         9.8961e-02, -3.9566e-01, -4.1590e-01, -7.4777e-01, -4.6913e-01,\n",
      "         3.8674e-01,  2.7161e-01, -1.5303e-02, -5.2653e-01, -2.0984e-01,\n",
      "         1.2046e-01, -4.0667e-01,  2.9756e-01, -1.3695e-01, -1.3846e+00,\n",
      "        -1.4904e-01, -4.8938e-01,  7.5170e-01, -2.2143e-01, -5.2081e-01,\n",
      "         2.6477e-01,  2.7790e-01, -4.1847e-01, -2.1104e-01, -7.4714e-01,\n",
      "        -6.5609e-02, -2.6370e-01,  2.0017e-01,  8.7429e-01,  6.9208e-01]]), array([[-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01]]), array([[ 5.6719e-02,  1.3333e-01,  7.2690e-01, -4.6336e-01, -5.9334e-01,\n",
      "         7.1746e-01, -1.1795e-01,  2.1614e-01,  4.3036e-01, -6.7053e-01,\n",
      "         5.7480e-01,  2.6827e-01,  2.4659e-02,  1.6066e-01,  2.0400e-01,\n",
      "        -3.9246e-01, -6.3294e-01,  6.2915e-01, -7.6340e-01,  1.1581e+00,\n",
      "         3.6218e-01,  3.1932e-01, -6.5613e-01, -4.7797e-01,  2.9885e-01,\n",
      "         6.2435e-01, -4.6060e-01, -9.6276e-01,  1.2214e+00, -2.3152e-01,\n",
      "        -6.8889e-02,  6.3519e-01,  7.7546e-01,  3.3128e-01, -3.5220e-01,\n",
      "         7.4236e-01, -6.6703e-01,  3.2260e-01,  4.3490e-01, -6.0154e-01,\n",
      "        -4.2067e-01,  2.1991e-02,  1.6378e-01, -9.5682e-01, -6.4464e-01,\n",
      "        -9.4111e-02, -2.7105e-01, -2.3312e-01, -3.8453e-01, -1.2665e+00,\n",
      "        -1.8289e-01,  5.0432e-01, -5.4260e-02,  1.1872e+00, -4.7143e-01,\n",
      "        -2.6562e+00,  4.4917e-01,  6.7218e-01,  1.4074e+00,  1.9179e-03,\n",
      "         4.0658e-01,  1.4287e+00, -1.0631e+00, -2.1713e-01,  4.7800e-01,\n",
      "         1.3170e-01,  1.2494e+00,  7.2980e-01, -2.0880e-01,  2.5449e-01,\n",
      "         1.2297e-01,  3.4922e-01,  2.4051e-01, -8.1023e-01,  5.2047e-01,\n",
      "         6.8801e-01,  6.7784e-02, -2.2132e-01, -1.2176e-01, -1.6238e-01,\n",
      "         5.3189e-01, -3.2943e-01, -5.3818e-01, -2.2957e-01, -1.4103e+00,\n",
      "         1.6494e-02, -1.3494e-01, -3.6251e-02, -7.7385e-01, -3.5178e-01,\n",
      "        -1.1230e-01, -3.7400e-01,  5.5139e-01, -1.9572e-01, -8.7050e-02,\n",
      "        -3.1469e-01, -4.2257e-01, -3.5286e-02, -2.4911e-02,  6.2131e-01]]), array([[ 9.3843e-02, -2.0283e-01,  3.4687e-01, -1.6559e-01,  9.3731e-02,\n",
      "         1.9882e-01, -6.8497e-02,  7.6033e-02,  3.1285e-01, -5.9245e-01,\n",
      "         1.9608e-01,  5.7128e-02,  7.2130e-02, -2.3307e-02,  1.3256e-01,\n",
      "        -4.4215e-01, -2.2331e-01,  5.7460e-01, -5.6796e-01, -2.9212e-01,\n",
      "         4.8023e-01, -1.9122e-01,  2.8004e-01,  2.3993e-01,  2.8304e-01,\n",
      "         1.0797e-01, -7.0790e-01, -5.2382e-01,  6.4586e-01,  1.6809e-03,\n",
      "        -2.7394e-01,  6.7346e-01, -2.0844e-01, -2.4083e-03, -7.6281e-02,\n",
      "         3.2356e-01, -5.3207e-01, -9.3861e-02, -3.9966e-01, -3.9100e-01,\n",
      "        -6.3573e-01, -3.3144e-01,  1.6891e-01, -2.7671e-01,  2.5438e-01,\n",
      "        -2.9795e-01,  4.4488e-01, -5.2510e-01,  4.4147e-01, -1.2168e+00,\n",
      "        -1.7280e-01, -1.1873e-02,  2.7402e-01,  1.6268e+00, -2.3643e-01,\n",
      "        -2.8586e+00, -4.3896e-01, -1.3818e-01,  1.0943e+00,  6.9101e-01,\n",
      "        -2.0175e-01,  9.0114e-01, -6.0804e-01,  1.4836e-01,  6.4141e-01,\n",
      "        -3.3438e-02,  2.5421e-01,  3.6123e-01, -1.4983e-01,  2.5836e-01,\n",
      "         1.9554e-01, -2.1860e-01, -1.2491e-01, -4.3070e-01,  2.2501e-01,\n",
      "        -2.7376e-02, -3.4659e-01,  7.4732e-02, -3.7176e-01,  6.4736e-03,\n",
      "         3.2609e-01, -1.0519e-01, -6.2855e-01,  1.8491e-01, -7.7250e-01,\n",
      "        -6.1363e-01, -7.9837e-02, -7.1546e-02, -5.5032e-01,  6.4136e-02,\n",
      "        -4.8826e-01, -1.9635e-01, -2.4152e-01,  7.3230e-01, -5.5225e-01,\n",
      "         2.4745e-01,  7.0344e-02,  5.8733e-01,  8.4153e-02,  1.0260e-01]])]\n",
      "=============Test X data Embedding=============\n",
      "['I', 'want', 'to', 'eat']\n",
      "[array([[-0.046539 ,  0.61966  ,  0.56647  , -0.46584  , -1.189    ,\n",
      "         0.44599  ,  0.066035 ,  0.3191   ,  0.14679  , -0.22119  ,\n",
      "         0.79239  ,  0.29905  ,  0.16073  ,  0.025324 ,  0.18678  ,\n",
      "        -0.31001  , -0.28108  ,  0.60515  , -1.0654   ,  0.52476  ,\n",
      "         0.064152 ,  1.0358   , -0.40779  , -0.38011  ,  0.30801  ,\n",
      "         0.59964  , -0.26991  , -0.76035  ,  0.94222  , -0.46919  ,\n",
      "        -0.18278  ,  0.90652  ,  0.79671  ,  0.24825  ,  0.25713  ,\n",
      "         0.6232   , -0.44768  ,  0.65357  ,  0.76902  , -0.51229  ,\n",
      "        -0.44333  , -0.21867  ,  0.3837   , -1.1483   , -0.94398  ,\n",
      "        -0.15062  ,  0.30012  , -0.57806  ,  0.20175  , -1.6591   ,\n",
      "        -0.079195 ,  0.026423 ,  0.22051  ,  0.99714  , -0.57539  ,\n",
      "        -2.7266   ,  0.31448  ,  0.70522  ,  1.4381   ,  0.99126  ,\n",
      "         0.13976  ,  1.3474   , -1.1753   ,  0.0039503,  1.0298   ,\n",
      "         0.064637 ,  0.90887  ,  0.82872  , -0.47003  , -0.10575  ,\n",
      "         0.5916   , -0.4221   ,  0.57331  , -0.54114  ,  0.10768  ,\n",
      "         0.39784  , -0.048744 ,  0.064596 , -0.61437  , -0.286    ,\n",
      "         0.5067   , -0.49758  , -0.8157   ,  0.16408  , -1.963    ,\n",
      "        -0.26693  , -0.37593  , -0.95847  , -0.8584   , -0.71577  ,\n",
      "        -0.32343  , -0.43121  ,  0.41392  ,  0.28374  , -0.70931  ,\n",
      "         0.15003  , -0.2154   , -0.37616  , -0.032502 ,  0.8062   ]]), array([[-1.7124e-01,  5.6447e-01,  3.4667e-01, -5.6711e-01, -6.5675e-01,\n",
      "         1.2081e-01, -7.6863e-01,  7.2832e-02,  4.2237e-01, -1.0464e-01,\n",
      "        -9.5098e-02,  3.5531e-01,  3.7523e-01, -1.0315e-01, -3.6373e-01,\n",
      "        -3.4235e-01,  1.5421e-01,  4.2595e-01, -9.3621e-01,  7.6463e-01,\n",
      "         2.2936e-01,  3.9153e-01,  4.8629e-02, -6.3902e-01, -2.7606e-01,\n",
      "         1.4309e-01, -1.4570e-01, -9.2603e-01,  7.3662e-01, -4.7586e-01,\n",
      "         1.6671e-01,  8.7328e-01,  4.3905e-02, -2.1803e-03,  6.0981e-01,\n",
      "         1.8376e-01,  1.7213e-01,  2.4313e-01,  3.1518e-01, -4.9676e-01,\n",
      "        -3.4410e-01, -1.8998e-01,  1.4180e-01, -1.0103e+00, -6.8090e-01,\n",
      "        -1.6667e-01, -3.8716e-02, -2.2747e-01, -2.0992e-01, -1.2806e+00,\n",
      "        -1.3947e-02,  2.5616e-02, -4.3727e-01,  8.0019e-01, -5.1486e-02,\n",
      "        -2.2276e+00,  2.3601e-01,  1.5772e-01,  1.5965e+00,  1.4865e-01,\n",
      "        -8.2737e-02,  7.0406e-01, -8.3248e-01, -4.6889e-01,  1.2773e+00,\n",
      "         4.1736e-01,  6.4693e-01,  7.8081e-01, -5.9024e-01, -5.2525e-01,\n",
      "         3.9025e-01, -5.5992e-01, -2.9066e-01, -8.8709e-01, -1.8135e-01,\n",
      "         2.2911e-01, -1.4212e-01,  3.6706e-02, -4.9487e-01, -1.1899e-01,\n",
      "         4.4099e-01, -4.2424e-01, -4.7910e-01, -9.3485e-02, -1.5978e+00,\n",
      "        -1.9971e-01,  9.9788e-02,  3.2889e-01, -2.9564e-01, -4.3231e-01,\n",
      "        -1.3218e-02, -2.0853e-01,  5.2186e-02, -8.6911e-01, -8.5816e-01,\n",
      "        -2.3443e-01,  5.7799e-02,  3.1150e-02,  4.8789e-01,  6.9311e-01]]), array([[-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01]]), array([[-0.79435  ,  0.73221  ,  0.30758  , -0.55326  , -1.0142   ,\n",
      "         0.71268  , -0.098544 ,  0.34649  ,  0.36471  , -0.95308  ,\n",
      "         0.07392  ,  0.5812   ,  0.47464  ,  0.59906  ,  0.19861  ,\n",
      "        -0.16305  , -0.21514  ,  0.23786  , -0.60277  ,  0.48853  ,\n",
      "         0.33604  ,  0.088385 , -0.13442  , -0.79827  , -0.24704  ,\n",
      "         0.76663  , -0.89623  , -0.7487   ,  0.26887  ,  0.39853  ,\n",
      "        -0.52541  ,  0.85086  ,  0.28696  , -0.37791  ,  0.51659  ,\n",
      "         1.2911   ,  0.14688  ,  0.39131  ,  0.0037607, -0.72696  ,\n",
      "         0.15202  , -0.2881   , -0.9256   , -0.82654  , -0.043089 ,\n",
      "         0.13493  , -0.70459  , -0.069904 , -0.50487  , -0.96548  ,\n",
      "         0.056805 , -0.38206  , -0.15625  ,  0.49787  , -0.60557  ,\n",
      "        -1.0282   , -0.13822  ,  0.067628 ,  1.0677   , -0.31713  ,\n",
      "         0.11543  ,  1.2516   , -0.075387 , -0.99882  ,  0.70076  ,\n",
      "         0.35112  ,  0.32259  , -0.42263  ,  0.39833  , -0.68835  ,\n",
      "        -0.48281  , -0.46954  ,  0.45839  ,  0.31533  , -0.72773  ,\n",
      "         0.76295  , -1.1747   , -0.55477  ,  0.43251  ,  0.70465  ,\n",
      "         0.12924  , -0.48052  , -1.1638   ,  0.56234  , -0.79682  ,\n",
      "        -0.65032  ,  0.39826  ,  0.17965  , -0.53933  ,  0.65524  ,\n",
      "         0.59738  , -0.73527  ,  0.66793  , -0.58127  , -1.1326   ,\n",
      "        -1.0082   ,  0.0025887, -0.32335  ,  0.69898  ,  0.26452  ]])]\n"
     ]
    }
   ],
   "source": [
    "train_x_emb_100 = [[] for _ in range(train_x_length)]\n",
    "test_x_emb_100 = [[] for _ in range(test_x_length)]\n",
    "\n",
    "for i in range(train_x_length):\n",
    "    token = train_x[i].split()\n",
    "    for j in range(len(token)):\n",
    "        train_x_emb_100[i].append(word_to_vec_map_100[token[j].lower()].reshape(1, -1))\n",
    "    if i == 0:\n",
    "        print(\"=============Train X data Embedding=============\")\n",
    "        print(token)\n",
    "        print(train_x_emb_100[i])\n",
    "        \n",
    "for i in range(test_x_length):\n",
    "    token = test_x[i].split()\n",
    "    for j in range(len(token)):\n",
    "        test_x_emb_100[i].append(word_to_vec_map_100[token[j].lower()].reshape(1, -1))\n",
    "    if i == 0:\n",
    "        print(\"=============Test X data Embedding=============\")\n",
    "        print(token)\n",
    "        print(test_x_emb_100[i])\n",
    "    \n",
    "        \n",
    "train_x_emb_100 = np.array(train_x_emb_100)\n",
    "test_x_emb_100 = np.array(test_x_emb_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_emb_50's shape: (132,)\n",
      "test_x_emb_50's shape: (56,)\n",
      "train_x_emb_100's shape: (132,)\n",
      "test_x_emb_100's shape: (56,)\n",
      "[array([[ 0.095387 , -0.16865  , -0.11514  , -0.51114  ,  0.38331  ,\n",
      "         0.22658  , -0.78504  ,  0.67626  , -0.66857  ,  0.18847  ,\n",
      "         0.19963  ,  0.58351  , -0.86134  , -0.39472  ,  1.1571   ,\n",
      "         0.51657  ,  0.11706  ,  0.0062629, -0.2593   , -0.33371  ,\n",
      "        -0.47957  ,  0.6211   ,  0.66831  , -0.058046 ,  0.81305  ,\n",
      "        -2.341    , -0.75437  ,  0.2167   ,  0.78012  , -0.81362  ,\n",
      "         2.9368   ,  0.13466  , -0.38043  , -0.59615  , -0.093113 ,\n",
      "        -0.2843   ,  0.28314  ,  0.59791  , -0.20751  , -0.43841  ,\n",
      "        -0.34187  , -0.21166  , -0.082453 ,  0.44007  , -0.3365   ,\n",
      "        -0.091078 , -0.45859  , -0.42103  , -0.53817  ,  0.13738  ]]), array([[-0.034604,  0.41087 , -0.097368, -0.19548 , -0.05855 , -0.2581  ,\n",
      "        -0.85141 ,  0.19582 , -0.76829 ,  0.37035 , -0.63907 ,  0.30593 ,\n",
      "        -0.38117 ,  0.40505 ,  0.90915 ,  0.54359 , -0.088861,  0.17422 ,\n",
      "         0.33587 , -0.36806 ,  0.32399 ,  1.056   ,  0.68695 ,  0.81261 ,\n",
      "         0.74166 , -1.7618  , -0.085259,  0.34565 ,  0.55371 , -0.24026 ,\n",
      "         2.8321  ,  0.80733 , -0.59279 , -0.52127 , -0.60045 , -0.39173 ,\n",
      "        -0.27123 , -0.52009 , -0.4718  , -0.46781 , -0.046203,  0.39371 ,\n",
      "        -0.78866 ,  0.43174 ,  0.52053 ,  0.028046, -0.013935,  0.56204 ,\n",
      "        -0.5977  ,  0.95068 ]]), array([[ 0.68047 , -0.039263,  0.30186 , -0.17792 ,  0.42962 ,  0.032246,\n",
      "        -0.41376 ,  0.13228 , -0.29847 , -0.085253,  0.17118 ,  0.22419 ,\n",
      "        -0.10046 , -0.43653 ,  0.33418 ,  0.67846 ,  0.057204, -0.34448 ,\n",
      "        -0.42785 , -0.43275 ,  0.55963 ,  0.10032 ,  0.18677 , -0.26854 ,\n",
      "         0.037334, -2.0932  ,  0.22171 , -0.39868 ,  0.20912 , -0.55725 ,\n",
      "         3.8826  ,  0.47466 , -0.95658 , -0.37788 ,  0.20869 , -0.32752 ,\n",
      "         0.12751 ,  0.088359,  0.16351 , -0.21634 , -0.094375,  0.018324,\n",
      "         0.21048 , -0.03088 , -0.19722 ,  0.082279, -0.09434 , -0.073297,\n",
      "        -0.064699, -0.26044 ]]), array([[-0.14525 ,  0.31265 ,  0.15184 , -0.63708 ,  0.63553 , -0.50295 ,\n",
      "        -0.23214 ,  0.52892 , -0.58629 ,  0.53935 , -0.3055  ,  1.0357  ,\n",
      "        -0.77989 , -0.19387 ,  1.2215  ,  0.24521 ,  0.26144 ,  0.22439 ,\n",
      "         0.15584 , -0.79146 , -0.65262 ,  1.3211  ,  0.76618 ,  0.38234 ,\n",
      "         1.4453  , -2.2643  , -1.1505  ,  0.50373 ,  1.2651  , -1.5903  ,\n",
      "         3.0518  ,  0.84118 , -0.69543 ,  0.29985 , -0.49151 , -0.22312 ,\n",
      "         0.59528 , -0.076347,  0.52358 , -0.50134 ,  0.22483 ,  0.01546 ,\n",
      "        -0.088005,  0.21282 ,  0.28545 , -0.15976 , -0.16777 , -0.50895 ,\n",
      "         0.14322 ,  1.0118  ]]), array([[-0.11008 , -0.42842 ,  0.023023, -0.66241 , -0.011844, -0.21112 ,\n",
      "        -0.77791 ,  0.82479 , -0.70825 , -0.22962 ,  0.14064 ,  0.30398 ,\n",
      "        -1.1173  , -0.18641 ,  0.82667 ,  0.44993 , -0.11678 , -0.47856 ,\n",
      "        -0.94898 , -0.14977 ,  0.19157 ,  0.10528 ,  0.66893 ,  0.02207 ,\n",
      "         0.52699 , -1.9035  ,  0.18775 ,  0.26756 ,  0.48347 , -0.28322 ,\n",
      "         3.1586  ,  0.44772 , -0.34549 , -0.31892 , -0.16631 , -0.22289 ,\n",
      "         0.26832 ,  0.4367  , -0.20443 , -0.61761 , -0.41918 , -0.22599 ,\n",
      "        -0.47885 , -0.40102 , -0.37106 ,  0.24178 ,  0.1351  , -0.81978 ,\n",
      "        -0.041543, -0.30139 ]])]\n",
      "[array([[ 0.28308  ,  0.3328   ,  0.50003  , -0.2043   , -0.34403  ,\n",
      "         0.10466  ,  0.25852  ,  0.11798  ,  0.50594  , -0.22371  ,\n",
      "         0.52499  ,  0.59336  ,  0.52034  ,  0.38505  , -0.094194 ,\n",
      "        -0.27289  ,  0.3719   ,  0.71022  , -0.78723  ,  0.142    ,\n",
      "         0.23843  ,  0.17683  , -0.13     , -0.51327  ,  0.13746  ,\n",
      "         0.092858 , -0.47914  , -1.0342   ,  0.51481  , -0.4158   ,\n",
      "         0.17622  ,  1.0603   ,  0.038309 ,  0.47409  ,  0.34532  ,\n",
      "         0.10244  , -0.10949  ,  0.031997 , -0.03563  , -0.073314 ,\n",
      "        -0.61494  , -0.0056377,  0.40174  , -0.47975  , -0.053224 ,\n",
      "        -0.23983  ,  0.64644  , -0.48115  ,  0.73126  , -1.4097   ,\n",
      "         0.15377  , -0.093436 ,  0.42553  ,  1.0389   ,  0.35117  ,\n",
      "        -2.2379   , -0.2496   ,  0.24372  ,  0.92944  ,  0.87231  ,\n",
      "         0.24636  ,  0.85973  , -0.72904  , -0.30587  ,  1.1191   ,\n",
      "        -0.16524  ,  0.65312  ,  0.22118  , -0.53921  , -0.034287 ,\n",
      "         0.39948  , -0.34075  ,  0.048538 , -0.023853 , -0.076588 ,\n",
      "         0.06669  , -0.16751  , -0.2614   , -0.8065   ,  0.36449  ,\n",
      "         0.18566  , -0.03655  , -0.56927  , -0.093071 , -2.0503   ,\n",
      "        -0.50041  , -0.0049648, -0.33624  , -0.17233  , -0.19766  ,\n",
      "        -0.35015  , -0.63284  ,  0.12563  ,  0.022786 , -0.56203  ,\n",
      "         0.21945  , -0.4995   ,  0.031549 , -0.22464  ,  0.48508  ]]), array([[-7.9761e-02,  1.9551e-01,  3.0579e-01, -2.1571e-01, -4.9017e-01,\n",
      "         4.6350e-01, -1.5171e-01, -1.6002e-01,  1.3081e-01, -6.5718e-01,\n",
      "        -1.1343e-01,  1.0231e-01,  1.1583e-01,  2.0241e-03,  1.8107e-01,\n",
      "        -1.8263e-01, -4.2386e-01,  5.6726e-02, -3.0419e-01,  1.5828e-01,\n",
      "        -1.1820e-01,  1.8624e-01, -5.2731e-01, -5.9154e-01,  7.1546e-02,\n",
      "         1.9633e-01, -4.9147e-02, -3.3004e-01,  5.0489e-01,  5.1138e-01,\n",
      "        -5.0726e-01,  7.9255e-01,  1.7890e-01,  3.5001e-01, -7.2015e-02,\n",
      "         8.9293e-01, -2.7286e-01, -5.7761e-01,  1.8615e-01, -9.8489e-02,\n",
      "        -6.1398e-01,  6.1104e-02, -3.3847e-01, -2.9190e-01, -7.1794e-01,\n",
      "        -3.7329e-01, -3.2193e-01, -3.8184e-01,  4.9009e-02, -1.2856e+00,\n",
      "         3.1266e-02,  1.2953e-01,  1.1391e-01,  6.9458e-01,  3.3839e-01,\n",
      "        -2.1965e+00,  8.4632e-02,  7.6947e-02,  9.7508e-01,  3.2743e-01,\n",
      "         2.8664e-01,  7.9778e-01, -4.9729e-01, -1.1200e+00,  9.1580e-01,\n",
      "         8.9064e-02,  1.1378e+00,  3.3187e-01, -1.8245e-01,  1.7541e-01,\n",
      "         9.8961e-02, -3.9566e-01, -4.1590e-01, -7.4777e-01, -4.6913e-01,\n",
      "         3.8674e-01,  2.7161e-01, -1.5303e-02, -5.2653e-01, -2.0984e-01,\n",
      "         1.2046e-01, -4.0667e-01,  2.9756e-01, -1.3695e-01, -1.3846e+00,\n",
      "        -1.4904e-01, -4.8938e-01,  7.5170e-01, -2.2143e-01, -5.2081e-01,\n",
      "         2.6477e-01,  2.7790e-01, -4.1847e-01, -2.1104e-01, -7.4714e-01,\n",
      "        -6.5609e-02, -2.6370e-01,  2.0017e-01,  8.7429e-01,  6.9208e-01]]), array([[-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01]]), array([[ 5.6719e-02,  1.3333e-01,  7.2690e-01, -4.6336e-01, -5.9334e-01,\n",
      "         7.1746e-01, -1.1795e-01,  2.1614e-01,  4.3036e-01, -6.7053e-01,\n",
      "         5.7480e-01,  2.6827e-01,  2.4659e-02,  1.6066e-01,  2.0400e-01,\n",
      "        -3.9246e-01, -6.3294e-01,  6.2915e-01, -7.6340e-01,  1.1581e+00,\n",
      "         3.6218e-01,  3.1932e-01, -6.5613e-01, -4.7797e-01,  2.9885e-01,\n",
      "         6.2435e-01, -4.6060e-01, -9.6276e-01,  1.2214e+00, -2.3152e-01,\n",
      "        -6.8889e-02,  6.3519e-01,  7.7546e-01,  3.3128e-01, -3.5220e-01,\n",
      "         7.4236e-01, -6.6703e-01,  3.2260e-01,  4.3490e-01, -6.0154e-01,\n",
      "        -4.2067e-01,  2.1991e-02,  1.6378e-01, -9.5682e-01, -6.4464e-01,\n",
      "        -9.4111e-02, -2.7105e-01, -2.3312e-01, -3.8453e-01, -1.2665e+00,\n",
      "        -1.8289e-01,  5.0432e-01, -5.4260e-02,  1.1872e+00, -4.7143e-01,\n",
      "        -2.6562e+00,  4.4917e-01,  6.7218e-01,  1.4074e+00,  1.9179e-03,\n",
      "         4.0658e-01,  1.4287e+00, -1.0631e+00, -2.1713e-01,  4.7800e-01,\n",
      "         1.3170e-01,  1.2494e+00,  7.2980e-01, -2.0880e-01,  2.5449e-01,\n",
      "         1.2297e-01,  3.4922e-01,  2.4051e-01, -8.1023e-01,  5.2047e-01,\n",
      "         6.8801e-01,  6.7784e-02, -2.2132e-01, -1.2176e-01, -1.6238e-01,\n",
      "         5.3189e-01, -3.2943e-01, -5.3818e-01, -2.2957e-01, -1.4103e+00,\n",
      "         1.6494e-02, -1.3494e-01, -3.6251e-02, -7.7385e-01, -3.5178e-01,\n",
      "        -1.1230e-01, -3.7400e-01,  5.5139e-01, -1.9572e-01, -8.7050e-02,\n",
      "        -3.1469e-01, -4.2257e-01, -3.5286e-02, -2.4911e-02,  6.2131e-01]]), array([[ 9.3843e-02, -2.0283e-01,  3.4687e-01, -1.6559e-01,  9.3731e-02,\n",
      "         1.9882e-01, -6.8497e-02,  7.6033e-02,  3.1285e-01, -5.9245e-01,\n",
      "         1.9608e-01,  5.7128e-02,  7.2130e-02, -2.3307e-02,  1.3256e-01,\n",
      "        -4.4215e-01, -2.2331e-01,  5.7460e-01, -5.6796e-01, -2.9212e-01,\n",
      "         4.8023e-01, -1.9122e-01,  2.8004e-01,  2.3993e-01,  2.8304e-01,\n",
      "         1.0797e-01, -7.0790e-01, -5.2382e-01,  6.4586e-01,  1.6809e-03,\n",
      "        -2.7394e-01,  6.7346e-01, -2.0844e-01, -2.4083e-03, -7.6281e-02,\n",
      "         3.2356e-01, -5.3207e-01, -9.3861e-02, -3.9966e-01, -3.9100e-01,\n",
      "        -6.3573e-01, -3.3144e-01,  1.6891e-01, -2.7671e-01,  2.5438e-01,\n",
      "        -2.9795e-01,  4.4488e-01, -5.2510e-01,  4.4147e-01, -1.2168e+00,\n",
      "        -1.7280e-01, -1.1873e-02,  2.7402e-01,  1.6268e+00, -2.3643e-01,\n",
      "        -2.8586e+00, -4.3896e-01, -1.3818e-01,  1.0943e+00,  6.9101e-01,\n",
      "        -2.0175e-01,  9.0114e-01, -6.0804e-01,  1.4836e-01,  6.4141e-01,\n",
      "        -3.3438e-02,  2.5421e-01,  3.6123e-01, -1.4983e-01,  2.5836e-01,\n",
      "         1.9554e-01, -2.1860e-01, -1.2491e-01, -4.3070e-01,  2.2501e-01,\n",
      "        -2.7376e-02, -3.4659e-01,  7.4732e-02, -3.7176e-01,  6.4736e-03,\n",
      "         3.2609e-01, -1.0519e-01, -6.2855e-01,  1.8491e-01, -7.7250e-01,\n",
      "        -6.1363e-01, -7.9837e-02, -7.1546e-02, -5.5032e-01,  6.4136e-02,\n",
      "        -4.8826e-01, -1.9635e-01, -2.4152e-01,  7.3230e-01, -5.5225e-01,\n",
      "         2.4745e-01,  7.0344e-02,  5.8733e-01,  8.4153e-02,  1.0260e-01]])]\n"
     ]
    }
   ],
   "source": [
    "# embedded dataset shape\n",
    "print(\"train_x_emb_50's shape: {}\".format(train_x_emb_50.shape))  # (132, # of tokens, 50(embedding dim))\n",
    "print(\"test_x_emb_50's shape: {}\".format(test_x_emb_50.shape))\n",
    "print(\"train_x_emb_100's shape: {}\".format(train_x_emb_100.shape))  # (132, # of tokens, 100(embedding dim))\n",
    "print(\"test_x_emb_100's shape: {}\".format(test_x_emb_100.shape))\n",
    "print(train_x_emb_50[0])\n",
    "print(train_x_emb_100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Optimizer\n",
    "- Stochastic Gradient Descent \n",
    "- ADAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, param, d_param):\n",
    "        param -= self.lr * d_param\n",
    "        return param\n",
    "    \n",
    "class ADAM:\n",
    "    def __init__(self, lr, beta_1 = 0.9, beta_2 = 0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta_1\n",
    "        self.beta2 = beta_2\n",
    "        self.first_momentum = 0\n",
    "        self.second_momentum = 0\n",
    "        self.iter = 0\n",
    "        \n",
    "        \n",
    "    def update(self, param, d_param):\n",
    "        self.iter += 1\n",
    "        # if self.iter == 1:\n",
    "        #     b = ((1 - self.beta1) * d_param)\n",
    "        #     print(b.shape)\n",
    "        # else:\n",
    "        #     a = (self.beta1 * self.first_momentum)\n",
    "        #     print(a.shape)\n",
    "        #     b = ((1 - self.beta1) * d_param)\n",
    "        #     print(b.shape)\n",
    "        self.first_momentum = self.beta1 * self.first_momentum + (1 - self.beta1) * d_param\n",
    "        self.second_momentum = self.beta2 * self.second_momentum + (1 - self.beta2) * d_param * d_param\n",
    "        first_unbias = self.first_momentum / (1 - self.beta1 ** self.iter)\n",
    "        second_unbias = self.second_momentum / (1 - self.beta2 ** self.iter)\n",
    "        return (param - self.lr * first_unbias / (np.sqrt(second_unbias) + 1e-8))\n",
    "    \n",
    "    def clear(self):\n",
    "        self.first_momentum = 0\n",
    "        self.second_momentum = 0\n",
    "        self.iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Sub Modules\n",
    "### with backpropagation\n",
    "- RNN Layer\n",
    "- LSTM Layer\n",
    "- FC Layer\n",
    "- Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN, LSTM Layer\n",
    "class RNN_Cell():\n",
    "    def __init__(self, input_size, hidden_size, optimizer, lr, beta1, beta2):\n",
    "        np.random.seed(42)\n",
    "        self.optimizer = optimizer\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.w_hh = np.random.normal(size = (hidden_size, hidden_size)) / 10\n",
    "        self.w_xh = np.random.normal(size = (input_size, hidden_size)) / 10\n",
    "        self.b_h = np.random.normal(size = (1, hidden_size)) / 10\n",
    "        \n",
    "        self.hidden_states = [np.zeros((1, hidden_size))]\n",
    "        self.input_tokens = None\n",
    "        self.len_tokens = 0\n",
    "        \n",
    "        self.dw_hh = np.zeros((hidden_size, hidden_size))\n",
    "        self.dw_xh = np.zeros((input_size, hidden_size))\n",
    "        self.db_h = np.zeros((1, hidden_size))\n",
    "        \n",
    "        if optimizer == \"SGD\":\n",
    "            self.optimizers = {\"w_hh\": SGD(lr),\n",
    "                               \"w_xh\": SGD(lr),\n",
    "                               \"b_h\": SGD(lr)}\n",
    "        elif optimizer == \"ADAM\":\n",
    "            self.optimizers = {\"w_hh\": ADAM(lr, beta1, beta2),\n",
    "                               \"w_xh\": ADAM(lr, beta1, beta2),\n",
    "                               \"b_h\": ADAM(lr, beta1, beta2)}\n",
    "        \n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x:   (# of tokens, 1, glove dims) \n",
    "            embedded sentence\n",
    "            \n",
    "        hidden_states_per_sentence:     (# of tokens, 1, hidden_size)\n",
    "            all hidden states of sentence\n",
    "        '''\n",
    "        \n",
    "        # init per input\n",
    "        self.hidden_states = [np.zeros((1, self.hidden_size))]\n",
    "        self.len_tokens = len(x)\n",
    "        self.input_tokens = x\n",
    "        \n",
    "        for i in range(self.len_tokens):\n",
    "            # print(self.hidden_states[i].shape, self.w_hh.shape)\n",
    "            # print(x[i].shape, self.w_xh.shape)\n",
    "            # print(self.b_h.shape)\n",
    "            hidden_state = np.matmul(self.hidden_states[i], self.w_hh) + np.matmul(x[i], self.w_xh) + self.b_h\n",
    "            hidden_state = np.tanh(hidden_state)\n",
    "            self.hidden_states.append(hidden_state)\n",
    "        hidden_states_per_sentence = np.array(self.hidden_states[1:])\n",
    "        return hidden_states_per_sentence\n",
    "       \n",
    "    def back_prop(self, dh):\n",
    "        '''\n",
    "        dh:   (# of tokens, 1, hidden_size)\n",
    "            deriative backward\n",
    "            \n",
    "        back_prop dout:  (# of tokens, 1, input_size)\n",
    "        '''\n",
    "        # print(\"dh's shape: {}\".format(dh.shape))\n",
    "        if dh.shape[0] != self.len_tokens:\n",
    "            last_h = dh\n",
    "            dh = [np.zeros((1, self.hidden_size)) for _ in range(self.len_tokens - 1)]\n",
    "            dh.append(last_h)\n",
    "            dh = np.array(dh)\n",
    "        \n",
    "        # init per input    \n",
    "        self.dw_hh = np.zeros((self.hidden_size, self.hidden_size))\n",
    "        self.dw_xh = np.zeros((self.input_size, self.hidden_size))\n",
    "        self.db_h = np.zeros((1, self.hidden_size))\n",
    "        hidden_states = np.array(self.hidden_states)\n",
    "        dinput = []\n",
    "        dh_t = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        for i in reversed(range(self.len_tokens)):\n",
    "            dh_t += dh[i]\n",
    "            dresult = (1 - (hidden_states[i+1] ** 2)) * dh_t\n",
    "            dh_t = np.matmul(dresult, self.w_hh.T)\n",
    "            \n",
    "            self.dw_hh += np.matmul(hidden_states[i-1].T, dresult)\n",
    "            # print(\"input tokens's shape: {}, dresult's shape: {}\".format(self.input_tokens[i].T.shape, dresult.shape))\n",
    "            self.dw_xh += np.matmul(self.input_tokens[i].T, dresult)\n",
    "            self.db_h += dresult\n",
    "            dinput.append(np.matmul(dresult, self.w_xh.T))\n",
    "        dinput.reverse()\n",
    "                \n",
    "        return np.array(dinput)\n",
    "    \n",
    "    def update(self):\n",
    "        self.w_hh = self.optimizers[\"w_hh\"].update(self.w_hh, self.dw_hh)\n",
    "        self.w_xh = self.optimizers[\"w_xh\"].update(self.w_xh, self.dw_xh)\n",
    "        self.b_h = self.optimizers[\"b_h\"].update(self.b_h, self.db_h)\n",
    "        \n",
    "    def clear_optim(self):\n",
    "        if self.optimizer == \"ADAM\":\n",
    "            self.optimizers[\"w_hh\"].clear()\n",
    "            self.optimizers[\"w_xh\"].clear()\n",
    "            self.optimizers[\"b_h\"].clear()\n",
    "        else: \n",
    "            print(\"Optimzier is SGD, SGD doesn't need to clear\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "\n",
    "def Sigmoid(x):\n",
    "    result = 1 / (1 + np.exp(-x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Cell():\n",
    "    def __init__(self, input_size, hidden_size, optimizer, lr, beta1, beta2):\n",
    "        self.optimizer = optimizer\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # forget gate\n",
    "        self.w_xh_f = np.random.normal(size = (input_size, hidden_size)) / 10\n",
    "        self.w_hh_f = np.random.normal(size = (hidden_size, hidden_size)) / 10\n",
    "        self.b_h_f = np.random.normal(size = (1, hidden_size)) / 10\n",
    "        \n",
    "        self.dw_xh_f = np.zeros((input_size, hidden_size))\n",
    "        self.dw_hh_f = np.zeros((hidden_size, hidden_size))\n",
    "        self.db_h_f = np.zeros((1, hidden_size))\n",
    "        \n",
    "        # input gate\n",
    "        self.w_xh_i = np.random.normal(size = (input_size, hidden_size)) / 10\n",
    "        self.w_hh_i = np.random.normal(size = (hidden_size, hidden_size)) / 10\n",
    "        self.b_h_i = np.random.normal(size = (1, hidden_size)) / 10\n",
    "        \n",
    "        self.dw_xh_i = np.zeros((input_size, hidden_size))\n",
    "        self.dw_hh_i = np.zeros((hidden_size, hidden_size))\n",
    "        self.db_h_i = np.zeros((1, hidden_size))\n",
    "        \n",
    "        self.w_xh_c = np.random.normal(size = (input_size, hidden_size)) / 10\n",
    "        self.w_hh_c = np.random.normal(size = (hidden_size, hidden_size)) / 10\n",
    "        self.b_h_c = np.random.normal(size = (1, hidden_size)) / 10\n",
    "        \n",
    "        self.dw_xh_c = np.zeros((input_size, hidden_size))\n",
    "        self.dw_hh_c = np.zeros((hidden_size, hidden_size))\n",
    "        self.db_h_c = np.zeros((1, hidden_size))\n",
    "    \n",
    "        # output gate\n",
    "        self.w_xh_o = np.random.normal(size = (input_size, hidden_size)) / 10\n",
    "        self.w_hh_o = np.random.normal(size = (hidden_size, hidden_size)) / 10\n",
    "        self.b_h_o = np.random.normal(size = (1, hidden_size)) / 10\n",
    "        \n",
    "        self.dw_xh_o = np.zeros((input_size, hidden_size))\n",
    "        self.dw_hh_o = np.zeros((hidden_size, hidden_size))\n",
    "        self.db_h_o = np.zeros((1, hidden_size))\n",
    "        \n",
    "        # etc\n",
    "        self.hidden_states = [np.zeros((1, hidden_size))]\n",
    "        self.cell_states = [np.zeros((1, hidden_size))]\n",
    "        self.forget_gate_results = []\n",
    "        self.input_gate_sig_results = []\n",
    "        self.input_gate_tanh_results = []\n",
    "        self.output_gate_results = []\n",
    "        \n",
    "        self.input_tokens = None\n",
    "        self.len_tokens = 0\n",
    "        \n",
    "        if optimizer == \"SGD\":\n",
    "            self.optimizers = {\"w_hh_f\": SGD(lr),\n",
    "                               \"w_xh_f\": SGD(lr),\n",
    "                               \"b_h_f\": SGD(lr),\n",
    "                               \n",
    "                               \"w_hh_i\": SGD(lr),\n",
    "                               \"w_xh_i\": SGD(lr),\n",
    "                               \"b_h_i\": SGD(lr),\n",
    "                               \n",
    "                               \"w_hh_c\": SGD(lr),\n",
    "                               \"w_xh_c\": SGD(lr),\n",
    "                               \"b_h_c\": SGD(lr),\n",
    "                               \n",
    "                               \"w_hh_o\": SGD(lr),\n",
    "                               \"w_xh_o\": SGD(lr),\n",
    "                               \"b_h_o\": SGD(lr)}\n",
    "        elif optimizer == \"ADAM\":\n",
    "            self.optimizers = {\"w_hh_f\": ADAM(lr, beta1, beta2),\n",
    "                               \"w_xh_f\": ADAM(lr, beta1, beta2),\n",
    "                               \"b_h_f\": ADAM(lr, beta1, beta2),\n",
    "                               \n",
    "                               \"w_hh_i\": ADAM(lr, beta1, beta2),\n",
    "                               \"w_xh_i\": ADAM(lr, beta1, beta2),\n",
    "                               \"b_h_i\": ADAM(lr, beta1, beta2),\n",
    "                               \n",
    "                               \"w_hh_c\": ADAM(lr, beta1, beta2),\n",
    "                               \"w_xh_c\": ADAM(lr, beta1, beta2),\n",
    "                               \"b_h_c\": ADAM(lr, beta1, beta2),\n",
    "                               \n",
    "                               \"w_hh_o\": ADAM(lr, beta1, beta2),\n",
    "                               \"w_xh_o\": ADAM(lr, beta1, beta2),\n",
    "                               \"b_h_o\": ADAM(lr, beta1, beta2)}\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x:   (# of tokens, 1, glove dims) \n",
    "            embedded sentence\n",
    "            \n",
    "        hidden_states_per_sentence:     (# of tokens, 1, hidden_size)\n",
    "            all hidden states of sentence\n",
    "        '''\n",
    "        # init per input\n",
    "        self.hidden_states = [np.zeros((1, self.hidden_size))]\n",
    "        self.cell_states = [np.zeros((1, self.hidden_size))]\n",
    "        self.forget_gate_results = []\n",
    "        self.input_gate_sig_results = []\n",
    "        self.input_gate_tanh_results = []\n",
    "        self.output_gate_results = []\n",
    "        \n",
    "        self.len_tokens = len(x)\n",
    "        self.input_tokens = x\n",
    "        \n",
    "        for i in range(self.len_tokens):\n",
    "            ht_1 = self.hidden_states[i]\n",
    "            ct_1 = self.cell_states[i]\n",
    "            token = x[i]\n",
    "            \n",
    "            f_t = Sigmoid(np.matmul(ht_1, self.w_hh_f) + np.matmul(token, self.w_xh_f) + self.b_h_f)\n",
    "            i_t = Sigmoid(np.matmul(ht_1, self.w_hh_i) + np.matmul(token, self.w_xh_i) + self.b_h_i)\n",
    "            cur_c_t = np.tanh(np.matmul(ht_1, self.w_hh_c) + np.matmul(token, self.w_xh_c) + self.b_h_c)\n",
    "            o_t = Sigmoid(np.matmul(ht_1, self.w_hh_o) + np.matmul(token, self.w_xh_o) + self.b_h_o)\n",
    "            \n",
    "            self.forget_gate_results.append(f_t)\n",
    "            self.input_gate_sig_results.append(i_t)\n",
    "            self.input_gate_tanh_results.append(cur_c_t)\n",
    "            self.output_gate_results.append(o_t)\n",
    "            \n",
    "            c_t = ct_1 * f_t + i_t * cur_c_t\n",
    "            h_t = o_t * np.tanh(c_t)\n",
    "            self.cell_states.append(c_t)\n",
    "            self.hidden_states.append(h_t)\n",
    "            \n",
    "        hidden_states_per_sentence = np.array(self.hidden_states[1:])\n",
    "        return hidden_states_per_sentence\n",
    "        \n",
    "    def back_prop(self, dh):\n",
    "        # init per input\n",
    "        self.dw_xh_f = np.zeros((self.input_size, self.hidden_size))\n",
    "        self.dw_hh_f = np.zeros((self.hidden_size, self.hidden_size))\n",
    "        self.db_h_f = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.dw_xh_i = np.zeros((self.input_size, self.hidden_size))\n",
    "        self.dw_hh_i = np.zeros((self.hidden_size, self.hidden_size))\n",
    "        self.db_h_i = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.dw_xh_c = np.zeros((self.input_size, self.hidden_size))\n",
    "        self.dw_hh_c = np.zeros((self.hidden_size, self.hidden_size))\n",
    "        self.db_h_c = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.dw_xh_o = np.zeros((self.input_size, self.hidden_size))\n",
    "        self.dw_hh_o = np.zeros((self.hidden_size, self.hidden_size))\n",
    "        self.db_h_o = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        dinput = []\n",
    "        \n",
    "        if dh.shape[0] != self.len_tokens:\n",
    "            last_h = dh\n",
    "            dh = [np.zeros((1, self.hidden_size)) for _ in range(self.len_tokens - 1)]\n",
    "            dh.append(last_h)\n",
    "            dh = np.array(dh)\n",
    "        \n",
    "        dh_t = np.zeros((1, self.hidden_size))\n",
    "        dc_t = np.zeros((1, self.hidden_size))\n",
    "        for i in reversed(range(self.len_tokens)):\n",
    "            # load cur gate values, states and token\n",
    "            f_t = self.forget_gate_results[i]\n",
    "            i_t = self.input_gate_sig_results[i]\n",
    "            cur_c_t = self.input_gate_tanh_results[i]\n",
    "            o_t = self.output_gate_results[i]\n",
    "            \n",
    "            token = self.input_tokens[i]\n",
    "            \n",
    "            # hidden state's derivative and cell state's derivative\n",
    "            dh_t += dh[i]\n",
    "            dc_t += (1 - np.tanh(self.cell_states[i]) ** 2) * dh_t * self.output_gate_results[i]\n",
    "            \n",
    "            # gate results derivatives\n",
    "            df_t = dc_t * self.cell_states[i - 1]\n",
    "            di_t = dc_t * cur_c_t\n",
    "            dcur_c_t = dc_t * i_t\n",
    "            do_t = dh_t * np.tanh(self.cell_states[i])\n",
    "            \n",
    "            dbefore_act_f = df_t * (f_t * (1 - f_t))   # sigmoid\n",
    "            dbefore_act_i = di_t * (i_t * (1 - i_t))   # sigmoid\n",
    "            dbefore_act_c = dcur_c_t * (1 - cur_c_t ** 2)   # tanh\n",
    "            dbefore_act_o = do_t * (o_t * (1 - o_t))   # sigmoid\n",
    "            \n",
    "            # set w's derivatives, b's derivatives\n",
    "            self.db_h_f += dbefore_act_f\n",
    "            self.db_h_i += dbefore_act_i\n",
    "            self.db_h_c += dbefore_act_c\n",
    "            self.db_h_o += dbefore_act_o\n",
    "            \n",
    "            self.dw_xh_f += np.matmul(token.T, dbefore_act_f)\n",
    "            self.dw_xh_i += np.matmul(token.T, dbefore_act_i)\n",
    "            self.dw_xh_c += np.matmul(token.T, dbefore_act_c)\n",
    "            self.dw_xh_o += np.matmul(token.T, dbefore_act_o)\n",
    "            \n",
    "            self.dw_hh_f += np.matmul(self.hidden_states[i-1].T, dbefore_act_f)\n",
    "            self.dw_hh_i += np.matmul(self.hidden_states[i-1].T, dbefore_act_i)\n",
    "            self.dw_hh_c += np.matmul(self.hidden_states[i-1].T, dbefore_act_c)\n",
    "            self.dw_hh_o += np.matmul(self.hidden_states[i-1].T, dbefore_act_o)        \n",
    "            \n",
    "            dx_t = np.matmul(dbefore_act_f, self.w_xh_f.T) + np.matmul(dbefore_act_i, self.w_xh_i.T) + \\\n",
    "                   np.matmul(dbefore_act_c, self.w_xh_c.T) + np.matmul(dbefore_act_o, self.w_xh_o.T)\n",
    "            \n",
    "            dinput.append(dx_t)\n",
    "            dh_t = np.matmul(dbefore_act_f, self.w_hh_f.T) + np.matmul(dbefore_act_i, self.w_hh_i.T) + \\\n",
    "                   np.matmul(dbefore_act_c, self.w_hh_c.T) + np.matmul(dbefore_act_o, self.w_hh_o.T)\n",
    "            dc_t = dc_t * self.forget_gate_results[i]\n",
    "            \n",
    "        dinput.reverse()\n",
    "        dweights_x = [self.dw_xh_f, self.dw_xh_i, self.dw_xh_c, self.dw_xh_o]\n",
    "        dweights_h = [self.dw_hh_f, self.dw_hh_i, self.dw_hh_c, self.dw_hh_o]\n",
    "        dbias = [self.db_h_f, self.db_h_i, self.db_h_c, self.db_h_o]\n",
    "        for d in dweights_h+dweights_x+dbias:\n",
    "            np.clip(d, -1, 1, out=d)\n",
    "        return np.array(dinput)\n",
    "    \n",
    "    def update(self):\n",
    "        self.w_hh_f = self.optimizers[\"w_hh_f\"].update(self.w_hh_f, self.dw_hh_f)\n",
    "        self.w_xh_f = self.optimizers[\"w_xh_f\"].update(self.w_xh_f, self.dw_xh_f)\n",
    "        self.b_h_f = self.optimizers[\"b_h_f\"].update(self.b_h_f, self.db_h_f)\n",
    "        \n",
    "        self.w_hh_i = self.optimizers[\"w_hh_i\"].update(self.w_hh_i, self.dw_hh_i)\n",
    "        self.w_xh_i = self.optimizers[\"w_xh_i\"].update(self.w_xh_i, self.dw_xh_i)\n",
    "        self.b_h_i = self.optimizers[\"b_h_i\"].update(self.b_h_i, self.db_h_i)\n",
    "        \n",
    "        self.w_hh_c = self.optimizers[\"w_hh_c\"].update(self.w_hh_c, self.dw_hh_c)\n",
    "        self.w_xh_c = self.optimizers[\"w_xh_c\"].update(self.w_xh_c, self.dw_xh_c)\n",
    "        self.b_h_c = self.optimizers[\"b_h_c\"].update(self.b_h_c, self.db_h_c)\n",
    "        \n",
    "        self.w_hh_o = self.optimizers[\"w_hh_o\"].update(self.w_hh_o, self.dw_hh_o)\n",
    "        self.w_xh_o = self.optimizers[\"w_xh_o\"].update(self.w_xh_o, self.dw_xh_o)\n",
    "        self.b_h_o = self.optimizers[\"b_h_o\"].update(self.b_h_o, self.db_h_o)\n",
    "            \n",
    "    def clear_optim(self):\n",
    "        if self.optimizer == \"ADAM\":\n",
    "            self.optimizers[\"w_hh_f\"].clear()\n",
    "            self.optimizers[\"w_xh_f\"].clear()\n",
    "            self.optimizers[\"b_h_f\"].clear()\n",
    "            \n",
    "            self.optimizers[\"w_hh_i\"].clear()\n",
    "            self.optimizers[\"w_xh_i\"].clear()\n",
    "            self.optimizers[\"b_h_i\"].clear()\n",
    "            \n",
    "            self.optimizers[\"w_hh_c\"].clear()\n",
    "            self.optimizers[\"w_xh_c\"].clear()\n",
    "            self.optimizers[\"b_h_c\"].clear()\n",
    "            \n",
    "            self.optimizers[\"w_hh_o\"].clear()\n",
    "            self.optimizers[\"w_xh_o\"].clear()\n",
    "            self.optimizers[\"b_h_o\"].clear()\n",
    "        else: \n",
    "            print(\"Optimzier is SGD, SGD doesn't need to clear\")\n",
    "        \n",
    "# sample = train_x_emb_50[0]\n",
    "# print(\"# of tokens: {}\".format(len(sample)))\n",
    "# r1 = LSTM_Cell(50, 10, \"SGD\")\n",
    "# r2 = LSTM_Cell(10, 5, \"SGD\")\n",
    "\n",
    "\n",
    "# result1 = r1.forward(sample)\n",
    "# result2 = r2.forward(result1)\n",
    "\n",
    "# print(result1.shape)\n",
    "# print(result2.shape)\n",
    "\n",
    "# back1 = r2.back_prop(result2)\n",
    "# print(back1.shape)\n",
    "# back2 = r1.back_prop(back1)\n",
    "# print(back2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout Layer\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p  # probability of keeping a unit active, higher = less dropout \n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x, train_mode=True):\n",
    "        if train_mode:\n",
    "            self.mask = np.random.rand(*x.shape) < self.p\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * self.p\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Layer and ReLU implementation\n",
    "\n",
    "class LinearLayer():\n",
    "    def __init__(self, input_size, output_size, optimizer, lr, beta1, beta2):\n",
    "        np.random.seed(0)\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.optimizer = optimizer\n",
    "        self.w = np.random.normal(size = (input_size, output_size)) / 10\n",
    "        self.b = np.random.normal(size = (1, output_size)) / 10\n",
    "\n",
    "        self.dout_w = None\n",
    "        self.dout_b = None\n",
    "        self.input = None\n",
    "\n",
    "        if optimizer == \"SGD\":\n",
    "            self.optimizers = {\"w\": SGD(lr),\n",
    "                               \"b\": SGD(lr)}\n",
    "        elif optimizer == \"ADAM\":\n",
    "            self.optimizers = {\"w\": ADAM(lr, beta1, beta2),\n",
    "                               \"b\": ADAM(lr, beta1, beta2)}\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            self.input = np.expand_dims(x, axis=0)\n",
    "        else:\n",
    "            self.input = x\n",
    "\n",
    "        # print(\"input's shape: {}\".format(self.input.shape))   # for debugging\n",
    "        return  np.matmul(x, self.w) + self.b\n",
    "\n",
    "    def back_prop(self, dout):\n",
    "        if self.input.any == None:\n",
    "            raise Exception(\"No forward\")\n",
    "        if len(dout.shape) == 1:\n",
    "            dout = np.expand_dims(dout, axis=0)\n",
    "        else:\n",
    "            dout = dout\n",
    "        self.dout_w = np.matmul(self.input.T, dout) \n",
    "        self.dout_b = np.sum(dout, axis=0, keepdims=True)\n",
    "        \n",
    "        # for debugging        \n",
    "        # print(\"dout' shape: {}, input's shape: {}, weight's shape: {}\".format(self.dout.shape, self.input.shape, self.w.shape))\n",
    "\n",
    "        return np.matmul(dout, self.w.T)\n",
    "    def update(self):\n",
    "        # print(self.w.shape)\n",
    "        # print(self.dout_w.shape)\n",
    "        self.w = self.optimizers[\"w\"].update(self.w, self.dout_w)\n",
    "        self.b = self.optimizers[\"b\"].update(self.b, self.dout_b)\n",
    "        \n",
    "    def clear_optim(self):\n",
    "        if self.optimizer == \"ADAM\":\n",
    "            self.optimizers[\"w\"].clear()\n",
    "            self.optimizers[\"b\"].clear()\n",
    "        else: \n",
    "            print(\"Optimzier is SGD, SGD doesn't need to clear\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Functions\n",
    "### with dout\n",
    "- SoftMax\n",
    "- Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMax():\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        x -= np.max(x, axis=1, keepdims=True)\n",
    "        return np.exp(x)/np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "        # e_x = np.exp(x - np.max(x, axis=1, keepdims= True)) # prevent overflow\n",
    "        # if np.any(np.sum(e_x, axis=1, keepdims= True) == np.nan):\n",
    "        #     print(wrong)\n",
    "        # return e_x / np.sum(e_x, axis=1, keepdims= True) + sigma\n",
    "\n",
    "    def back_prop(self, y):\n",
    "        prop = self.forward(self.x)\n",
    "        prop[np.arange(prop.shape[0]),y] -= 1\n",
    "        prop /= self.x.shape[0]\n",
    "        return prop \n",
    "\n",
    "class Cross_Entropy():\n",
    "    # back prop not used\n",
    "    def forward(self, y_hat, y):    # y_hat.shape = (1, 5)\n",
    "        # if np.isnan(y_hat.any):\n",
    "        #     print(\"cross entropy forwarding error\")\n",
    "        return np.sum(-1 * np.log(y_hat[np.arange(y_hat.shape[0]), y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Layer Recurrent Neural Network(RNN)\n",
    "### sequence\n",
    "**input - Embedding - LSTM - Dropout - LSTM - Dropout - LSTM - Dropout - FC Layer - Activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "class RNN(): \n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, optimizer, p, lr, beta1, beta2):\n",
    "        self.R1 = RNN_Cell(input_size, hidden_size1, optimizer, lr, beta1, beta2)\n",
    "        self.Drop1 = Dropout(p)\n",
    "        \n",
    "        self.R2 = RNN_Cell(hidden_size1, hidden_size2, optimizer, lr, beta1, beta2)\n",
    "        self.Drop2 = Dropout(p)\n",
    "        \n",
    "        self.L3 = LinearLayer(hidden_size2, 5, optimizer, lr, beta1, beta2)\n",
    "        self.SM = SoftMax()\n",
    "        \n",
    "    def forward(self, x, mode = \"No_Dropout\", train_activation = True):\n",
    "        if mode == \"No_Dropout\":\n",
    "            hidden_states = self.R1.forward(x)\n",
    "            hidden_states = self.R2.forward(hidden_states)\n",
    "            \n",
    "            output = self.L3.forward(hidden_states[-1])\n",
    "            output = self.SM.forward(output)\n",
    "            \n",
    "            return output\n",
    "        else:\n",
    " \n",
    "            hidden_states = self.R1.forward(x)\n",
    "            hidden_states = self.Drop1.forward(hidden_states, train_activation)\n",
    "            \n",
    "            hidden_states = self.R2.forward(hidden_states)\n",
    "            hidden_states = self.Drop2.forward(hidden_states, train_activation)\n",
    "            \n",
    "            output = self.L3.forward(hidden_states[-1])\n",
    "            output = self.SM.forward(output)\n",
    "            \n",
    "            return output\n",
    "            \n",
    "    def backward(self, label, mode = \"No_Dropout\"):\n",
    "        if mode == \"No_Dropout\":\n",
    "            dout = self.SM.back_prop(label)\n",
    "            dout = self.L3.back_prop(dout)\n",
    "            \n",
    "            dh = self.R2.back_prop(dout)\n",
    "\n",
    "            dh = self.R1.back_prop(dh)\n",
    "            \n",
    "        else:\n",
    "            dout = self.SM.back_prop(label)\n",
    "            dout = self.L3.back_prop(dout)\n",
    "            \n",
    "            dh = self.Drop2.back_prop(dout)\n",
    "            dh = self.R2.back_prop(dh)\n",
    "            \n",
    "            dh = self.Drop1.back_prop(dh)\n",
    "            dh = self.R1.back_prop(dh)\n",
    "            \n",
    "    def update(self):\n",
    "        self.L3.update()\n",
    "        self.R2.update()\n",
    "        self.R1.update()\n",
    "        \n",
    "        \n",
    "    def clear_optim(self):\n",
    "        self.L3.clear_optim()\n",
    "        self.R2.clear_optim()\n",
    "        self.R1.clear_optim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "class LSTM(): \n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, optimizer, p, lr, beta1, beta2):\n",
    "        self.optimizer = optimizer\n",
    "        self.LSTM1 = LSTM_Cell(input_size, hidden_size1, optimizer, lr, beta1, beta2)\n",
    "        self.Drop1 = Dropout(p)\n",
    "        \n",
    "        self.LSTM2 = LSTM_Cell(hidden_size1, hidden_size2, optimizer, lr, beta1, beta2)\n",
    "        self.Drop2 = Dropout(p)\n",
    "        \n",
    "        self.L3 = LinearLayer(hidden_size2, 5, optimizer, lr, beta1, beta2)\n",
    "        self.SM = SoftMax()\n",
    "        \n",
    "    def forward(self, x, mode = \"No_Dropout\", train_activation = True):\n",
    "        if mode == \"No_Dropout\":\n",
    "            hidden_states = self.LSTM1.forward(x)\n",
    "            hidden_states = self.LSTM2.forward(hidden_states)\n",
    "            \n",
    "            output = self.L3.forward(hidden_states[-1])\n",
    "            output = self.SM.forward(output)\n",
    "            \n",
    "            return output\n",
    "        else:\n",
    "            hidden_states = self.LSTM1.forward(x)\n",
    "            hidden_states = self.Drop1.forward(hidden_states, train_activation)\n",
    "            \n",
    "            hidden_states = self.LSTM2.forward(hidden_states)\n",
    "            hidden_states = self.Drop2.forward(hidden_states, train_activation)\n",
    "            \n",
    "            output = self.L3.forward(hidden_states[-1])\n",
    "            output = self.SM.forward(output)\n",
    "            \n",
    "            return output\n",
    "            \n",
    "    def backward(self, label, mode = \"No_Dropout\"):\n",
    "        if mode == \"No_Dropout\":\n",
    "            dout = self.SM.back_prop(label)\n",
    "            dout = self.L3.back_prop(dout)\n",
    "            \n",
    "            dh = self.LSTM2.back_prop(dout)\n",
    "\n",
    "            dh = self.LSTM1.back_prop(dh)\n",
    "        else:\n",
    "            dout = self.SM.back_prop(label)\n",
    "            dout = self.L3.back_prop(dout)\n",
    "            \n",
    "            dh = self.Drop2.back_prop(dout)\n",
    "            dh = self.LSTM2.back_prop(dh)\n",
    "            \n",
    "            dh = self.Drop1.back_prop(dh)\n",
    "            dh = self.LSTM1.back_prop(dh)            \n",
    "        \n",
    "    def update(self):\n",
    "        self.L3.update()\n",
    "        self.LSTM2.update()\n",
    "        self.LSTM1.update()\n",
    "        \n",
    "    def clear_optim(self):\n",
    "        self.L3.clear_optim()\n",
    "        self.LSTM2.clear_optim()\n",
    "        self.LSTM1.clear_optim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, LSTM Train PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set common params\n",
    "\n",
    "epochs = 100\n",
    "lr = 1e-2\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  50\n",
      "================================================\n",
      "gt:     3\n",
      "output: [4]\n",
      "Train || 1 epoch | loss:1.51838 | cnt: 42.0 | acc: 31.81818\n",
      "================================================\n",
      "Train || 2 epoch | loss:1.10416 | cnt: 71.0 | acc: 53.78788\n",
      "================================================\n",
      "Train || 3 epoch | loss:0.84933 | cnt: 95.0 | acc: 71.96970\n",
      "================================================\n",
      "Train || 4 epoch | loss:0.66239 | cnt: 108.0 | acc: 81.81818\n",
      "================================================\n",
      "Train || 5 epoch | loss:0.52310 | cnt: 116.0 | acc: 87.87879\n",
      "================================================\n",
      "Train || 6 epoch | loss:0.42035 | cnt: 118.0 | acc: 89.39394\n",
      "================================================\n",
      "Train || 7 epoch | loss:0.33124 | cnt: 122.0 | acc: 92.42424\n",
      "================================================\n",
      "Train || 8 epoch | loss:0.24758 | cnt: 126.0 | acc: 95.45455\n",
      "================================================\n",
      "Train || 9 epoch | loss:0.17239 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 10 epoch | loss:0.11653 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 11 epoch | loss:0.08570 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 12 epoch | loss:0.06623 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 13 epoch | loss:0.05325 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 14 epoch | loss:0.04396 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 15 epoch | loss:0.03717 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 16 epoch | loss:0.03213 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 17 epoch | loss:0.02824 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 18 epoch | loss:0.02513 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 19 epoch | loss:0.02259 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 20 epoch | loss:0.02046 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 21 epoch | loss:0.01864 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 22 epoch | loss:0.01707 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 23 epoch | loss:0.01570 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 24 epoch | loss:0.01450 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 25 epoch | loss:0.01343 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 26 epoch | loss:0.01248 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 27 epoch | loss:0.01164 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 28 epoch | loss:0.01088 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 29 epoch | loss:0.01020 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 30 epoch | loss:0.00959 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 31 epoch | loss:0.00904 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 32 epoch | loss:0.00854 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 33 epoch | loss:0.00808 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 34 epoch | loss:0.00766 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 35 epoch | loss:0.00728 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 36 epoch | loss:0.00693 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 37 epoch | loss:0.00661 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 38 epoch | loss:0.00631 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 39 epoch | loss:0.00604 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 40 epoch | loss:0.00578 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 41 epoch | loss:0.00555 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 42 epoch | loss:0.00533 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 43 epoch | loss:0.00512 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 44 epoch | loss:0.00493 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 45 epoch | loss:0.00475 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 46 epoch | loss:0.00459 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 47 epoch | loss:0.00443 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 48 epoch | loss:0.00428 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 49 epoch | loss:0.00414 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 50 epoch | loss:0.00401 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 51 epoch | loss:0.00389 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 52 epoch | loss:0.00377 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 53 epoch | loss:0.00366 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 54 epoch | loss:0.00356 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 55 epoch | loss:0.00346 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 56 epoch | loss:0.00337 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 57 epoch | loss:0.00328 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 58 epoch | loss:0.00319 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 59 epoch | loss:0.00311 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 60 epoch | loss:0.00304 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 61 epoch | loss:0.00296 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 62 epoch | loss:0.00290 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 63 epoch | loss:0.00283 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 64 epoch | loss:0.00276 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 65 epoch | loss:0.00270 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 66 epoch | loss:0.00264 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 67 epoch | loss:0.00259 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 68 epoch | loss:0.00253 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 69 epoch | loss:0.00248 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 70 epoch | loss:0.00243 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 71 epoch | loss:0.00239 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 72 epoch | loss:0.00234 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 73 epoch | loss:0.00229 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 74 epoch | loss:0.00225 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 75 epoch | loss:0.00221 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 76 epoch | loss:0.00217 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 77 epoch | loss:0.00213 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 78 epoch | loss:0.00210 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 79 epoch | loss:0.00206 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 80 epoch | loss:0.00203 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 81 epoch | loss:0.00199 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 82 epoch | loss:0.00196 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 83 epoch | loss:0.00193 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 84 epoch | loss:0.00190 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 85 epoch | loss:0.00187 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 86 epoch | loss:0.00184 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 87 epoch | loss:0.00181 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 88 epoch | loss:0.00178 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 89 epoch | loss:0.00176 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 90 epoch | loss:0.00173 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 91 epoch | loss:0.00171 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 92 epoch | loss:0.00168 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 93 epoch | loss:0.00166 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 94 epoch | loss:0.00164 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 95 epoch | loss:0.00161 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 96 epoch | loss:0.00159 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 97 epoch | loss:0.00157 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 98 epoch | loss:0.00155 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 99 epoch | loss:0.00153 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 100 epoch | loss:0.00151 | cnt: 132.0 | acc: 100.00000\n",
      "Test || 100 epoch | loss:1.12674 | cnt: 45.0 | acc: 80.35714285714286\n"
     ]
    }
   ],
   "source": [
    "# RNN + SGD + 50d experiment(a)\n",
    "\n",
    "# set for experiments\n",
    "train_dataset = train_x_emb_50\n",
    "test_dataset = test_x_emb_50\n",
    "input_size = 50     # embedding dimension\n",
    "optimizer = \"SGD\"\n",
    "p = 0.5     # Drop Rate\n",
    "model = RNN(input_size, hidden_size1, hidden_size2, optimizer, p, lr, beta1, beta2)\n",
    "a_train_loss_list = []\n",
    "a_test_loss_list = []\n",
    "a_train_acc_list = []\n",
    "a_test_acc_list = []\n",
    "a_test_emoji = []\n",
    "train_mode = \"No_Dropout\"\n",
    "\n",
    "criterion = Cross_Entropy() \n",
    "train_dataset_size = train_dataset.shape[0]\n",
    "test_dataset_size = test_dataset.shape[0]\n",
    "\n",
    "print(\"input size: \", input_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_cnt = 0\n",
    "    train_total_loss = 0\n",
    "    # Train\n",
    "    print(\"================================================\")    \n",
    "    for idx, sentence in enumerate(train_dataset):\n",
    "        output = model.forward(sentence, train_mode)    \n",
    "        # print(\"output's shape: {}\".format(output.shape))\n",
    "        loss = criterion.forward(output, train_y[idx])\n",
    "        if epoch % 10 == 0 and idx == 0:\n",
    "            print(\"gt:    \", train_y[idx])\n",
    "            print(\"output:\", np.argmax(output, axis=1))\n",
    "        train_cnt += (np.argmax(output, axis=1) == train_y[idx]).astype(np.float16).sum()\n",
    "        train_total_loss += loss\n",
    "        model.backward(train_y[idx])\n",
    "        model.update()\n",
    "    train_total_loss /= train_dataset_size\n",
    "    train_acc = train_cnt * 100/ train_dataset_size\n",
    "    \n",
    "    a_train_loss_list.append(train_total_loss)\n",
    "    a_train_acc_list.append(train_acc)\n",
    "    \n",
    "    print(\"Train || {} epoch | loss:{:.5f} | cnt: {} | acc: {:.5f}\".format(epoch+1, train_total_loss, train_cnt, train_acc))   \n",
    "\n",
    "test_cnt = 0\n",
    "test_total_loss = 0\n",
    "# Test\n",
    "for idx, sentence in enumerate(test_dataset):\n",
    "    output = model.forward(sentence)    \n",
    "    # print(\"output's shape: {}\".format(output.shape))\n",
    "    a_test_emoji.append(np.argmax(output, axis=1))\n",
    "    \n",
    "    loss = criterion.forward(output, test_y[idx])\n",
    "    if epoch % 10 == 0 and idx == 0:\n",
    "        print(\"gt:    \", test_y[idx])\n",
    "        print(\"output:\", np.argmax(output, axis=1))\n",
    "    test_cnt += (np.argmax(output, axis=1) == test_y[idx]).astype(np.float16).sum()\n",
    "    test_total_loss += loss\n",
    "\n",
    "test_total_loss /= test_dataset_size\n",
    "test_acc = test_cnt * 100/ test_dataset_size\n",
    "\n",
    "a_test_loss_list.append(test_total_loss)\n",
    "a_test_acc_list.append(test_acc)\n",
    "print(\"Test || {} epoch | loss:{:.5f} | cnt: {} | acc: {}\".format(epoch+1, test_total_loss, test_cnt, test_acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  50\n",
      "================================================\n",
      "gt:     3\n",
      "output: [2]\n",
      "Train || 1 epoch | loss:1.57909 | cnt: 38.0 | acc: 28.78788\n",
      "================================================\n",
      "Train || 2 epoch | loss:1.55372 | cnt: 52.0 | acc: 39.39394\n",
      "================================================\n",
      "Train || 3 epoch | loss:1.53633 | cnt: 52.0 | acc: 39.39394\n",
      "================================================\n",
      "Train || 4 epoch | loss:1.52068 | cnt: 53.0 | acc: 40.15152\n",
      "================================================\n",
      "Train || 5 epoch | loss:1.50444 | cnt: 55.0 | acc: 41.66667\n",
      "================================================\n",
      "Train || 6 epoch | loss:1.48649 | cnt: 56.0 | acc: 42.42424\n",
      "================================================\n",
      "Train || 7 epoch | loss:1.46603 | cnt: 56.0 | acc: 42.42424\n",
      "================================================\n",
      "Train || 8 epoch | loss:1.44234 | cnt: 56.0 | acc: 42.42424\n",
      "================================================\n",
      "Train || 9 epoch | loss:1.41476 | cnt: 57.0 | acc: 43.18182\n",
      "================================================\n",
      "Train || 10 epoch | loss:1.38272 | cnt: 61.0 | acc: 46.21212\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 11 epoch | loss:1.34599 | cnt: 64.0 | acc: 48.48485\n",
      "================================================\n",
      "Train || 12 epoch | loss:1.30463 | cnt: 67.0 | acc: 50.75758\n",
      "================================================\n",
      "Train || 13 epoch | loss:1.25898 | cnt: 68.0 | acc: 51.51515\n",
      "================================================\n",
      "Train || 14 epoch | loss:1.20935 | cnt: 73.0 | acc: 55.30303\n",
      "================================================\n",
      "Train || 15 epoch | loss:1.15613 | cnt: 77.0 | acc: 58.33333\n",
      "================================================\n",
      "Train || 16 epoch | loss:1.09996 | cnt: 80.0 | acc: 60.60606\n",
      "================================================\n",
      "Train || 17 epoch | loss:1.04188 | cnt: 80.0 | acc: 60.60606\n",
      "================================================\n",
      "Train || 18 epoch | loss:0.98346 | cnt: 87.0 | acc: 65.90909\n",
      "================================================\n",
      "Train || 19 epoch | loss:0.92650 | cnt: 89.0 | acc: 67.42424\n",
      "================================================\n",
      "Train || 20 epoch | loss:0.87214 | cnt: 94.0 | acc: 71.21212\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 21 epoch | loss:0.82098 | cnt: 97.0 | acc: 73.48485\n",
      "================================================\n",
      "Train || 22 epoch | loss:0.77284 | cnt: 101.0 | acc: 76.51515\n",
      "================================================\n",
      "Train || 23 epoch | loss:0.72715 | cnt: 100.0 | acc: 75.75758\n",
      "================================================\n",
      "Train || 24 epoch | loss:0.68260 | cnt: 102.0 | acc: 77.27273\n",
      "================================================\n",
      "Train || 25 epoch | loss:0.63994 | cnt: 104.0 | acc: 78.78788\n",
      "================================================\n",
      "Train || 26 epoch | loss:0.60089 | cnt: 105.0 | acc: 79.54545\n",
      "================================================\n",
      "Train || 27 epoch | loss:0.56602 | cnt: 107.0 | acc: 81.06061\n",
      "================================================\n",
      "Train || 28 epoch | loss:0.53922 | cnt: 109.0 | acc: 82.57576\n",
      "================================================\n",
      "Train || 29 epoch | loss:0.51247 | cnt: 111.0 | acc: 84.09091\n",
      "================================================\n",
      "Train || 30 epoch | loss:0.48611 | cnt: 112.0 | acc: 84.84848\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 31 epoch | loss:0.46129 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 32 epoch | loss:0.43792 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 33 epoch | loss:0.41322 | cnt: 114.0 | acc: 86.36364\n",
      "================================================\n",
      "Train || 34 epoch | loss:0.38761 | cnt: 114.0 | acc: 86.36364\n",
      "================================================\n",
      "Train || 35 epoch | loss:0.36262 | cnt: 116.0 | acc: 87.87879\n",
      "================================================\n",
      "Train || 36 epoch | loss:0.33886 | cnt: 119.0 | acc: 90.15152\n",
      "================================================\n",
      "Train || 37 epoch | loss:0.31668 | cnt: 121.0 | acc: 91.66667\n",
      "================================================\n",
      "Train || 38 epoch | loss:0.29584 | cnt: 122.0 | acc: 92.42424\n",
      "================================================\n",
      "Train || 39 epoch | loss:0.27627 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 40 epoch | loss:0.25776 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 41 epoch | loss:0.24056 | cnt: 124.0 | acc: 93.93939\n",
      "================================================\n",
      "Train || 42 epoch | loss:0.22450 | cnt: 125.0 | acc: 94.69697\n",
      "================================================\n",
      "Train || 43 epoch | loss:0.20967 | cnt: 125.0 | acc: 94.69697\n",
      "================================================\n",
      "Train || 44 epoch | loss:0.19569 | cnt: 126.0 | acc: 95.45455\n",
      "================================================\n",
      "Train || 45 epoch | loss:0.18222 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 46 epoch | loss:0.16926 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 47 epoch | loss:0.15637 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 48 epoch | loss:0.14408 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 49 epoch | loss:0.13273 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 50 epoch | loss:0.12285 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 51 epoch | loss:0.11427 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 52 epoch | loss:0.10594 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 53 epoch | loss:0.09712 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 54 epoch | loss:0.09098 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 55 epoch | loss:0.08525 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 56 epoch | loss:0.07982 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 57 epoch | loss:0.07522 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 58 epoch | loss:0.07119 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 59 epoch | loss:0.06749 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 60 epoch | loss:0.06407 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 61 epoch | loss:0.06095 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 62 epoch | loss:0.05813 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 63 epoch | loss:0.05556 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 64 epoch | loss:0.05321 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 65 epoch | loss:0.05104 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 66 epoch | loss:0.04906 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 67 epoch | loss:0.04722 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 68 epoch | loss:0.04548 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 69 epoch | loss:0.04386 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 70 epoch | loss:0.04239 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 71 epoch | loss:0.04110 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 72 epoch | loss:0.04001 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 73 epoch | loss:0.03910 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 74 epoch | loss:0.03866 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 75 epoch | loss:0.03849 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 76 epoch | loss:0.03732 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 77 epoch | loss:0.16532 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 78 epoch | loss:0.67411 | cnt: 108.0 | acc: 81.81818\n",
      "================================================\n",
      "Train || 79 epoch | loss:0.20702 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 80 epoch | loss:0.13827 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 81 epoch | loss:0.12491 | cnt: 126.0 | acc: 95.45455\n",
      "================================================\n",
      "Train || 82 epoch | loss:0.07522 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 83 epoch | loss:0.05461 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 84 epoch | loss:0.04473 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 85 epoch | loss:0.03914 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 86 epoch | loss:0.03560 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 87 epoch | loss:0.03293 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 88 epoch | loss:0.03082 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 89 epoch | loss:0.02905 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 90 epoch | loss:0.02755 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 91 epoch | loss:0.02623 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 92 epoch | loss:0.02507 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 93 epoch | loss:0.02402 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 94 epoch | loss:0.02306 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 95 epoch | loss:0.02219 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 96 epoch | loss:0.02138 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 97 epoch | loss:0.02062 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 98 epoch | loss:0.01991 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 99 epoch | loss:0.01925 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 100 epoch | loss:0.01863 | cnt: 132.0 | acc: 100.00000\n",
      "Test || 100 epoch | loss:0.88226 | cnt: 42.0 | acc: 75.0\n"
     ]
    }
   ],
   "source": [
    "# LSTM + SGD + 50d experiment(b)\n",
    "\n",
    "# set for experiments\n",
    "train_dataset = train_x_emb_50\n",
    "test_dataset = test_x_emb_50\n",
    "input_size = 50     # embedding dimension\n",
    "optimizer = \"SGD\"\n",
    "p = 0.5     # Drop Rate\n",
    "model = LSTM(input_size, hidden_size1, hidden_size2, optimizer, p, lr, beta1, beta2)\n",
    "b_train_loss_list = []\n",
    "b_test_loss_list = []\n",
    "b_train_acc_list = []\n",
    "b_test_acc_list = []\n",
    "b_test_emoji = []\n",
    "train_mode = \"No_Dropout\"\n",
    "\n",
    "criterion = Cross_Entropy() \n",
    "train_dataset_size = train_dataset.shape[0]\n",
    "test_dataset_size = test_dataset.shape[0]\n",
    "\n",
    "print(\"input size: \", input_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_cnt = 0\n",
    "    train_total_loss = 0\n",
    "\n",
    "    # Train\n",
    "    print(\"================================================\")    \n",
    "    for idx, sentence in enumerate(train_dataset):\n",
    "        output = model.forward(sentence, train_mode)    \n",
    "        # print(\"output's shape: {}\".format(output.shape))\n",
    "        loss = criterion.forward(output, train_y[idx])\n",
    "        if epoch % 10 == 0 and idx == 0:\n",
    "            print(\"gt:    \", train_y[idx])\n",
    "            print(\"output:\", np.argmax(output, axis=1))\n",
    "        train_cnt += (np.argmax(output, axis=1) == train_y[idx]).astype(np.float16).sum()\n",
    "        train_total_loss += loss\n",
    "        model.backward(train_y[idx])\n",
    "        model.update()\n",
    "    train_total_loss /= train_dataset_size\n",
    "    train_acc = train_cnt * 100/ train_dataset_size\n",
    "    \n",
    "    b_train_loss_list.append(train_total_loss)\n",
    "    b_train_acc_list.append(train_acc)\n",
    "\n",
    "    print(\"Train || {} epoch | loss:{:.5f} | cnt: {} | acc: {:.5f}\".format(epoch+1, train_total_loss, train_cnt, train_acc))   \n",
    "test_cnt = 0\n",
    "test_total_loss = 0\n",
    "\n",
    "# Test\n",
    "for idx, sentence in enumerate(test_dataset):\n",
    "    output = model.forward(sentence)    \n",
    "    # print(\"output's shape: {}\".format(output.shape))\n",
    "    b_test_emoji.append(np.argmax(output, axis=1))\n",
    "    \n",
    "    loss = criterion.forward(output, test_y[idx])\n",
    "    if epoch % 10 == 0 and idx == 0:\n",
    "        print(\"gt:    \", test_y[idx])\n",
    "        print(\"output:\", np.argmax(output, axis=1))\n",
    "    test_cnt += (np.argmax(output, axis=1) == test_y[idx]).astype(np.float16).sum()\n",
    "    test_total_loss += loss\n",
    "\n",
    "test_total_loss /= test_dataset_size\n",
    "test_acc = test_cnt * 100/ test_dataset_size\n",
    "\n",
    "b_test_loss_list.append(test_total_loss)\n",
    "b_test_acc_list.append(test_acc)\n",
    "print(\"Test || {} epoch | loss:{:.5f} | cnt: {} | acc: {}\".format(epoch+1, test_total_loss, test_cnt, test_acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  50\n",
      "================================================\n",
      "gt:     3\n",
      "output: [2]\n",
      "Train || 1 epoch | loss:1.48631 | cnt: 44.0 | acc: 33.33333\n",
      "================================================\n",
      "Train || 2 epoch | loss:1.17867 | cnt: 68.0 | acc: 51.51515\n",
      "================================================\n",
      "Train || 3 epoch | loss:0.92103 | cnt: 83.0 | acc: 62.87879\n",
      "================================================\n",
      "Train || 4 epoch | loss:0.73309 | cnt: 93.0 | acc: 70.45455\n",
      "================================================\n",
      "Train || 5 epoch | loss:0.33430 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 6 epoch | loss:0.31553 | cnt: 118.0 | acc: 89.39394\n",
      "================================================\n",
      "Train || 7 epoch | loss:0.26230 | cnt: 119.0 | acc: 90.15152\n",
      "================================================\n",
      "Train || 8 epoch | loss:0.26393 | cnt: 120.0 | acc: 90.90909\n",
      "================================================\n",
      "Train || 9 epoch | loss:0.19020 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 10 epoch | loss:0.19685 | cnt: 124.0 | acc: 93.93939\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 11 epoch | loss:0.17616 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 12 epoch | loss:0.26762 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 13 epoch | loss:0.09318 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 14 epoch | loss:0.13574 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 15 epoch | loss:0.32304 | cnt: 125.0 | acc: 94.69697\n",
      "================================================\n",
      "Train || 16 epoch | loss:0.10123 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 17 epoch | loss:0.01417 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 18 epoch | loss:0.24042 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 19 epoch | loss:0.16291 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 20 epoch | loss:0.06132 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 21 epoch | loss:0.15641 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 22 epoch | loss:0.02744 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 23 epoch | loss:0.25369 | cnt: 125.0 | acc: 94.69697\n",
      "================================================\n",
      "Train || 24 epoch | loss:0.04271 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 25 epoch | loss:0.04363 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 26 epoch | loss:0.02519 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 27 epoch | loss:0.16102 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 28 epoch | loss:0.71613 | cnt: 121.0 | acc: 91.66667\n",
      "================================================\n",
      "Train || 29 epoch | loss:0.35406 | cnt: 124.0 | acc: 93.93939\n",
      "================================================\n",
      "Train || 30 epoch | loss:0.13595 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 31 epoch | loss:0.06800 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 32 epoch | loss:0.04654 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 33 epoch | loss:0.00235 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 34 epoch | loss:0.04647 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 35 epoch | loss:0.01648 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 36 epoch | loss:0.17606 | cnt: 126.0 | acc: 95.45455\n",
      "================================================\n",
      "Train || 37 epoch | loss:0.06177 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 38 epoch | loss:0.00831 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 39 epoch | loss:0.34819 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 40 epoch | loss:0.66981 | cnt: 122.0 | acc: 92.42424\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 41 epoch | loss:0.34886 | cnt: 124.0 | acc: 93.93939\n",
      "================================================\n",
      "Train || 42 epoch | loss:0.09171 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 43 epoch | loss:0.00048 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 44 epoch | loss:0.01009 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 45 epoch | loss:0.05645 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 46 epoch | loss:0.20442 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 47 epoch | loss:0.40641 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 48 epoch | loss:0.19107 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 49 epoch | loss:0.37276 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 50 epoch | loss:0.14342 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 51 epoch | loss:0.46909 | cnt: 126.0 | acc: 95.45455\n",
      "================================================\n",
      "Train || 52 epoch | loss:0.21209 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 53 epoch | loss:0.20622 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 54 epoch | loss:0.09783 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 55 epoch | loss:0.13411 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 56 epoch | loss:0.11464 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 57 epoch | loss:0.00585 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 58 epoch | loss:0.07620 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 59 epoch | loss:0.00057 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 60 epoch | loss:0.08581 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 61 epoch | loss:0.00024 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 62 epoch | loss:0.21749 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 63 epoch | loss:0.10778 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 64 epoch | loss:0.00000 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 65 epoch | loss:0.00004 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 66 epoch | loss:0.15537 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 67 epoch | loss:0.13372 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 68 epoch | loss:0.01219 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 69 epoch | loss:0.09331 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 70 epoch | loss:0.33465 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 71 epoch | loss:0.07987 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 72 epoch | loss:0.11883 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 73 epoch | loss:0.11066 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 74 epoch | loss:0.19900 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 75 epoch | loss:0.07038 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 76 epoch | loss:0.00691 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 77 epoch | loss:0.00072 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 78 epoch | loss:0.15982 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 79 epoch | loss:0.05676 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 80 epoch | loss:0.51995 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 81 epoch | loss:0.26694 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 82 epoch | loss:0.01443 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 83 epoch | loss:0.11593 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 84 epoch | loss:0.04818 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 85 epoch | loss:0.18034 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 86 epoch | loss:0.31499 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 87 epoch | loss:0.00010 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 88 epoch | loss:0.07922 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 89 epoch | loss:0.03352 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 90 epoch | loss:0.09214 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 91 epoch | loss:0.00036 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 92 epoch | loss:0.10150 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 93 epoch | loss:0.18984 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 94 epoch | loss:0.03090 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 95 epoch | loss:0.17961 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 96 epoch | loss:0.44370 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 97 epoch | loss:0.02958 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 98 epoch | loss:0.11700 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 99 epoch | loss:0.11571 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 100 epoch | loss:0.09517 | cnt: 131.0 | acc: 99.24242\n",
      "Test || 100 epoch | loss:7.36207 | cnt: 37.0 | acc: 66.07142857142857\n"
     ]
    }
   ],
   "source": [
    "# LSTM + ADAM + 50d experiment(c)\n",
    "\n",
    "# set for experiments\n",
    "train_dataset = train_x_emb_50\n",
    "test_dataset = test_x_emb_50\n",
    "input_size = 50     # embedding dimension\n",
    "optimizer = \"ADAM\"\n",
    "p = 0.5\n",
    "model = LSTM(input_size, hidden_size1, hidden_size2, optimizer, p, lr, beta1, beta2)\n",
    "c_train_loss_list = []\n",
    "c_test_loss_list = []\n",
    "c_train_acc_list = []\n",
    "c_test_acc_list = []\n",
    "c_test_emoji = []\n",
    "train_mode = \"No_Dropout\"\n",
    "\n",
    "criterion = Cross_Entropy() \n",
    "train_dataset_size = train_dataset.shape[0]\n",
    "test_dataset_size = test_dataset.shape[0]\n",
    "\n",
    "print(\"input size: \", input_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_cnt = 0\n",
    "    train_total_loss = 0\n",
    "    model.clear_optim()\n",
    "    \n",
    "    # Train\n",
    "    print(\"================================================\")    \n",
    "    for idx, sentence in enumerate(train_dataset):\n",
    "        output = model.forward(sentence, train_mode)    \n",
    "        # print(\"output's shape: {}\".format(output.shape))\n",
    "        loss = criterion.forward(output, train_y[idx])\n",
    "        if epoch % 10 == 0 and idx == 0:\n",
    "            print(\"gt:    \", train_y[idx])\n",
    "            print(\"output:\", np.argmax(output, axis=1))\n",
    "        train_cnt += (np.argmax(output, axis=1) == train_y[idx]).astype(np.float16).sum()\n",
    "        train_total_loss += loss\n",
    "        model.backward(train_y[idx])\n",
    "        model.update()\n",
    "    train_total_loss /= train_dataset_size\n",
    "    train_acc = train_cnt * 100/ train_dataset_size\n",
    "    \n",
    "    c_train_loss_list.append(train_total_loss)\n",
    "    c_train_acc_list.append(train_acc)\n",
    "\n",
    "    print(\"Train || {} epoch | loss:{:.5f} | cnt: {} | acc: {:.5f}\".format(epoch+1, train_total_loss, train_cnt, train_acc))   \n",
    "\n",
    "# Test(Validataion)\n",
    "test_cnt = 0\n",
    "test_total_loss = 0\n",
    "for idx, sentence in enumerate(test_dataset):\n",
    "    output = model.forward(sentence)    \n",
    "    # print(\"output's shape: {}\".format(output.shape))\n",
    "    c_test_emoji.append(np.argmax(output, axis=1))\n",
    "    \n",
    "    loss = criterion.forward(output, test_y[idx])\n",
    "    if epoch % 10 == 0 and idx == 0:\n",
    "        print(\"gt:    \", test_y[idx])\n",
    "        print(\"output:\", np.argmax(output, axis=1))\n",
    "    test_cnt += (np.argmax(output, axis=1) == test_y[idx]).astype(np.float16).sum()\n",
    "    test_total_loss += loss\n",
    "\n",
    "test_total_loss /= test_dataset_size\n",
    "test_acc = test_cnt * 100/ test_dataset_size\n",
    "\n",
    "c_test_loss_list.append(test_total_loss)\n",
    "c_test_acc_list.append(test_acc)\n",
    "print(\"Test || {} epoch | loss:{:.5f} | cnt: {} | acc: {}\".format(epoch+1, test_total_loss, test_cnt, test_acc))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  100\n",
      "================================================\n",
      "gt:     3\n",
      "output: [0]\n",
      "Train || 1 epoch | loss:1.58258 | cnt: 34.0 | acc: 25.75758\n",
      "================================================\n",
      "Train || 2 epoch | loss:1.55040 | cnt: 48.0 | acc: 36.36364\n",
      "================================================\n",
      "Train || 3 epoch | loss:1.53048 | cnt: 50.0 | acc: 37.87879\n",
      "================================================\n",
      "Train || 4 epoch | loss:1.51308 | cnt: 50.0 | acc: 37.87879\n",
      "================================================\n",
      "Train || 5 epoch | loss:1.49503 | cnt: 52.0 | acc: 39.39394\n",
      "================================================\n",
      "Train || 6 epoch | loss:1.47486 | cnt: 54.0 | acc: 40.90909\n",
      "================================================\n",
      "Train || 7 epoch | loss:1.45154 | cnt: 55.0 | acc: 41.66667\n",
      "================================================\n",
      "Train || 8 epoch | loss:1.42409 | cnt: 59.0 | acc: 44.69697\n",
      "================================================\n",
      "Train || 9 epoch | loss:1.39170 | cnt: 64.0 | acc: 48.48485\n",
      "================================================\n",
      "Train || 10 epoch | loss:1.35397 | cnt: 70.0 | acc: 53.03030\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 11 epoch | loss:1.31106 | cnt: 72.0 | acc: 54.54545\n",
      "================================================\n",
      "Train || 12 epoch | loss:1.26361 | cnt: 76.0 | acc: 57.57576\n",
      "================================================\n",
      "Train || 13 epoch | loss:1.21185 | cnt: 77.0 | acc: 58.33333\n",
      "================================================\n",
      "Train || 14 epoch | loss:1.15557 | cnt: 81.0 | acc: 61.36364\n",
      "================================================\n",
      "Train || 15 epoch | loss:1.09436 | cnt: 86.0 | acc: 65.15152\n",
      "================================================\n",
      "Train || 16 epoch | loss:1.02741 | cnt: 90.0 | acc: 68.18182\n",
      "================================================\n",
      "Train || 17 epoch | loss:0.95351 | cnt: 94.0 | acc: 71.21212\n",
      "================================================\n",
      "Train || 18 epoch | loss:0.87398 | cnt: 96.0 | acc: 72.72727\n",
      "================================================\n",
      "Train || 19 epoch | loss:0.79535 | cnt: 99.0 | acc: 75.00000\n",
      "================================================\n",
      "Train || 20 epoch | loss:0.72535 | cnt: 100.0 | acc: 75.75758\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 21 epoch | loss:0.66664 | cnt: 104.0 | acc: 78.78788\n",
      "================================================\n",
      "Train || 22 epoch | loss:0.61636 | cnt: 107.0 | acc: 81.06061\n",
      "================================================\n",
      "Train || 23 epoch | loss:0.57489 | cnt: 109.0 | acc: 82.57576\n",
      "================================================\n",
      "Train || 24 epoch | loss:0.53745 | cnt: 112.0 | acc: 84.84848\n",
      "================================================\n",
      "Train || 25 epoch | loss:0.49853 | cnt: 116.0 | acc: 87.87879\n",
      "================================================\n",
      "Train || 26 epoch | loss:0.45953 | cnt: 115.0 | acc: 87.12121\n",
      "================================================\n",
      "Train || 27 epoch | loss:0.41901 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 28 epoch | loss:0.37841 | cnt: 118.0 | acc: 89.39394\n",
      "================================================\n",
      "Train || 29 epoch | loss:0.35837 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 30 epoch | loss:0.32903 | cnt: 120.0 | acc: 90.90909\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 31 epoch | loss:0.30605 | cnt: 120.0 | acc: 90.90909\n",
      "================================================\n",
      "Train || 32 epoch | loss:0.28313 | cnt: 120.0 | acc: 90.90909\n",
      "================================================\n",
      "Train || 33 epoch | loss:0.25464 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 34 epoch | loss:0.23543 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 35 epoch | loss:0.21699 | cnt: 123.0 | acc: 93.18182\n",
      "================================================\n",
      "Train || 36 epoch | loss:0.20080 | cnt: 124.0 | acc: 93.93939\n",
      "================================================\n",
      "Train || 37 epoch | loss:0.18506 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 38 epoch | loss:0.16967 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 39 epoch | loss:0.15437 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "Train || 40 epoch | loss:0.13906 | cnt: 128.0 | acc: 96.96970\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 41 epoch | loss:0.12577 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 42 epoch | loss:0.11266 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 43 epoch | loss:0.10059 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 44 epoch | loss:0.09229 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 45 epoch | loss:0.08706 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 46 epoch | loss:0.09217 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 47 epoch | loss:0.12483 | cnt: 127.0 | acc: 96.21212\n",
      "================================================\n",
      "Train || 48 epoch | loss:0.08653 | cnt: 129.0 | acc: 97.72727\n",
      "================================================\n",
      "Train || 49 epoch | loss:0.07514 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 50 epoch | loss:0.06939 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 51 epoch | loss:0.21902 | cnt: 122.0 | acc: 92.42424\n",
      "================================================\n",
      "Train || 52 epoch | loss:0.44259 | cnt: 114.0 | acc: 86.36364\n",
      "================================================\n",
      "Train || 53 epoch | loss:0.09427 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 54 epoch | loss:0.07397 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 55 epoch | loss:0.05806 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 56 epoch | loss:0.05232 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 57 epoch | loss:0.04835 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 58 epoch | loss:0.04500 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 59 epoch | loss:0.04216 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 60 epoch | loss:0.03964 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 61 epoch | loss:0.03738 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 62 epoch | loss:0.03535 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 63 epoch | loss:0.03351 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 64 epoch | loss:0.03184 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 65 epoch | loss:0.03034 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 66 epoch | loss:0.02898 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 67 epoch | loss:0.02775 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 68 epoch | loss:0.02665 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 69 epoch | loss:0.02570 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 70 epoch | loss:0.02491 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 71 epoch | loss:0.02438 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 72 epoch | loss:0.02443 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 73 epoch | loss:0.02728 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 74 epoch | loss:0.04526 | cnt: 130.0 | acc: 98.48485\n",
      "================================================\n",
      "Train || 75 epoch | loss:0.34125 | cnt: 120.0 | acc: 90.90909\n",
      "================================================\n",
      "Train || 76 epoch | loss:0.20926 | cnt: 125.0 | acc: 94.69697\n",
      "================================================\n",
      "Train || 77 epoch | loss:0.04904 | cnt: 131.0 | acc: 99.24242\n",
      "================================================\n",
      "Train || 78 epoch | loss:0.03133 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 79 epoch | loss:0.02769 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 80 epoch | loss:0.02585 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 81 epoch | loss:0.02456 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 82 epoch | loss:0.02335 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 83 epoch | loss:0.02192 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 84 epoch | loss:0.02037 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 85 epoch | loss:0.01901 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 86 epoch | loss:0.01792 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 87 epoch | loss:0.01703 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 88 epoch | loss:0.01624 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 89 epoch | loss:0.01553 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 90 epoch | loss:0.01489 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 91 epoch | loss:0.01429 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 92 epoch | loss:0.01375 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 93 epoch | loss:0.01324 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 94 epoch | loss:0.01278 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 95 epoch | loss:0.01235 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 96 epoch | loss:0.01194 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 97 epoch | loss:0.01156 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 98 epoch | loss:0.01121 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 99 epoch | loss:0.01088 | cnt: 132.0 | acc: 100.00000\n",
      "================================================\n",
      "Train || 100 epoch | loss:0.01057 | cnt: 132.0 | acc: 100.00000\n",
      "Test || 100 epoch | loss:1.19561 | cnt: 39.0 | acc: 69.64285714285714\n"
     ]
    }
   ],
   "source": [
    "# LSTM + SGD + 100d experiment(d)\n",
    "\n",
    "# set for experiments\n",
    "train_dataset = train_x_emb_100\n",
    "test_dataset = test_x_emb_100\n",
    "input_size = 100     # embedding dimension\n",
    "optimizer = \"SGD\"\n",
    "p = 0.5\n",
    "model = LSTM(input_size, hidden_size1, hidden_size2,  optimizer, p, lr, beta1, beta2)\n",
    "d_train_loss_list = []\n",
    "d_test_loss_list = []\n",
    "d_train_acc_list = []\n",
    "d_test_acc_list = []\n",
    "d_test_emoji = []\n",
    "train_mode = \"No_Dropout\"\n",
    "\n",
    "criterion = Cross_Entropy() \n",
    "train_dataset_size = train_dataset.shape[0]\n",
    "test_dataset_size = test_dataset.shape[0]\n",
    "\n",
    "print(\"input size: \", input_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_cnt = 0\n",
    "    train_total_loss = 0\n",
    "\n",
    "    # Train\n",
    "    print(\"================================================\")    \n",
    "    for idx, sentence in enumerate(train_dataset):\n",
    "        output = model.forward(sentence, train_mode)    \n",
    "        # print(\"output's shape: {}\".format(output.shape))\n",
    "        loss = criterion.forward(output, train_y[idx])\n",
    "        if epoch % 10 == 0 and idx == 0:\n",
    "            print(\"gt:    \", train_y[idx])\n",
    "            print(\"output:\", np.argmax(output, axis=1))\n",
    "        train_cnt += (np.argmax(output, axis=1) == train_y[idx]).astype(np.float16).sum()\n",
    "        train_total_loss += loss\n",
    "        model.backward(train_y[idx])\n",
    "        model.update()\n",
    "    train_total_loss /= train_dataset_size\n",
    "    train_acc = train_cnt * 100/ train_dataset_size\n",
    "    \n",
    "    d_train_loss_list.append(train_total_loss)\n",
    "    d_train_acc_list.append(train_acc)\n",
    "\n",
    "    print(\"Train || {} epoch | loss:{:.5f} | cnt: {} | acc: {:.5f}\".format(epoch+1, train_total_loss, train_cnt, train_acc))   \n",
    "\n",
    "# Test\n",
    "test_cnt = 0\n",
    "test_total_loss = 0\n",
    "for idx, sentence in enumerate(test_dataset):\n",
    "    output = model.forward(sentence)    \n",
    "    # print(\"output's shape: {}\".format(output.shape))\n",
    "    d_test_emoji.append(np.argmax(output, axis=1))\n",
    "    \n",
    "    loss = criterion.forward(output, test_y[idx])\n",
    "    if epoch % 10 == 0 and idx == 0:\n",
    "        print(\"gt:    \", test_y[idx])\n",
    "        print(\"output:\", np.argmax(output, axis=1))\n",
    "    test_cnt += (np.argmax(output, axis=1) == test_y[idx]).astype(np.float16).sum()\n",
    "    test_total_loss += loss\n",
    "\n",
    "test_total_loss /= test_dataset_size\n",
    "test_acc = test_cnt * 100/ test_dataset_size\n",
    "\n",
    "d_test_loss_list.append(test_total_loss)\n",
    "d_test_acc_list.append(test_acc)\n",
    "print(\"Test || {} epoch | loss:{:.5f} | cnt: {} | acc: {}\".format(epoch+1, test_total_loss, test_cnt, test_acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  50\n",
      "================================================\n",
      "gt:     3\n",
      "output: [2]\n",
      "Train || 1 epoch | loss:1.58454 | cnt: 38.0 | acc: 28.78788\n",
      "================================================\n",
      "Train || 2 epoch | loss:1.57397 | cnt: 38.0 | acc: 28.78788\n",
      "================================================\n",
      "Train || 3 epoch | loss:1.56471 | cnt: 38.0 | acc: 28.78788\n",
      "================================================\n",
      "Train || 4 epoch | loss:1.55572 | cnt: 39.0 | acc: 29.54545\n",
      "================================================\n",
      "Train || 5 epoch | loss:1.55212 | cnt: 40.0 | acc: 30.30303\n",
      "================================================\n",
      "Train || 6 epoch | loss:1.54825 | cnt: 46.0 | acc: 34.84848\n",
      "================================================\n",
      "Train || 7 epoch | loss:1.54685 | cnt: 44.0 | acc: 33.33333\n",
      "================================================\n",
      "Train || 8 epoch | loss:1.54723 | cnt: 46.0 | acc: 34.84848\n",
      "================================================\n",
      "Train || 9 epoch | loss:1.54526 | cnt: 49.0 | acc: 37.12121\n",
      "================================================\n",
      "Train || 10 epoch | loss:1.53475 | cnt: 49.0 | acc: 37.12121\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 11 epoch | loss:1.54138 | cnt: 43.0 | acc: 32.57576\n",
      "================================================\n",
      "Train || 12 epoch | loss:1.53248 | cnt: 44.0 | acc: 33.33333\n",
      "================================================\n",
      "Train || 13 epoch | loss:1.53183 | cnt: 49.0 | acc: 37.12121\n",
      "================================================\n",
      "Train || 14 epoch | loss:1.52680 | cnt: 51.0 | acc: 38.63636\n",
      "================================================\n",
      "Train || 15 epoch | loss:1.52220 | cnt: 50.0 | acc: 37.87879\n",
      "================================================\n",
      "Train || 16 epoch | loss:1.52090 | cnt: 50.0 | acc: 37.87879\n",
      "================================================\n",
      "Train || 17 epoch | loss:1.50580 | cnt: 56.0 | acc: 42.42424\n",
      "================================================\n",
      "Train || 18 epoch | loss:1.50002 | cnt: 51.0 | acc: 38.63636\n",
      "================================================\n",
      "Train || 19 epoch | loss:1.48500 | cnt: 53.0 | acc: 40.15152\n",
      "================================================\n",
      "Train || 20 epoch | loss:1.49107 | cnt: 51.0 | acc: 38.63636\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 21 epoch | loss:1.47980 | cnt: 55.0 | acc: 41.66667\n",
      "================================================\n",
      "Train || 22 epoch | loss:1.45795 | cnt: 53.0 | acc: 40.15152\n",
      "================================================\n",
      "Train || 23 epoch | loss:1.45086 | cnt: 52.0 | acc: 39.39394\n",
      "================================================\n",
      "Train || 24 epoch | loss:1.42198 | cnt: 54.0 | acc: 40.90909\n",
      "================================================\n",
      "Train || 25 epoch | loss:1.41706 | cnt: 55.0 | acc: 41.66667\n",
      "================================================\n",
      "Train || 26 epoch | loss:1.37962 | cnt: 56.0 | acc: 42.42424\n",
      "================================================\n",
      "Train || 27 epoch | loss:1.38368 | cnt: 53.0 | acc: 40.15152\n",
      "================================================\n",
      "Train || 28 epoch | loss:1.35503 | cnt: 60.0 | acc: 45.45455\n",
      "================================================\n",
      "Train || 29 epoch | loss:1.35202 | cnt: 59.0 | acc: 44.69697\n",
      "================================================\n",
      "Train || 30 epoch | loss:1.32863 | cnt: 58.0 | acc: 43.93939\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 31 epoch | loss:1.32389 | cnt: 62.0 | acc: 46.96970\n",
      "================================================\n",
      "Train || 32 epoch | loss:1.29280 | cnt: 67.0 | acc: 50.75758\n",
      "================================================\n",
      "Train || 33 epoch | loss:1.23377 | cnt: 68.0 | acc: 51.51515\n",
      "================================================\n",
      "Train || 34 epoch | loss:1.20133 | cnt: 72.0 | acc: 54.54545\n",
      "================================================\n",
      "Train || 35 epoch | loss:1.20068 | cnt: 74.0 | acc: 56.06061\n",
      "================================================\n",
      "Train || 36 epoch | loss:1.16502 | cnt: 74.0 | acc: 56.06061\n",
      "================================================\n",
      "Train || 37 epoch | loss:1.15144 | cnt: 77.0 | acc: 58.33333\n",
      "================================================\n",
      "Train || 38 epoch | loss:1.09997 | cnt: 77.0 | acc: 58.33333\n",
      "================================================\n",
      "Train || 39 epoch | loss:1.07312 | cnt: 83.0 | acc: 62.87879\n",
      "================================================\n",
      "Train || 40 epoch | loss:1.06998 | cnt: 80.0 | acc: 60.60606\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 41 epoch | loss:1.01687 | cnt: 85.0 | acc: 64.39394\n",
      "================================================\n",
      "Train || 42 epoch | loss:0.99840 | cnt: 81.0 | acc: 61.36364\n",
      "================================================\n",
      "Train || 43 epoch | loss:0.97829 | cnt: 80.0 | acc: 60.60606\n",
      "================================================\n",
      "Train || 44 epoch | loss:1.00135 | cnt: 83.0 | acc: 62.87879\n",
      "================================================\n",
      "Train || 45 epoch | loss:0.91055 | cnt: 89.0 | acc: 67.42424\n",
      "================================================\n",
      "Train || 46 epoch | loss:0.94343 | cnt: 90.0 | acc: 68.18182\n",
      "================================================\n",
      "Train || 47 epoch | loss:0.87020 | cnt: 88.0 | acc: 66.66667\n",
      "================================================\n",
      "Train || 48 epoch | loss:0.92416 | cnt: 87.0 | acc: 65.90909\n",
      "================================================\n",
      "Train || 49 epoch | loss:0.89629 | cnt: 92.0 | acc: 69.69697\n",
      "================================================\n",
      "Train || 50 epoch | loss:0.78467 | cnt: 99.0 | acc: 75.00000\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 51 epoch | loss:0.75640 | cnt: 97.0 | acc: 73.48485\n",
      "================================================\n",
      "Train || 52 epoch | loss:0.78253 | cnt: 95.0 | acc: 71.96970\n",
      "================================================\n",
      "Train || 53 epoch | loss:0.73431 | cnt: 101.0 | acc: 76.51515\n",
      "================================================\n",
      "Train || 54 epoch | loss:0.75670 | cnt: 97.0 | acc: 73.48485\n",
      "================================================\n",
      "Train || 55 epoch | loss:0.74474 | cnt: 99.0 | acc: 75.00000\n",
      "================================================\n",
      "Train || 56 epoch | loss:0.68342 | cnt: 101.0 | acc: 76.51515\n",
      "================================================\n",
      "Train || 57 epoch | loss:0.64742 | cnt: 103.0 | acc: 78.03030\n",
      "================================================\n",
      "Train || 58 epoch | loss:0.62717 | cnt: 102.0 | acc: 77.27273\n",
      "================================================\n",
      "Train || 59 epoch | loss:0.64993 | cnt: 103.0 | acc: 78.03030\n",
      "================================================\n",
      "Train || 60 epoch | loss:0.61644 | cnt: 102.0 | acc: 77.27273\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 61 epoch | loss:0.68222 | cnt: 102.0 | acc: 77.27273\n",
      "================================================\n",
      "Train || 62 epoch | loss:0.59651 | cnt: 106.0 | acc: 80.30303\n",
      "================================================\n",
      "Train || 63 epoch | loss:0.60818 | cnt: 107.0 | acc: 81.06061\n",
      "================================================\n",
      "Train || 64 epoch | loss:0.58434 | cnt: 107.0 | acc: 81.06061\n",
      "================================================\n",
      "Train || 65 epoch | loss:0.53364 | cnt: 109.0 | acc: 82.57576\n",
      "================================================\n",
      "Train || 66 epoch | loss:0.48301 | cnt: 115.0 | acc: 87.12121\n",
      "================================================\n",
      "Train || 67 epoch | loss:0.55882 | cnt: 107.0 | acc: 81.06061\n",
      "================================================\n",
      "Train || 68 epoch | loss:0.51964 | cnt: 111.0 | acc: 84.09091\n",
      "================================================\n",
      "Train || 69 epoch | loss:0.49699 | cnt: 110.0 | acc: 83.33333\n",
      "================================================\n",
      "Train || 70 epoch | loss:0.54000 | cnt: 105.0 | acc: 79.54545\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 71 epoch | loss:0.46868 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 72 epoch | loss:0.46783 | cnt: 108.0 | acc: 81.81818\n",
      "================================================\n",
      "Train || 73 epoch | loss:0.55642 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 74 epoch | loss:0.49583 | cnt: 108.0 | acc: 81.81818\n",
      "================================================\n",
      "Train || 75 epoch | loss:0.48083 | cnt: 110.0 | acc: 83.33333\n",
      "================================================\n",
      "Train || 76 epoch | loss:0.42680 | cnt: 110.0 | acc: 83.33333\n",
      "================================================\n",
      "Train || 77 epoch | loss:0.43945 | cnt: 112.0 | acc: 84.84848\n",
      "================================================\n",
      "Train || 78 epoch | loss:0.39343 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 79 epoch | loss:0.51373 | cnt: 110.0 | acc: 83.33333\n",
      "================================================\n",
      "Train || 80 epoch | loss:0.41946 | cnt: 115.0 | acc: 87.12121\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 81 epoch | loss:0.44458 | cnt: 118.0 | acc: 89.39394\n",
      "================================================\n",
      "Train || 82 epoch | loss:0.40734 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 83 epoch | loss:0.60389 | cnt: 105.0 | acc: 79.54545\n",
      "================================================\n",
      "Train || 84 epoch | loss:0.44564 | cnt: 114.0 | acc: 86.36364\n",
      "================================================\n",
      "Train || 85 epoch | loss:0.43012 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 86 epoch | loss:0.36674 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 87 epoch | loss:0.42376 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 88 epoch | loss:0.33522 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 89 epoch | loss:0.40507 | cnt: 113.0 | acc: 85.60606\n",
      "================================================\n",
      "Train || 90 epoch | loss:0.37123 | cnt: 119.0 | acc: 90.15152\n",
      "================================================\n",
      "gt:     3\n",
      "output: [3]\n",
      "Train || 91 epoch | loss:0.35558 | cnt: 115.0 | acc: 87.12121\n",
      "================================================\n",
      "Train || 92 epoch | loss:0.39546 | cnt: 110.0 | acc: 83.33333\n",
      "================================================\n",
      "Train || 93 epoch | loss:0.31150 | cnt: 118.0 | acc: 89.39394\n",
      "================================================\n",
      "Train || 94 epoch | loss:0.34196 | cnt: 111.0 | acc: 84.09091\n",
      "================================================\n",
      "Train || 95 epoch | loss:0.39605 | cnt: 117.0 | acc: 88.63636\n",
      "================================================\n",
      "Train || 96 epoch | loss:0.33981 | cnt: 116.0 | acc: 87.87879\n",
      "================================================\n",
      "Train || 97 epoch | loss:0.27808 | cnt: 120.0 | acc: 90.90909\n",
      "================================================\n",
      "Train || 98 epoch | loss:0.29137 | cnt: 118.0 | acc: 89.39394\n",
      "================================================\n",
      "Train || 99 epoch | loss:0.27311 | cnt: 124.0 | acc: 93.93939\n",
      "================================================\n",
      "Train || 100 epoch | loss:0.24006 | cnt: 120.0 | acc: 90.90909\n",
      "Test || 100 epoch | loss:1.62445 | cnt: 31.0 | acc: 55.357142857142854\n"
     ]
    }
   ],
   "source": [
    "# LSTM + SGD + 50d + dropout experiment(e)\n",
    "\n",
    "# set for experiments\n",
    "train_dataset = train_x_emb_50\n",
    "test_dataset = test_x_emb_50\n",
    "input_size = 50     # embedding dimension\n",
    "optimizer = \"SGD\"\n",
    "p = 0.5     # Drop Rate\n",
    "model = LSTM(input_size, hidden_size1, hidden_size2, optimizer, p, lr, beta1, beta2)\n",
    "e_train_loss_list = []\n",
    "e_test_loss_list = []\n",
    "e_train_acc_list = []\n",
    "e_test_acc_list = []\n",
    "e_test_emoji = []\n",
    "dropout = \"Dropout\"\n",
    "\n",
    "criterion = Cross_Entropy() \n",
    "train_dataset_size = train_dataset.shape[0]\n",
    "test_dataset_size = test_dataset.shape[0]\n",
    "\n",
    "print(\"input size: \", input_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_cnt = 0\n",
    "    train_total_loss = 0\n",
    "\n",
    "    # Train\n",
    "    print(\"================================================\")    \n",
    "    for idx, sentence in enumerate(train_dataset):\n",
    "        output = model.forward(sentence, dropout, True)    \n",
    "        # print(\"output's shape: {}\".format(output.shape))\n",
    "        loss = criterion.forward(output, train_y[idx])\n",
    "        if epoch % 10 == 0 and idx == 0:\n",
    "            print(\"gt:    \", train_y[idx])\n",
    "            print(\"output:\", np.argmax(output, axis=1))\n",
    "        train_cnt += (np.argmax(output, axis=1) == train_y[idx]).astype(np.float16).sum()\n",
    "        train_total_loss += loss\n",
    "        model.backward(train_y[idx])\n",
    "        model.update()\n",
    "    train_total_loss /= train_dataset_size\n",
    "    train_acc = train_cnt * 100/ train_dataset_size\n",
    "    \n",
    "    e_train_loss_list.append(train_total_loss)\n",
    "    e_train_acc_list.append(train_acc)\n",
    "\n",
    "    print(\"Train || {} epoch | loss:{:.5f} | cnt: {} | acc: {:.5f}\".format(epoch+1, train_total_loss, train_cnt, train_acc))   \n",
    "\n",
    "# Test\n",
    "test_cnt = 0\n",
    "test_total_loss = 0\n",
    "for idx, sentence in enumerate(test_dataset):\n",
    "    output = model.forward(sentence, dropout, False)    \n",
    "    # print(\"output's shape: {}\".format(output.shape))\n",
    "    e_test_emoji.append(np.argmax(output, axis=1))\n",
    "    \n",
    "    loss = criterion.forward(output, test_y[idx])\n",
    "    if epoch % 10 == 0 and idx == 0:\n",
    "        print(\"gt:    \", test_y[idx])\n",
    "        print(\"output:\", np.argmax(output, axis=1))\n",
    "    test_cnt += (np.argmax(output, axis=1) == test_y[idx]).astype(np.float16).sum()\n",
    "    test_total_loss += loss\n",
    "\n",
    "test_total_loss /= test_dataset_size\n",
    "test_acc = test_cnt * 100/ test_dataset_size\n",
    "\n",
    "e_test_loss_list.append(test_total_loss)\n",
    "e_test_acc_list.append(test_acc)\n",
    "print(\"Test || {} epoch | loss:{:.5f} | cnt: {} | acc: {}\".format(epoch+1, test_total_loss, test_cnt, test_acc))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"RNN+SGD+50d\", \"LSTM+SGD+50d\", \"LSTM+ADAM+50d\", \"LSTM+SGD+100d\", \"LSTM+SGD+50d+dropout\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy comparison for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN+SGD+50d</th>\n",
       "      <td>80.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM+SGD+50d</th>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM+ADAM+50d</th>\n",
       "      <td>66.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM+SGD+100d</th>\n",
       "      <td>69.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM+SGD+50d+dropout</th>\n",
       "      <td>55.357143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Test Accuracy\n",
       "RNN+SGD+50d               80.357143\n",
       "LSTM+SGD+50d              75.000000\n",
       "LSTM+ADAM+50d             66.071429\n",
       "LSTM+SGD+100d             69.642857\n",
       "LSTM+SGD+50d+dropout      55.357143"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test_acc = a_test_acc_list[0]\n",
    "b_test_acc = b_test_acc_list[0]\n",
    "c_test_acc = c_test_acc_list[0]\n",
    "d_test_acc = d_test_acc_list[0]\n",
    "e_test_acc = e_test_acc_list[0]\n",
    "acc_list = [a_test_acc, b_test_acc, c_test_acc, d_test_acc, e_test_acc]\n",
    "\n",
    "df = pd.DataFrame(acc_list, index = experiments, columns = [\"Test Accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All emojis for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN+SGD+50d</th>\n",
       "      <th>LSTM+SGD+50d</th>\n",
       "      <th>LSTM+ADAM+50d</th>\n",
       "      <th>LSTM+SGD+100d</th>\n",
       "      <th>LSTM+SGD+50d+dropout</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I want to eat</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he did not answer</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he got a very nice raise</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she got me a nice present</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha ha ha it was so funny</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he is a good friend</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am upset</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We had such a lovely dinner tonight</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where is the food</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop making this joke ha ha ha</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where is the ball</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work is hard</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This girl is messing with me</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are you serious</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Let us go play baseball</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This stupid grader is not working</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work is horrible</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congratulation for having a baby</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop pissing me off</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any suggestions for dinner</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love taking breaks</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you brighten my day</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I boiled rice</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she is a bully</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Why are you feeling bad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am upset</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give me the ball</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My grandmother is the love of my life</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy your game</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valentine day is near</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I miss you so much</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throw the ball</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My life is so boring</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she said yes</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will you be my valentine</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he can pitch really well</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dance with me</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am hungry</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>See you at the restaurant</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like to laugh</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I will  run</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like your jacket</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i miss her</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what is your favorite baseball game</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good job</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love you to the stars and back</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What you did was awesome</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha ha ha lol</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I do not want to joke</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go away</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday we lost again</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family is all I have</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you are failing this exercise</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good joke</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You deserve this nice prize</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I did not have breakfast</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      RNN+SGD+50d LSTM+SGD+50d LSTM+ADAM+50d  \\\n",
       "I want to eat                                                               \n",
       "he did not answer                                                           \n",
       "he got a very nice raise                                                   \n",
       "she got me a nice present                                                   \n",
       "ha ha ha it was so funny                                                    \n",
       "he is a good friend                                                        \n",
       "I am upset                                                                 \n",
       "We had such a lovely dinner tonight                                         \n",
       "where is the food                                                           \n",
       "Stop making this joke ha ha ha                                              \n",
       "where is the ball                                                           \n",
       "work is hard                                                               \n",
       "This girl is messing with me                                                \n",
       "are you serious                                                             \n",
       "Let us go play baseball                                                     \n",
       "This stupid grader is not working                                           \n",
       "work is horrible                                                            \n",
       "Congratulation for having a baby                                           \n",
       "stop pissing me off                                                         \n",
       "any suggestions for dinner                                                 \n",
       "I love taking breaks                                                      \n",
       "you brighten my day                                                         \n",
       "I boiled rice                                                               \n",
       "she is a bully                                                            \n",
       "Why are you feeling bad                                                     \n",
       "I am upset                                                                 \n",
       "give me the ball                                                            \n",
       "My grandmother is the love of my life                                       \n",
       "enjoy your game                                                             \n",
       "valentine day is near                                                      \n",
       "I miss you so much                                                       \n",
       "throw the ball                                                              \n",
       "My life is so boring                                                        \n",
       "she said yes                                                                \n",
       "will you be my valentine                                                   \n",
       "he can pitch really well                                                    \n",
       "dance with me                                                               \n",
       "I am hungry                                                                 \n",
       "See you at the restaurant                                                   \n",
       "I like to laugh                                                            \n",
       "I will  run                                                                \n",
       "I like your jacket                                                       \n",
       "i miss her                                                               \n",
       "what is your favorite baseball game                                         \n",
       "Good job                                                                    \n",
       "I love you to the stars and back                                           \n",
       "What you did was awesome                                                    \n",
       "ha ha ha lol                                                                \n",
       "I do not want to joke                                                      \n",
       "go away                                                                     \n",
       "yesterday we lost again                                                     \n",
       "family is all I have                                                       \n",
       "you are failing this exercise                                               \n",
       "Good joke                                                                   \n",
       "You deserve this nice prize                                                 \n",
       "I did not have breakfast                                                    \n",
       "\n",
       "                                      LSTM+SGD+100d LSTM+SGD+50d+dropout  \\\n",
       "I want to eat                                                            \n",
       "he did not answer                                                        \n",
       "he got a very nice raise                                                \n",
       "she got me a nice present                                                \n",
       "ha ha ha it was so funny                                                 \n",
       "he is a good friend                                                    \n",
       "I am upset                                                               \n",
       "We had such a lovely dinner tonight                                     \n",
       "where is the food                                                        \n",
       "Stop making this joke ha ha ha                                           \n",
       "where is the ball                                                        \n",
       "work is hard                                                             \n",
       "This girl is messing with me                                             \n",
       "are you serious                                                          \n",
       "Let us go play baseball                                                  \n",
       "This stupid grader is not working                                        \n",
       "work is horrible                                                         \n",
       "Congratulation for having a baby                                         \n",
       "stop pissing me off                                                      \n",
       "any suggestions for dinner                                               \n",
       "I love taking breaks                                                   \n",
       "you brighten my day                                                      \n",
       "I boiled rice                                                            \n",
       "she is a bully                                                         \n",
       "Why are you feeling bad                                                 \n",
       "I am upset                                                               \n",
       "give me the ball                                                         \n",
       "My grandmother is the love of my life                                  \n",
       "enjoy your game                                                          \n",
       "valentine day is near                                                    \n",
       "I miss you so much                                                     \n",
       "throw the ball                                                           \n",
       "My life is so boring                                                     \n",
       "she said yes                                                             \n",
       "will you be my valentine                                                 \n",
       "he can pitch really well                                                 \n",
       "dance with me                                                            \n",
       "I am hungry                                                              \n",
       "See you at the restaurant                                                \n",
       "I like to laugh                                                        \n",
       "I will  run                                                              \n",
       "I like your jacket                                                     \n",
       "i miss her                                                             \n",
       "what is your favorite baseball game                                      \n",
       "Good job                                                                 \n",
       "I love you to the stars and back                                       \n",
       "What you did was awesome                                                 \n",
       "ha ha ha lol                                                             \n",
       "I do not want to joke                                                  \n",
       "go away                                                                  \n",
       "yesterday we lost again                                                  \n",
       "family is all I have                                                     \n",
       "you are failing this exercise                                            \n",
       "Good joke                                                                \n",
       "You deserve this nice prize                                              \n",
       "I did not have breakfast                                                 \n",
       "\n",
       "                                      Ground Truth  \n",
       "I want to eat                                      \n",
       "he did not answer                                  \n",
       "he got a very nice raise                           \n",
       "she got me a nice present                          \n",
       "ha ha ha it was so funny                           \n",
       "he is a good friend                                \n",
       "I am upset                                         \n",
       "We had such a lovely dinner tonight                \n",
       "where is the food                                  \n",
       "Stop making this joke ha ha ha                     \n",
       "where is the ball                                  \n",
       "work is hard                                       \n",
       "This girl is messing with me                       \n",
       "are you serious                                    \n",
       "Let us go play baseball                            \n",
       "This stupid grader is not working                  \n",
       "work is horrible                                   \n",
       "Congratulation for having a baby                   \n",
       "stop pissing me off                                \n",
       "any suggestions for dinner                         \n",
       "I love taking breaks                              \n",
       "you brighten my day                                \n",
       "I boiled rice                                      \n",
       "she is a bully                                     \n",
       "Why are you feeling bad                            \n",
       "I am upset                                         \n",
       "give me the ball                                   \n",
       "My grandmother is the love of my life             \n",
       "enjoy your game                                    \n",
       "valentine day is near                              \n",
       "I miss you so much                                \n",
       "throw the ball                                     \n",
       "My life is so boring                               \n",
       "she said yes                                       \n",
       "will you be my valentine                           \n",
       "he can pitch really well                           \n",
       "dance with me                                      \n",
       "I am hungry                                        \n",
       "See you at the restaurant                          \n",
       "I like to laugh                                    \n",
       "I will  run                                        \n",
       "I like your jacket                                \n",
       "i miss her                                        \n",
       "what is your favorite baseball game                \n",
       "Good job                                           \n",
       "I love you to the stars and back                  \n",
       "What you did was awesome                           \n",
       "ha ha ha lol                                       \n",
       "I do not want to joke                              \n",
       "go away                                            \n",
       "yesterday we lost again                            \n",
       "family is all I have                              \n",
       "you are failing this exercise                      \n",
       "Good joke                                          \n",
       "You deserve this nice prize                        \n",
       "I did not have breakfast                           "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_emoji = [label_to_emoji(y_hat[0]) for y_hat in a_test_emoji]\n",
    "b_emoji = [label_to_emoji(y_hat[0]) for y_hat in b_test_emoji]\n",
    "c_emoji = [label_to_emoji(y_hat[0]) for y_hat in c_test_emoji]\n",
    "d_emoji = [label_to_emoji(y_hat[0]) for y_hat in d_test_emoji]\n",
    "e_emoji = [label_to_emoji(y_hat[0]) for y_hat in e_test_emoji]\n",
    "ground_truth_emoji = [label_to_emoji(label) for label in test_y]\n",
    "\n",
    "emojis = np.array([a_emoji, b_emoji, c_emoji, d_emoji, e_emoji, ground_truth_emoji]).T\n",
    "column = experiments.copy()\n",
    "column.append(\"Ground Truth\")\n",
    "sentences = [sentence.replace(\"\\t\", \"\") for sentence in test_x]\n",
    "\n",
    "test_emoji_df = pd.DataFrame(emojis, index = sentences, columns=column)\n",
    "test_emoji_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd1xWdfvA8c/3Xuw9ZMoQRVAUFTVnjspsuHNUZlqatm3vrJ5+ZfXU07BtaWZqWmnDbGjmSnPhxImobNl73uf3x40kiYoK3oDX+/Xixc0533POdRDhvs53XErTNIQQQgghhBBCNH06awcghBBCCCGEEKJ+SIInhBBCCCGEEM2EJHhCCCGEEEII0UxIgieEEEIIIYQQzYQkeEIIIYQQQgjRTEiCJ4QQQgghhBDNhCR4QgghmjSl1M9KqQkXeGyCUuqq+o6pMWjO9yaEEOLMDNYOQAghxOVHKVVwypf2QClQWfX1XZqmza/ruTRNG1yfsQkhhBBNmSR4QgghLjlN0xxPvlZKJQB3apr2+7/bKaUMmqZVXMrYGoPL9b6FEEJcPBmiKYQQotFQSvVTSiUqpR5XSqUCnyul3JRSPyqlTiilsqteB5xyzGql1J1Vr29XSq1TSr1R1faIUqpOPXxKKRul1P+UUslVH/9TStlU7fOsum6OUipLKbVWKaWr2ve4UipJKZWvlNqvlBp4hvN7KKV+UErlKaU2K6X+o5Rad8p+TSl1j1LqIHCwatvbSqnjVcdsVUr1OaX9DKXUEqXUoqprb1NKdfzXZaOVUjuVUrlV7Wzr9A8hhBCiyZIETwghRGPjA7gDQcAULH+rPq/6uiVQDLx3luO7A/sBT+A1YLZSStXhuk8DVwDRQEegG/BM1b6HgUTAC2gBPAVoSqlw4F6gq6ZpTsAgIOEM558FFFbd34Sqj38bVhV/ZNXXm6vicQe+Ahb/K0kbCiw+Zf9SpZTxlP2jgWuBEKADcPtZ7l8IIUQzIAmeEEKIxsYMPK9pWqmmacWapmVqmvaNpmlFmqblAy8DV57l+KOapn2iaVolMBfwxZKUncstwIuapqVrmnYCeAEYX7WvvOo8QZqmlWuatlbTNA3LvEEbIFIpZdQ0LUHTtMP/PrFSSg+MrLqvIk3T9lbF9m+vaJqWpWlaMYCmaV9W3X+Fpmn/rbpW+Cntt2qatkTTtHLgTcAWS5J60juapiVrmpYF/IAlWRRCCNGMSYInhBCisTmhaVrJyS+UUvZKqY+UUkeVUnnAGsC1KmmqTerJF5qmFVW9dDxD21P5AUdP+fpo1TaA14FDwK9KqXil1BNV5z8EPAjMANKVUguVUn6czgvLvPfjp2w7Xku7GtuUUo8opeKqhljmAC5YeiZPa69pmhlLL+Op10895XURdfs+CCGEaMIkwRNCCNHYaP/6+mEsvVbdNU1zBvpWba/LsMvzkYxlGOhJLau2oWlavqZpD2uaFgoMAR46OddO07SvNE3rXXWsBsys5dwngAog4JRtgbW0q773qvl2j2EZZummaZorkEvN+w48pb2u6vzJdblZIYQQzZMkeEIIIRo7Jyzz7nKUUu7A8w10nQXAM0opL6WUJ/Ac8CWAUuoGpVRY1Vy+XCxDM81KqXCl1ICqxVhKquI0//vEVcNFvwVmVPVItgVuO0c8TliSwhOAQSn1HOD8rzZdlFIjlFIGLD2JpcDGC7l5IYQQzYMkeEIIIRq7/wF2QAaW5GVFA13nP8AWYCewC9hWtQ2gNfA7UAD8BbyvadofWObEvVoVWyrgDTx5hvPfi2WIZSowD0tCWXqWeH7Bcq8HsAwXLeH0YZ3LgDFANpb5giOq5uMJIYS4TCnLHHEhhBBCXEpKqZmAj6Zpta2mWZfjZwBhmqbdWq+BCSGEaNKkB08IIYS4BJRSbZVSHZRFN+AO4DtrxyWEEKJ5MVg7ACGEEOIy4YRlWKYfkAb8F8sQSyGEEKLeyBBNIYQQQgghhGgmZIimEEIIIYQQQjQTkuAJIYQQQgghRDPR5ObgeXp6asHBwdYOQwghhBBCCCGsYuvWrRmapnnVtq/JJXjBwcFs2bLF2mEIIYQQQgghhFUopY6eaZ8M0RRCCCGEEEKIZkISPCGEEEIIIYRoJiTBE0IIIYQQQohmosnNwRNCCCGEEKK+lZeXk5iYSElJibVDEaKara0tAQEBGI3GOh/TYAmeUuoz4AYgXdO09mdo0w/4H2AEMjRNu7Kh4hFCCCGEEOJMEhMTcXJyIjg4GKWUtcMRAk3TyMzMJDExkZCQkDof15BDNOcA155pp1LKFXgfGKJpWjvgpgaMRQghhBBCiDMqKSnBw8NDkjvRaCil8PDwOO9e5QZL8DRNWwNknaXJzcC3mqYdq2qf3lCxCCGEEEIIcS6S3InG5kJ+Jq25yEobwE0ptVoptVUpdZsVYxFCCCGEEMKq9Ho90dHRtG/fnhtvvJGcnBwAEhISUErx7rvvVre99957mTNnDgC33347/v7+lJaWApCRkUFwcHCdr/vjjz/SqVMnOnbsSGRkJB999FH1vi+//JIOHTrQrl07OnbsyJ133lkdV79+/QgPD6dDhw60bduWe++9t3pfXcyYMQN/f3+io6OJjo5m+fLl1fteeeUVwsLCCA8P55dffjnj8W+88Uadr3e5sGaCZwC6ANcDg4BnlVJtamuolJqilNqilNpy4sSJSxmjEEIIIYQQl4SdnR2xsbHs3r0bd3d3Zs2aVb3P29ubt99+m7KyslqP1ev1fPbZZ2c9/5w5c5gxY0aNbeXl5UyZMoUffviBHTt2sH37dvr16wfAihUreOutt/j555/Zs2cP27Zto2fPnqSlpVUfP3/+fHbu3MnOnTuxsbFh6NChp1139erV3H777bXGNH36dGJjY4mNjeW6664DYO/evSxcuJA9e/awYsUK7r77biorK896b+If1kzwEoFfNE0r1DQtA1gDdKytoaZpH2uaFqNpWoyXl9clDbIu0g6cYO/Pe8lJK0LTNGuHI4QQQgghmrgePXqQlJRU/bWXlxcDBw5k7ty5tbZ/8MEHeeutt6ioqDiv6+Tn51NRUYGHhwcANjY2hIeHA/Dyyy/zxhtv4O/vD1iSyEmTJlXvP5XJZOK1117j2LFj7Nix47xi+Ldly5YxduxYbGxsCAkJISwsjL///rs6pjZt2tC7d2/2799/UddprqyZ4C0DeiulDEope6A7EGfFeC7Yzg+X8seyVOY/v5HZD6/lh3di2fRDPAm7MiguqP0pixBCCCGEELWprKxk5cqVDBkypMb2xx9/nDfeeKPW3qyWLVvSu3dv5s2bd17Xcnd3Z8iQIQQFBTFu3Djmz5+P2WwGYM+ePXTu3LnO59Lr9XTs2JF9+/bV+Zj33nuPDh06MGnSJLKzswFISkoiMDCwuk1AQABJSUls3bqVhQsXEhsby/Lly9m8eXOdr3M5acgyCQuAfoCnUioReB5LOQQ0TftQ07Q4pdQKYCdgBj7VNG13Q8XTkPr2SsT347mklYVT6B9Bvn1XjsdlcbIzz9nTFu9gZzwDHPEMdMIzwBEHFxvrBi2EEEIIIWr1wg972JucV6/njPRz5vkb2521TXFxMdHR0SQlJREREcHVV19dY39oaCjdu3fnq6++qvX4J598kqFDh3L99ddXb8vMzGTgwIEAZGVlUVZWxtKlSwGYN28eUVFRfPrpp+zatYvff/+dN954g99++616ft9Ju3btYvz48eTn5/N///d/jBkzptYYTh3N1r17d0pLSykoKCArK4vo6GgAZs6cyaBBg5g2bRrPPvssSimeffZZHn744bMOM127di3Dhw/H3t4e4LQEWFg0WIKnadq4OrR5HXi9oWK4VGxGvkC7HiMI+N+jpP28Dm37p7gO70vF6OdJT6kgLSGPtCN5HNryz0Kh9s4mPAMd8QxwqvrsiIu3PTqdrN4khBBCCHE5OjkHr6ioiEGDBjFr1izuv//+Gm2eeuopRo0axZVXnl4+unXr1kRHR/P1119Xb/Pw8CA2NhawzMFLSEg4bR4eQFRUFFFRUYwfP56QkBDmzJlDu3bt2LZtG/379ycqKorY2FjuvfdeiouLa42/srKSXbt2ERERAcCmTZsAyxy8OXPmnJY0tmjRovr15MmTueGGGwDw9/fn+PHj1fsSExPx9/cnMTHxDN85caoGS/AuN8qvI66v/YrDLb+T+uyTZC9Zi+3qgUQ+MJ7OdzwCBhtKCsvJTCog43gBGYn5ZCQWEPv7McyVlicdeqMODz8HPAIc8fC3JH0e/o7YOtS9cr0QQgghhLg45+ppa2j29va88847DBs2jLvvvrvGvrZt2xIZGckPP/xA165dTzv26aefrtGDdy4FBQVs2bKlemGV2NhYgoKCAEuP4COPPMKyZcsICAgAOGNyV15eztNPP01gYCAdOnSo07VTUlLw9fUF4LvvvqN9+/aApWfu5ptv5qGHHiI5OZmDBw/SrVs3bGxsuP3223nyySepqKjghx9+4K677qrzvV4uJMGrZ8aOVxGwbCD5X75D6lsfc+S5eXh+9yWeU6di22kM/m188G/jVt2+ssJMVkohmYkFZCQVkJlYwJEdGcStT6luY+9sws7JiK2DERsHy+fqD0cDto4m7BxPfm3Exs6Akp5AIYQQQogmq1OnTnTo0IEFCxbQp0+fGvuefvppOnXqVOtx7dq1o3Pnzmzbtq1O19E0jddee4277roLOzs7HBwcqnvarrvuOk6cOMHgwYOprKzE1dWV9u3bM2jQoOrjb7nlFmxsbCgtLeWqq65i2bJldb7Hxx57jNjYWJRSBAcHV5dnaNeuHaNHjyYyMhKDwcCsWbPQ6/V07tyZMWPG0LFjR7y9vWtNcAWoprbqY0xMjLZlyxZrh1EnFVlZpD31IHmrN2Owq8S1VTGu/aIw9roZIm4EW5daj9M0jaK8MjISLQlfTloRJYXllo8Cy+fSwgrM5tr/7ZROYetgSfxsHQwYbfToDbpTPhR6ox69QaHT6wANzWy5rqZVjZ3WQNNA6cBg0mM06TCY9DVf2+hxa2GPk4etFAYVQgghRJMWFxdXPbRQiMaktp9NpdRWTdNiamsvPXgNyODujv+HX+Cybj1Zn7xPxt/byNhzBMfvnsGt9eM4XNkf1XE0tL4GjLbVxymlcHCxwcHFhqB2HrWeW9M0yksqqxO/4oKq5K+gnOKCslNel1NSWEFlhZnKcrPl88mPcjPmSg2lFEoBOsvn6q8VaJUaFWXmMyaTAHZORloEO+Md7EyLEGe8g5xPG1ZaVlxB7oli8jKKyc0oJi+jBM2s4eHvgIe/DEUVQgghhBCiPkiCdwk49u6FY+9elCUmkvP11+R8vYiC1XkYt2zBNeQPXNoaMHYaBG1vgLCBYHI45zmVUpjsDJjsDDh72jX4PVRWmqkoM1NRVkl5aSUVZWbKSirISiqoXkQmYVdmdXvXFva4+dhTmFNKXkYJJYXlNc53Mpnbuy65epujm011sucR4ICtgxGdTqF0qvrzydc6g8Le2YStg1F6D4UQQgghhKgiQzStQCsrI3/VKrIXLqRo4ybQKRz9KnAOzMMpCHThAyxDONsMAnt3a4dbZ6XFFaQftSR76Ql55KQV4ehmg7OnHc5edrh42lW/trEzVA9FzUwssAxHTbJ8ZKcUnbXH8FQ6wz+9nQ6upqrPNji4mLB3tsHexfRPIijzEoUQQghxBjJEUzRW5ztEUxK8elBRaSajoAwfF9tzN/6XsoQEcpYsIffHH6lITUOZ9DgFVuLin4mDbwUqtLcl2Yu4EZx8GiD6xqeywkxOWhFlxZZ5hprZMkfw5GuzWaOywkxRXhmFOaUU5pZSmFNGUW4phTmllJWcXvxT6RR2TkbsnS2Jn8lWXz0fUXfK3ESdQYfRRo9/aze8g5wkKRRCCCEuE5LgicZKEjwreOXnOD5fl8C+l6694Dp2mtlM8dat5P7wI3krVmDOy0PvaINzcCXOLVKx8yxHBfWAdsMsyZ6zX/3eRDNSVlJBUW4ZRfllls95ZRTllVKUV0ZxXhmFuWWUl1ZSWWHGXGGmskKrnpd4smQFgL2LieAOnoR08CQg3A2DSW/FuxJCCCFEQ5IETzRWssiKFfi72lFWaSajoBRv5/PvxQNQOh32Xbti37UrPs88TcG69eT9+AM5q/4ge7cnRi8nXEJScNnzJCanxyDwCogcCpFDwCWgnu+oaTPZGjDZGnBtYX/ex2pmjZKico7tyeLIjhMc/DuNvWuTMZh0tIz0ILiDJ4ER7ji4mKR3TwghhBBCNDqS4NUDf1fLIieJOcUXnOCdSplMOA3oj9OA/lQWFJL/22/kfr+MjI2byNBaYNfKG5f0DJwPP4X+lychsDt0GAPthjepOXuNkdIp7BxNhHf3Iby7D5XlZpIOZHNkRwZHdmYQH3sCsMz9c3SzxcndBid3WxzdbXFyt8XJzRbPQEfsnExWvhMhhBBCNDWOjo4UFBTU2LZ//37uuusucnJyKC0tpU+fPowcOZLHH38cgEOHDuHv74+dnR0dOnRg0qRJ9O/fn08++YQ777wTsBQv79SpE6+//jqPPPLIOeMoKipi8uTJ7Ny5E03TcHV1ZcWKFTg6OpKWlsb06dPZuHEjbm5umEwmHnvsMYYPH87q1asZOnQooaGhFBUV0aJFCx577DFuuOGGOn8P9Ho9UVFRALRs2ZLvv/8egCNHjjB27FgyMzPp0qUL8+bNw2Q6/f1Wbd/Dy40kePXAryrBS84ppnNLt3O0Pj96Rwdchw/DdfgwylNTyf3hB3KXLiN1VTppxkAcowJwLUzD4ehDqBVPWBZm6TDWUnrBIEnGxdIbdbRs50HLdh70HdeGE8fySY3PoyC7hIKsEvKzSkncl01hTinVo50V+Ia6WIZ3dvTEtYW9rPQphBBCiAty//33M336dIYOHQrArl27iIqKqi423q9fP9544w1iYiyj9VavXk379u35+uuvqxO8BQsW0LFjx1rPHxwcTEJCQo1tb7/9Ni1atGDXrl2AJck0Go1omsawYcOYMGECX331FQBHjx6tTsIA+vTpw48//ghYEsthw4ZhZ2fHwIEDa1yjX79+zJkzh+Dg4Brb7ezsiI2NPS3Oxx9/nOnTpzN27FimTp3K7NmzmTZt2rm+fZclSfDqga+rDcqQS1J2cYNex+jjg+fkyXjceScle/aSu2wZeT/9RP62Yow+HXHt4oXr/o0Y4n4AOzdoNwI6joWAriAJxkVTSuEdZKnz92+VlWYKc0rJzywh6UAOCTsz+Ou7w/z13WFcvO0IqUr2fEJdQKmqtsXkZ5aQl1lCflYJ+ZklVJSZ8Q52wreVKz6hLji62VjhToUQQgjRWKSkpBAQ8M90nJO9W2cTFBREXl4eaWlpeHt7s2LFCq677rrzumZQUFD11+Hh4QCsXLkSk8nE1KlTa1zrvvvuq/U80dHRPPfcc7z33nunJXjnQ9M0Vq1aVZ1UTpgwgRkzZjBt2jSOHDnCzTffTEFBQXUSfLmTBK8efLZ3Fo6t5pGUPfeSXE8phV37dti1b0eLxx4lf+VKshcs5MRPmzhhsMO5xw24tinBfvt81JbZ4BUBXe+wJHs2TpckxsuNXq/D2cMOZw87/Nu40e2GEPKzSji6yzK0c+fqRGJ/P47RRm8pMP+vMhB2ziacPWzR6RV71yazc1UiAE7utvi0csG3lQs+oS54BDhe8EI+QgghhGh6pk+fzoABA+jZsyfXXHMNEydOxNXV9ZzHjRo1isWLF9OpUyc6d+6MjU3dHxpPmjSJa665hiVLljBw4EAmTJhA69at2bNnD507dz6v+Dt37szrr79e5/YlJSXExMRgMBh44oknGDZsGJmZmbi6umIwWFKXgIAAkpKSAHjggQeYNm0at912G7NmzTqv2JorSfDqQbBzMOgqiM89DnS4pNdWRiPO116L87XXUhofT86iReR8t5S8tXmYQjvj1isMl8rt6Jc/Ar/PsCR5MXdAi8hLGuflyMndlvZXBtD+ygDKSio4vjeLxP3Z2NgZcPKwtXxUzd07dYXOykozGccLSD2cS8rhXJIPZHNwcxpgKQYf1T+Adr39sLE3WuvWhBBCiObt5ycgdVf9ntMnCga/et6HTZw4kUGDBrFixQqWLVvGRx99xI4dO86ZsI0ePZoxY8awb98+xo0bx4YNG6r3vfzyyyxevBiA5ORkoqOjAejVqxezZs0iOjqa+Ph4fv31V37//Xe6du3KX3/9ddo17rnnHtatW4fJZGLz5s21xnHqiv2ff/45b7/9NmCZO3jddddhMpkICQnhu+++AyxDPv39/YmPj2fAgAFERUXh4uJyxvtcv34933zzDQDjx4+vnpt4OZMErx6EuoQCkFhw1Kpx2ISG0uLJJ/F68EHylv9M9sKFpM37nRPOzrjdOA33wHQM2+bB5k8hqBd0vRPa3iBz9S4Bk62BVp29adXZ+5xt9XodLYKdaRHsTMeBgWiaRn5WCSmHcolbn8xf3x5m808JRPT0peOAAFy8zn+1UCGEEEI0HX5+fkyaNIlJkybRvn17du/eTZcuXc56jI+PD0ajkd9++4233367RoL39NNP8/TTTwOWOXi1zXlzdHRkxIgRjBgxAp1Ox/Lly4mOjq5OpgBmzZpFRkZG9fy/2mzfvr16if+JEycyceJE4Mxz8Pz9/QEIDQ2lX79+bN++nZEjR5KTk0NFRQUGg4HExMTqdoCsdfAvkuDVgxCXEAAyy45ZORILnZ0driNH4DpyBMU7d5L5ySdkzl9Glq0trsPuwqOLLcbDi2DJRHD0gR73QMwksHG0duiiFkqp6uGf4d19OHEsnx0rj7NnTRK7VicS0sGT6Kta4hvmIr/ghBBCiPpwAT1tDWXFihUMHDgQo9FIamoqmZmZNZKbs3nxxRdJT09Hrz+/Wr7r168nMjISNzc3ysrK2Lt3L/369WPAgAE89dRTfPDBB9ULnBQVFZ3xPDt37uSll17i008/rdN1s7Ozsbe3x8bGhoyMDNavX89jjz2GUor+/fuzZMkSxo4dy9y5c6vn2/Xq1YuFCxdy6623Mn/+/PO6z+ZKErx64GLjgp3OlTxdKvkl5TjZNp6hc3YdOhDw7ruUHj5M5iefkr1kKdlLwOWGG/C4JhKb44vht2dh3ZvQfRp0n2JZoEU0Wl4tnbhqYiQ9hrdi1+pEdq9N4siODLxaOuEf7oaLlx2u3na4eNvj6Goj9fqEEEKIJqKoqKjGgioPPfQQiYmJPPDAA9jaWkpxvf766/j4+NTpfD179rygOA4fPsy0adPQNA2z2cz111/PyJEjUUqxdOlSpk+fzmuvvYaXlxcODg7MnDmz+ti1a9fSqVMnioqK8Pb25p133qnzAitxcXHcdddd6HQ6zGYzTzzxBJGRlmlFM2fOZOzYsTzzzDN06tSJO+64A7Cs+HnzzTczc+ZMWWSlijp1XGxTEBMTo23ZssXaYZxmyDe3cCg9h6UjFtKmReNdyKQ8KYnMz+eQs2QJWmkpTtdcg9eYAdgkfAUHfgaTk2VBlh73gOO5hxMK6ysvq2T/xlT2rksmK7mQygpz9T69UYeLlx0uXnZ4BjrRoX8Atg6N5wGEEEII0VjExcVVDyUUojGp7WdTKbVV07Rax8ZKD149CXEOIT73FxKzihp1gmf098fnmafxnDaVrHnzyJ73JfkrV+I2ZgyeY+/DsOtTWP82bPoQOk+AXg+AS92GAQjrMJr0tO/rT/u+/mhmjYKcUnLSi8hNL/7nc1oRCTsz2PVHIt2HhhLZ209W4xRCCCGEaIYkwasnER6tWZW8jAOZyQyghbXDOSeDhwfeDz6I+/jxnHjvPbIXLiR32TI8p96F2+RH0W2eBVtmw7a5lt683tOlxEIToHSqemXOwLY192UkFrB20QH+/Go/e9Ym0WdMG/zCXK0SpxBCCCGEaBg6awfQXES1aAPA/qxDVo7k/Bg8PPB9/nlCv1+GfUwM6W/8l/jx95FruA7t3q0QMQTW/hfe6QRbPoPKCmuHLC6QZ4Ajwx7qxDV3tqOkoJzv3tjGr7P3UJBdau3QhBBCCCFEPZEEr56EuVpKJRzLT7BuIBfIplUrAj/8gJZzPkfn6kLyI4+QMPVxikLuhjtXgUcY/DgdPuwNB3+3drjiAimlaB3TgptnXEHMdcHEbz/B/Bkb2fJzAhVlldYOTwghhBBCXKQGG6KplPoMuAFI1zSt/VnadQX+AsZqmrakoeJpaN723ug0W9KLG0ephAvlcMUVhCxZQu6y7znxv/9x9JZbcLvlFrwfXILu2Cr47TmYPxJaDYBr/gMt2lk7ZHEBjDZ6ug8JJaKnL+uXHGLTsng2fR+PnZMJBxcTDi42OLiYsHe1wcHFBkdXG/zbumE0nd8yy0IIIYQQ4tJqyDl4c4D3gC/O1EAppQdmAr82YByXhFIKJ50/+eYka4dy0ZROh+vwYThfczXp/3ub7C+/pGD1anz/8xIO9/wNmz+BP2daevO6TYEBz0oNvSbK2dOOwVOjSNyfTdKBbIpyyyjMLaUot4wTx/Ipyi+DqoV23f0cGDS5Pe6+DtYNWgghhBBCnFGDDdHUNG0NkHWOZvcB3wDpDRXHpeRl25JyXSrlleZzN24CdA4O+Dz9FEFfzkPp9Ry7fSIpL75MZfvb4P5YS3H0TR/CBz3g8CprhysuQkC4G91vDKX/rW254Z6OjH6qKxNf68209/px+6u9GHxXFMX5ZSx+dQsH/k61drhCCCFEs+ToePoD8/3799OvXz+io6OJiIhgypQp/PLLL0RHRxMdHY2joyPh4eFER0dz2223sXr1apRSNYqLx8bGopTijTfeOK94HnzwQfz9/TGb/3lvO2fOHLy8vOjUqROtW7dm0KBBbNiwocZxGRkZGI1GPvzwwxrbg4OD6dOnT41t0dHRtG9/xsF+p+nXr1/1/UZHR5OebkkjSktLGTNmDGFhYXTv3p2EhIQzHt8YS67VJ6vNwVNK+QPDgQ+sFUN9a+kUjM6Yz+HME9YOpV7Zd+lCyLKluN8xiZwlS4i/cQgFW3bD9f+FiStAbwPzhsPSe6A429rhinqk0+twcLUhtJMXo5/qhlegI799tpfVX+2nolzm7AkhhBAN7f7772f69OnExsYSFxfHfffdx6BBg4iNjSU2NpaYmBjmz59PbGwsX3xhGTjXvn17vv766+pzLFiwgI4dO9Z6/uDg4Fq3m81mvvvuOwIDA/nzzz9r7BszZgzbt2/n4MGDPPHEE4wYMYK4uLjq/YsXL+aKK65gwYIFp503Pz+f48ePA9Q45t9mzJjBnDlzat138n5jY2Px9rbUbZ49ezZubm4cOnSI6dOn8/jjj5/x3M2dNRdZ+R/wuKZp5+zuUkpNUUptUUptOXGi8SZPbdxaAbAteb+VI6l/OltbWjz6KMELF6BzdOD4lLtIfvwJKl0jYeo66P0Q7FgAs7pD3A/WDlc0AEc3G4ZN70TnQS3ZsyaJb1/fRu6JYmuHJYQQQjRrKSkpBAQEVH8dFRV1zmOCgoIoKSkhLS0NTdNYsWIFgwcPPq/rrl69mnbt2jFt2rRaE7WT+vfvz5QpU/j444+rty1YsID//ve/JCUlkZiYWKP96NGjWbRoUXW7cePGnVdcZ7Js2TImTJgAwKhRo1i5ciWaplFcXMzYsWOJiIhg+PDhFBc3//cu1kzwYoCFSqkEYBTwvlJqWG0NNU37WNO0GE3TYry8vC5hiOeno4+lVEJc5kErR9Jw7Dp0IOTbb/GYNpXcH3/kyIiRFO8/DFc9D5NXgaM3LLoVvr4NCprFyFtxCp1eR4/hYVx3dwfyMor5+v82E7/97A9dKsorMTeTYctCCCHEpTZ9+nQGDBjA4MGDeeutt8jJyanTcaNGjWLx4sVs2LCBzp07Y2Njc17XPZl8DR8+nJ9++ony8vIztu3cuTP79u0D4Pjx46SkpNCtW7caydxJI0eO5NtvvwXghx9+4MYbbzyvuAAmTpxIdHQ0L730EppmWSwgKSmJwMBAAAwGAy4uLmRmZvLBBx9gb29PXFwcL7zwAlu3bj3v6zU1Vit0rmlayMnXSqk5wI+api21Vjz1IdqnFZrZwJHcI9YOpUHpTCa8H3gApyuvJHH6QxwdN44WTz+N65jRqMl/wIZ3YPVMOLIGhs6CttdbO2RRz0I6eDL6qa788slufv5oFxE9fbF1MFJcUEZxQTnF+eWUFJRRnF9OeWkl9s4megxvRXh3H5ROWTt8IYQQ4qxm/j2TfVn76vWcbd3b8ni38x82OHHiRAYNGsSKFStYtmwZH330ETt27DhnwjZ69GjGjBnDvn37GDduXI15ci+//DKLFy8GIDk5mejoaAB69erFrFmzKCsrY/ny5bz55ps4OTnRvXt3fvnlF2644YZar3UyyQJYtGgRo0ePBmDs2LFMmjSJhx9+uHq/h4cHbm5uLFy4kIiICOzt7av37dq1i/HjxwOQmpqKyWTif//7HwArV67Ew8OD+fPn4+/vT35+PiNHjmTevHncdtttZ/w+rFmzhvvvvx+ADh060KFDh7N+35qDhiyTsADoB3gqpRKB5wEjgKZpH57l0CbL0daEqvAipahpl0qoK7voaEK+/YbkRx8jdcYMirZtxXfGDHR9Hoa2N8K3k2HhzdB9Glz9IhhM1g5Z1CNnTztGPNKF9d8eYtfqRPR6HXZORmwdjdg5mXD1tsPO0YSto5EjOzNYOTeO3WuS6DO6DS1CnK0dvhBCCNFk+Pn5MWnSJCZNmkT79u3ZvXs3Xbp0OesxPj4+GI1GfvvtN95+++0aCd7TTz/N008/DVjm4MXGxtY49pdffiEnJ6d6OGhRURF2dnZnTPC2b99OREQEYOn5S01NZf78+YAlgTx48CCtW7eubj9mzBjuueee0+bYRUVFVccyY8YMgoODuf3222u08ff3B8DJyYmbb76Zv//+m9tuuw1/f3+OHz9OQEAAFRUV5Obm4uHhcdbvUXPVYAmepml1HlCradrtDRXHpWav/MipuDwSPACDmxuBH39ExocfkvHue5Ts3UvAO+9gE9oG7vgVfn0WNn0AxzfCqM/BPeTcJxVNht6oo++YNvQaGYZOr1Cq9t65LtcGsf/vVP769jBLZm6h7RU+XDG8FQ4u5zdcRAghhLgULqSnraGsWLGCgQMHYjQaSU1NJTMzszrJOZcXX3yR9PR09Przq2O7YMECPv300+r5cYWFhYSEhFBUVHRa2z///JOPP/6YP/74gwMHDlBQUEBS0j9lw55//nkWLFjAc889V71t+PDhpKSkMGjQIJKTk+scV0VFBTk5OXh6elJeXs6PP/7IVVddBcCQIUOYO3cuPXr0YMmSJQwYMAClFH379uWrr75iwIAB7N69m507d57X96IpstoQzebK3RhAoraNkooSbA221g7nklA6HV533419dDRJDz/CkVE34fvSi7hcfz1c9xqE9IFl98BHfWHoexA51Nohi3qmN5x9Oq/SKdpe4UtotBdbf04gduVxDm8/Qcx1wXQcEIjeaM3pwEIIIUTjUFRUVGNBlYceeojExEQeeOABbG0t7ytff/11fHx86nS+nj17XlAMK1asqFHiwMHBgd69e/PDD5aF9BYtWsS6desoKioiJCSEb775hoiICF544QWGDx9e43wjR45kzJgxNRI8JyenC1rlsrS0lEGDBlFeXk5lZSVXXXUVkydPBuCOO+5g/PjxhIWF4e7uzsKFCwGYNm0aEydOJCIigoiIiHP2fDYH6tQxs01BTEyM1phrV0xe8ikbC99m8Q2LaevR1trhXHLlqakkTX+I4u3bcbv5Zlo8+QTKaITso7BkIiRtha6T4Zr/gPHySIDF6XLSi1i/5BAJOzNw8bIjqL0HJnsDNnYGbOwNmOxOvrYM93R0k54+IYQQDSsuLq56mKEQjUltP5tKqa2apsXU1l568OpZqGsoGwth94mDl2WCZ/TxIeiLuaT/902y5syhLOEI/m+/jd4tyFIzb+UL8Nd7cHwT3DQHPFpZO2RhBa7e9lx/dweO7clk47J49m1Mpay44oztW0a60/naIPxau55xGKgQQgghhJAEr961926FlqjYlX6QUZdffgeAMhpp8cTj2LRuTcrzz3P0llsJ/OhDjL6+MOhlCO4NS6fBx/3hps8hbKC1QxZW0rKdBy3bWSZAm80a5SUVlBZXUFZcQWmR5SMruYCdfySy9M3t+IS60OXaIIKiPCTRE0IIIYSohUx8qWdB7i5o5e4cyjls7VCsznXkCFp+/BHlyckkjBlLSVycZUf4YLhrDbgGwvyb4O9PrBuoaBR0OoWNvRFnDzs8A5zwb+NGaLQXMdeFcNvLPek7tg2FOaX89P5OFv1nMwc2p0p9PSGEEEKIf5EEr575u9phLvUiqfCotUNpFBx69iRo/nzQ6Th6y60UrF1r2eHaEiatgNZXw/JH4KdHoPLMQ/TE5c1g0hPVL4BbXrqCgbdHYK4089vsvcx/fiNbliewf2MKx/dmkZlUQElBOU1tbrEQQgghRH2RIZr1zN3BhKpoQXbZeirMFRh08i22DW9D8KJFHJ86leNTp+Hz/HO4jR4NNk4w9iv4/XnY8C5kHbaUUrBztXbIopHS63W0vcKX8G4+HNmZwdYVR9n0ffxp7XR6hb2zCXsXG1p19qLjwED0enmeJYQQQojmT7KPeqaUwtUQQD4VJBUkEeQcZO2QGgVjC2+C5s0jafp0Up97nvLEJLwefACl01tW1PRsAz9Oh9lXw82LwD3U2iGLRkzpFKHRXoRGe1FWUkFRbhlFeaUU5pZVvy7KLSMnvYi/vj3MgU1p9L+1rRRYF0IIIUSzJ4+0G4CPXUsA4nNO71m4nOkdHQh8fxauN91E5scfk/zY42jl5ZadnW+D25ZB4Qn4ZCAkrLdusKLJMNkacG1hj19rN1rHtKDjwEB6DA9j4O2RjHwshsF3RVFSUMaS17awZtEBykpkKLAQQojGydHR8bRt+/fvp1+/fkRHRxMREcGUKVP45ZdfiI6OJjo6GkdHR8LDw4mOjua2225j9erVKKX49NNPq88RGxuLUoo33nijTnEUFRVxyy23EBUVRfv27enduzcFBQUApKWlcfPNNxMaGkqXLl3o0aMH3333HQCrV6/GxcWFTp06ER4eTt++ffnxxx/P63tw7bXX4urqyg033FBj+5EjR+jevTthYWGMGTOGsrIywFIbb8yYMYSFhdG9e3cSEhJqPW+/fv1ozKXW6pMkeA0gxMXS+xSfKwnevymjEZ8XX8DrwQfI+/FHEqdPx1z1H5Tg3nDnSnDwhC+Gwo6F1g1WNAuhnby4ecYVRF0ZwK7ViSx4YRPxsSesHZYQQghRJ/fffz/Tp08nNjaWuLg47rvvPgYNGkRsbCyxsbHExMQwf/58YmNj+eKLLwBo3749X3/9dfU5FixYQMeOHWs9f3Bw8Gnb3n77bVq0aMGuXbvYvXs3s2fPxmg0omkaw4YNo2/fvsTHx7N161YWLlxIYmJi9bF9+vRh+/bt7N+/n3feeYd7772XlStXnnaNfv361ZqMPfroo8ybN++07Y8//jjTp0/n0KFDuLm5MXv2bABmz56Nm5sbhw4dYvr06RdUQL25kQSvAQS5eWAud+JgtqykWRulFJ5Tp9Li6acp+H0liffci7mkxLLToxXc8RsE9YDv7oKNH1g3WNEsmOwM9B3bhpGPdsHG3sDPH+7i5492UZBdau3QhBBCiLNKSUkhICCg+uuoqKhzHhMUFERJSQlpaWlomsaKFSsYPHjweV3T39+/+uvw8HBsbGxYtWoVJpOJqVOn1rjWfffdV+t5oqOjee6553jvvffqfO2BAwfi5ORUY5umaaxatYpRo0YBMGHCBJYuXQrAsmXLmDBhAgCjRo1i5cqVaJpGcXExY8eOJSIiguHDh1NcXFznGJo6SfAagL+rHeYyb0nwzsF9/K34vPgChevWcfyuqZgLCy077FzhliUQcSOseAJWvQyyKqKoBz6hLtz0VFd6DG/F0d2ZLHhhIymHc60dlhBCCHFG06dPZ8CAAQwePJi33nqLnJycOh03atQoFi9ezIYNG+jcuTM2NjZ1vuakSZOYOXMmPXr04JlnnuHgwYMA7Nmzh86dO59X/J07d2bfvn3ndcy/ZWZm4urqisFgWT4kICCApKQkAJKSkggMDATAYDDg4uJCZmYmH3zwAfb29sTFxfHCCy+wdevWi4qhKZFFVhqAn6sd5lJvjuXvQNM0Kch8Fm6jR6OztSX5iSc5NnkKgR99iN7JCQw2cNNc+OEBWPMaFGfB4NdBJ88kxMXR63V0HhREq85e/PDODn7+cCejnojB2cPO2qEJIYRoJFL/7/8ojbu4pOTfbCLa4vPUU+d93MSJExk0aBArVqxg2bJlfPTRR+zYseOcCdvo0aMZM2YM+/btY9y4cWzYsKF638svv8zixYsBSE5OJjo6GoBevXoxa9YsoqOjiY+P59dff+X333+na9eu/PXXX6dd45577mHdunWYTCY2b95caxynli76/PPPefvttwE4dOgQ1113HSaTiZCQkOp5fPVlzZo13H///QB06NCBDh061Ov5GzN5t9wAAtwsPXgllUWkF6VbO5xGz2XIEPzffJPinTs5NnESlSefTOn0MORd6PUAbP4Uvp0MFWVWjVU0Hy5e9lx/TwcqKzSWv79TFl8RQgjRaPn5+TFp0iSWLVuGwWBg9+7d5zzGx8cHo9HIb7/9xsCBA2vse/rpp6vn8Pn5+VW/njVrVnUbR0dHRowYwfvvv8+tt97K8uXLadeuHdu2batuM2vWLFauXMmJE2ee2759+3YiIiIAS7J66tzB5cuXExsbe87kzsPDg5ycHCoqLH+rExMTq4eQ+vv7c/z4cQAqKirIzc3Fw8PjnN+f5kx68BpAC2dbtDIvwLLQSguHFlaOqPFzvnYQymQi6YEHODrhdlp+NhuDhwcoBVe/CHbulnp5Jbkw+gsw2Vs7ZNEMuPk4cO3k9vzw3g5++2wvg6dGodNJj7sQQlzuLqSnraGsWLGCgQMHYjQaSU1NJTMzs8b8uLN58cUXSU9PR6/Xn9c1169fT2RkJG5ubpSVlbF371769evHgAEDeOqpp/jggw+YNm0aYFlx80x27tzJSy+9VGNFzwuhlKJ///4sWbKEsWPHMnfuXIYOHQrAkCFDmDt3Lj169GDJkiUMGDAApRR9+/blq6++YsCAAezevZudO3deVAxNiSR4DcBk0OFuDKQYS4LXw6+HtUNqEpwG9Cfgww9IvOdejo6/jZaff46xhbdlZ+8Hwc4NfnwQ5g231MqTguiiHgRGutNndGvWLDzAxqWH6TkizNohCSGEuEwVFRXVWFDloYceIjExkQceeABbW1sAXn/9dXx8fOp0vp49e15QHIcPH2batGlomobZbOb6669n5MiRKKVYunQp06dP57XXXsPLywsHBwdmzpxZfezatWvp1KkTRUVFeHt7884775zWg3g2ffr0Yd++fRQUFBAQEMDs2bMZNGgQM2fOZOzYsTzzzDN06tSJO+64A4A77riD8ePHExYWhru7OwsXWlZhnzZtGhMnTiQiIoKIiAi6dOlyQd+LpkhpTWzxipiYGK0p1LAY/v464u0f4qa2Q3jmimesHU6TUrR5M8fvmorBx4egeV9YevJO2rPUMlTTsw2MXwqOXtYKUzQzfy7Yz+4/kxg4IYK2PXytHY4QQohLLC4urnoooRCNSW0/m0qprZqmxdTWXubgNZAANwdURQuphXcB7Lt2JfCjDylPTubYHXdSmXvKKofthsHNX0NWPMy9EQozrBanaF56j25NQFs3/vhyH8mHcqwdjhBCCCHEBZEEr4H4udpSVuRJfI4keBfCvmtXAt59l9LDhzk+5S4qCwr/2dmqv2WIZnYCzB0iSZ6oF3q9jkGT2+PsacfPH+4iL+PyqZcjhBBCiOZDErwG4u9qR3mJF5klmeSWSp2tC+HYpzf+b/6X4t27Sbz77n+KoQOE9LUkeVmH4YuhUJhpvUBFs2HrYOT6uzugmTV+kpU1hRBCCNEESYLXQE4WOwc4knvEytE0Xc5XX43fq69QtHkzifffj1Z2SpmE0Cth3ELIPGRJ8oqyrBeoaDZcW9gzaEp7slOLWPHRLooLpDSHEEIIIZoOSfAayMli54DMw7tILjfeiM8LMyhcs5akRx5FqzilV6VVfxi3ADIPwhdDJMkT9SKwrTv9bw0n6UAOC17YxKGtUs9SCCGEEE2DJHgNxN/NDq3cDb0yyjy8euA2ejQtnnyC/F9/JeXpp9HM5n92thoAY7+CEwekJ0/Um4iefox+qiuObrb88sluVny0i6I86c0TQgghROPWYAmeUuozpVS6Umr3GfbfopTaqZTapZTaoJTq2FCxWIOzrREnGxOOOl/pwasn7hMm4Hn/feQu+57UF1+kRomPsIEw7is4sR/mDYPibKvFKZoPD39HRj3ehSuGhZKwK5OvXtjI/k2pNLXyMkIIIZoGR0fH07bt37+ffv36ER0dTUREBFOmTOGXX34hOjqa6OhoHB0dCQ8PJzo6mttuu43Vq1ejlKpRXDw2NhalFG+88Uad4igqKuKWW24hKiqK9u3b07t3bwoKCgBIS0vj5ptvJjQ0lC5dutCjRw++++47AFavXo2LiwudOnUiPDycvn378uOPP57X90Cv11ff25AhQ6q3HzlyhO7duxMWFsaYMWMoK6v9oWtt38O6WL16NTfccMMFHVsf/u///q/eztWQPXhzgGvPsv8IcKWmaVHAS8DHDRiLVfi72aGv9JEErx55TpuGx513kLNwERnvzaq5M+wqGDsf0uMsxdBL8qwTpGhWdHodXa4NZvTTXXH1tuf3z/ey/INdFGSXWjs0IYQQl4H777+f6dOnExsbS1xcHPfddx+DBg0iNjaW2NhYYmJimD9/PrGxsXzxxRcAtG/fnq+//rr6HAsWLKBjx9r7UoKDg0/b9vbbb9OiRQt27drF7t27mT17NkajEU3TGDZsGH379iU+Pp6tW7eycOFCEhMTq4/t06cP27dvZ//+/bzzzjvce++9rFy58rRr9OvXj4SEhNO229nZVd/b999/X7398ccfZ/r06Rw6dAg3Nzdmz55d128hc+bMYcaMGXVuf6qKikuz4FqTSPA0TVsDnHGsnKZpGzRNO9nNshEIaKhYrMXP1Y6KYi+SC5IpqSg59wHinJRSeD38MC7Dh5MxaxY533xbs0Hrq2HMl5C6CxbeDOXyfRf1w93XgRGPdqHXqDAS47JY8OImfvt8Dyvn7uWPeXGsnr+PNQv2s3bRAdYtPsim7+PJz5KfPyGEEBcnJSWFgIB/3iZHRUWd85igoCBKSkpIS0tD0zRWrFjB4MGDz+ua/v7+1V+Hh4djY2PDqlWrMJlMTJ06tca17rvvvlrPEx0dzXPPPcd7771X52vXRtM0Vq1axahRowCYMGECS5cuBSw9ez169CAqKopnnnnmvM67YsUK2rZtS+fOnfn223/eU86YMYPx48fTq1cvxo8fT0JCAgMGDKBDhw4MHDiQY8eOAXD77bczdepUYmJiaNOmTXVvZUlJCRMnTiQqKopOnTrxxx9/AJZE8957762+zg033MDq1at54oknKC4uJjo6mltuueWCv08nNZY5eHcAP59pp1JqilJqi1Jqy4kTJy5hWBfH39WO/Hx3NDQS8hKsHU6zoZTC98UXcOjZk5Tnn6dg3fqaDdoMgmEfQsI6WDIJKmWpe1E/dDpF9FUtGfNMN3xCXUg5lEvivmwSdmcSH3uCg1vS2bcxlb3rktn6cwKL/vM38dubzu8sIYQQjc/06dMZMGAAgwcP5q233iInJ6dOx40aNYrFixezYcMGOnfujI2NTZ2vOWnSJGbOnEmPHj145plnOHjwIAB79uyhc+fO5xV/586d2bdvX53bl5SUEBMTwxVXXFGdxGVmZuLq6orBYAAgICCApKQkAB544AGmTZvGrl278PX1Pa/rTJ48mR9++IGtW7eSmppaY//evXv5/fffWbBgAffddx8TJkxg586d3HLLLdx///3V7RISEvj777/56aefmDp1KiUlJcyaNQulFLt27WLBggVMmDCBkpIzP/R99dVXq3su58+fX+d7OBPDRZ/hIiml+mNJ8HqfqY2maR9TNYQzJiamyUx+8XO1o6DAAwdviM+Jp617W2uH1GwooxH/d97m6C23kvTAAwTN/xLbtqd8fzvcBCU5sPwR+P4+GDoLdI3leYZo6lxb2HPjfWefNpyTVsSvs/fw80e7aNfHj143tcZo0l+iCIUQQlyMtV8fION4Qb2e0zPQkT6j25z3cRMnTmTQoEGsWLGCZcuW8dFHH7Fjx45zJmyjR49mzJgx7Nu3j3HjxrFhw4bqfS+//DKLFy8GIDk5mejoaAB69erFrFmziI6OJj4+nl9//ZXff/+drl278tdff512jXvuuYd169ZhMpnYvHlzrXGcOm/9888/5+233wbg0KFDXHfddZhMJkJCQqrn8R09ehR/f3/i4+MZMGAAUVFRuLi4nPE+169fzzfffAPA+PHjefzxxwFLUjhw4EAAsrKyKCsrq04Y582bR2VlJSEhIbRu3RqAW2+9lY8//mfG2JAhQ7CzswPgr7/+qu7hGz9+PI899liN77NOp6N169aEhoayb98+1q1bV92r2bZtW4KCgjhw4MAZ76G+WfUdr1KqA/ApMFTTtGZXqdrfzQ5zmSc6dDIPrwHoHR0J/OhDdI6OHL9rKuX/evJCt8nQ7ynY8RX8+gzIwhjiEnJtYc/Ix7rQ6eqW7FmbzOJXtpCRWL9vFoQQQlwe/Pz8mDRpEsuWLcNgMLB7d61rGNbg4+OD0Wjkt99+q050Tnr66aer57n5+flVv54165/1DRwdHRkxYgTvv/8+t956K8uXL6ddu3Zs27atus2sWbNYuXIlZxtht337diIiIgBLsnrq3MHly5cTGxtbndwB1UNDQ0ND6devH9u3b8fDw4OcnJzq+XCJiYk1hpAqpU67roeHR/W1XnzxRaZOnVr9dV2GuTo4OJyzTW3Xri2WkwwGA+ZTVoI/W6/exbBaD55SqiXwLTBe07RLl9JeQv6utqAZ8LCVlTQbitHHh8CPP+boLbdwfMpdBM3/Er2T0z8NrnwMirNg4yywd4O+j1ovWHHZ0Rt09BwZRmCEO7/P2cuSV7fQc2QYUf38z/oHQAghhHVdSE9bQ1mxYgUDBw7EaDSSmppKZmZmjeTmbF588UXS09PR689vBMn69euJjIzEzc2NsrIy9u7dS79+/RgwYABPPfUUH3zwAdOmTQMsK26eyc6dO3nppZdqrOh5NtnZ2djb22NjY0NGRgbr16/nscceQylF//79WbJkCWPHjmXu3LkMHToUsPQ6Lly4kFtvvfW8hje2bduWhIQEDh8+TKtWrViwYMEZ2/bs2ZOFCxcyfvx45s+fT58+far3LV68mAkTJnDkyBHi4+MJDw+nT58+zJ8/nwEDBnDgwAGOHTtGeHg4eXl5vP/++5jNZpKSkvj777+rz2M0GikvL8doNNb5Hs6kwRI8pdQCoB/gqZRKBJ4HjACapn0IPAd4AO9XvdGp0DQtpqHisQZ/V3sA3I1B7Muq+9hjcX5sw9sQ8M7bHJtyF4n330/Ljz5CmUyWnUrBoFcsZRNW/Qfs3KDrndYNWFx2AiPdGfNMN1Z9EcfaRQc4HpfFgNvaYudosnZoQgghGpGioqIaC6o89NBDJCYm8sADD2BrawvA66+/jo+PT53O17NnzwuK4/Dhw0ybNg1N0zCbzVx//fWMHDkSpRRLly5l+vTpvPbaa3h5eeHg4MDMmTOrj127di2dOnWiqKgIb29v3nnnndN6EM8kLi6Ou+66C51Oh9ls5oknniAyMhKAmTNnMnbsWJ555hk6derEHXfcAVhW/Lz55puZOXNmddJXF7a2tnz88cdcf/312Nvb06dPH/Lz82tt++677zJx4kRef/11vLy8+Pzzz6v3tWzZkm7dupGXl8eHH36Ira0td999N9OmTSMqKgqDwcCcOXOwsbGhV69ehISEEBkZSURERI35jFOmTKFDhw507tz5oufhqaZWzykmJkbbsmWLtcOok0qzRvgzP9Oj83ZiCxeyYdwGnExO5z5QXJCc75aS8uSTuAwdiu+rr9TsIaksh0Xj4cAKGPkpRI2yXqDisqVpGjtXJbLhu0MYjHoCI9xp2c6dwAh3nNxtrR2eEEJc1uLi4qqHEgpRF7fffjs33HBD9eqeDaW2n02l1NYzdY5ZfZGV5kyvU/i62qKVWrrR92ftJ8anWXVSNiquw4dRnpxExrvvYfT3x+v+U5bs1Rvhps/hy5Hw3V1g6wqtr7JarOLypJSi48BA/MNd2bHyOMf3ZnF4WzoAbj72BEa60zLSA7/WrhhtZEEWIYQQQpw/SfAamJ+LHYX5LcAO9mXtkwSvgXnefTflyclkvP8+Nq3DcD615ovRDsYtgDnXw9e3wcTl4BdttVjF5cszwImBEyLRNI2slEKO783i+N4s9qxNZueqRHQGRdSVAfQaFSZz9YQQQohGas6cOdYOoVaS4DUwfzc7NsUX4+HmQVxWnLXDafaUUvg8/zxl8UdIfuppTKGh2IaH/9PA1gVuWQKfXgVfjYY7fgO3IOsFLC5rSik8/Bzx8HMk+qqWVJRVknIol/1/p7Jj5XE0TaP3Ta0lyRNCCCFEnUlhsAbm72pHal4J4e5tZaGVS0RnMuH/9v/QOzmReM+9VGRn12zg5GNJ8spLYP5NlgVYhGgEDCY9gZHuDJwQQccBgexclcimZbICrxBCXCpNbW0K0fxdyM+kJHgNzN/VjkqzRqBDa+Jz4imrLLN2SJcFo7c3Ae++Q0VaGskPP4xWVTelmndbGDsfso/AwluhotQ6gQpRC6UUvW4KI7KPH1tXHGXLzwnWDkkIIZo9W1tbMjMzJckTjYamaWRmZlavoFpXMkSzgfm52gHgZgimQqvgYM5B2nm0s3JUlwe7jh3xmTGDlKefJv2/b9Li8cdqNgjpA8M+gG/ugKXTYMSnoJNnHqJxUErRb1w4FWWVbFoWj9Gkp+PAQGuHJYQQzVZAQACJiYlnLdotxKVma2tbo3RGXUiC18D83SwJnq3Z8sZsX+Y+SfAuIdeRIyjZu5eszz/HNjIClxtvrNkgahTkHoffZ4BLIFz9glXiFKI2SqcYeFsEFWVm1i0+iMGko12fuhW3FUIIcX6MRiMhISHWDkOIiybdFQ3Mz8WS4BUXueJgdJCFVqygxROPY9+1KynPPEvxnj2nN+j1IMTcAev/B5s/vdThCXFWOr2Oa+5oR8t2Hqz+aj/7N6VaOyQhhBBCNGKS4DUwO5MedwcTybmlhLuFy0IrVqCMRsuiKx7uJN57HxWZmf9qoGDwa9DmWlj+KOz/2TqBCnEGeoOOwXe1x7+NKyvn7K2unSeEEEII8W+S4F0CLd3tOXKikLbubTmQfYBKc6W1Q7rsGNzdCXj3XSqzskh6cDpaeXnNBnoDjPoMfDvCkkmQtM06gQpxBgaTnuumdaBFiDO/zt7Dtl+OUlEmv0uEEEIIUZMkeJdApJ8ze5JzaeveluKKYo7mH7V2SJclu3bt8P3PSxRt3kz6G2+c3sDkADd/DQ6esGAc5CZe+iCFOAuTrYEb7u1Iy3Ye/PXdYeY/v5G4DSmYzbLimxBCCCEsJMG7BNr5OZNXUoGbwTJxd1+mDNO0Fpcbb8Rt/Hiy5n5B/qpVpzdw9LYkeeVF8NVYKC249EEKcRY29kauv7sDwx7qhL2ziVVfxPH1y39zdI8s7S2EEEIISfAuifZ+LgAU5Ltj0BlkHp6VeT/6CDaREaQ8+RTlKSm1NIiAmz6H9L2WEgoypFY0Qv5t3Bj1RAzX3NmO8jIzP767g2X/iyX9aJ61QxNCCCGEFUmZhEsg3McJvU6xP7WY1q6tJcGzMp3JRMCbb3JkxEiSHn2UoDlzUIZ//VcIuwoGz4Tlj8Cvz8K1/2edYIU4C6UUrWNaEBrtxZ61SWz+KYHFr2whKMoDZw87bOwN2NgbMNlZPtvYGbCxN+LmY4/BpLd2+EIIIYRoAJLgXQK2Rj2tvR3ZnZRL2zZtWX18NZqmoZSydmiXLVNwMD4vzCD50cfIeP99vO6///RG3SZD5mHYOAs8WkHXOy59oELUgd6go0P/QNpe4cu2X49ycEs6qYdzKS2ugFpGbbq2sGf4w52xdzZd+mCFEEII0aAkwbtEIv2cWXcwg6uvaMt3h74jrSgNHwcfa4d1WXO58UYKN/xFxgcfYt+tOw5XdD+90aCXISveUj7BLRjCBl7yOIWoK5OdgSuGtuKKoa0A0MwaZaWVlBaVU1ZcQWlhBXmZxaxZcIAf3o1l2EOdsbGTPwNCCCFEcyJz8C6R9n4upOeX4mNneeMlwzQbB59nn8EUHEzyo4+eXh8PQKeHUbMt8/IW3w7p8u8mmg6lU9jYGXD2sMMzwAn/cDcievpx7dQospIL+WnWDim1IIQQQjQzkuBdIu38nAEoK/JBoYjLirNyRAJAZ2+P///eojI3l+Qnn0Qzm09vZOME4xaCwRa+Gg0FJy59oELUo6B2Hlw1MZKUw7ms+GQ3lZW1/NwLIYQQokmSBO8SiaxK8A6llhHkHCSlEhoR2/BwWjz5BIVr1pL1+ZzaG7kGWpK8gjRYeDOUl1zSGIWob61jWnDluHCO7spk1dw4NKmlJ4QQQjQLkuBdIk62RoI97NmTnEdb97YyRLORcR07FqdrriH9rbco3rGj9kYBXWD4R5D4N3x/H0jNMdHEte/rT/ehoRz4O421Xx+UOnpCCCFEMyAJ3iXUzt+F3cm5tHVvS3JhMrmludYOSVRRSuH70osYvb1JeuhhKvPza2/YbhgMeBZ2fQ1r3rikMQrRELpcG0T0VYHsWp3I3z8esXY4QgghhLhIkuBdQu38nDmeVUxLh9aALLTS2OhdXPD77xuUp6aS9uqrZ27Y52HoMBb++A/s/vbSBShEA1BK0XNkGG17+rLlpwR2rDxu7ZCEEEIIcREaLMFTSn2mlEpXSu0+w36llHpHKXVIKbVTKdW5oWJpLNr7uQBgLvMDJMFrjOw7dcLjjjvI/eZbCtasqb2RUjDkHQi8ApZOg8StlzZIIeqZUor+t4QTGu3FusUH+X3OXpIOZMu8PCGEEKIJasgevDnAtWfZPxhoXfUxBfigAWNpFE6upHn8hA5ve29ZSbOR8rz3HkxhrUh59jkq8/Jqb2SwgbHzwbEFLBgLOdLrIZo2nV7H1XdEEnWlP/GxJ1j65na+fO4v/v7xCHkZxdYOTwghhBB11GAJnqZpa4CsszQZCnyhWWwEXJVSvg0VT2Pg4WiDr4stu5NyiXCPkJU0GymdyYTfK69QkZFB2syZZ27o4Ak3fw0VJZYkr/QM8/aEaCIMRj19x4Uz8bXeXDUxEmdPOzb/dIR5z/zF0je3se+vFMpKKi7o3OVllezflEphbmk9Ry2EEEKIU1lzDp4/cGq3R2LVtmatnZ9z9UqaR/KOUFwhT8YbI7uoqHMP1QTwbgs3fQ7pcfDNZDBL0WjR9BlNesK7+zD0wU7c9nJPug8JpSC7lJVz45jz+HpWz9/HieN1e6BRUljO5p+O8MVTG/j98738MU8ebAkhhBANyWDtAOpCKTUFyzBOWrZsaeVoLk47PxdW7Usn1Dkcs2bmYPZBOnh1sHZYohae995D/qqVpDz7HKE/fI/e2bn2hmFXweCZsPwR+O05GPTypQ1UiAbk5G5LzHXBdBkcROrhXPauT2bfxlT2rE2mRYgz7fv6E9bFG4NJX+O4guwSYlceZ8/aZCpKKwmK8sDB1Ya9a5NJ2p+Nf7ible5ICCGEaN6smeAlAYGnfB1Qte00mqZ9DHwMEBMT06Rn/bfzc8asgb7C0lm5L2ufJHiN1Mmhmgljx5H26kz8/u8siVu3yZBxAP56DzzCIGbipQtUiEtAKYVvmCu+Ya70GtWa/RtT2b0miZVz41i3+CBte/jSro9lAantvx5j/6ZUNA1ad/Wm8zVBePg7UlFWybHdmWz49hCjnohBKWXluxJCCCGaH2smeN8D9yqlFgLdgVxN01KsGM8l0d7fspJmWqYdziZnWWilkTs5VDPz449xvnYQjn37nrnxoFcgKx5+ehhcAy09e0I0Q7YORjoODKTDgACSD+Swe20Su1YnWkosKDAYdLTr40/0VYE4e9pVH2cw6el2Yyirvojj0NZ0Wse0sOJdCCGEEM1TgyV4SqkFQD/AUymVCDwPGAE0TfsQWA5cBxwCioDLosvD18UWN3sje1PyaeveVhZaaQLqPFRTb4BRn8Png+Hr22HSCvBpf0ljFeJSUkrhH+6Gf7gbRXll7PsrBXOlRrs+ftg5mWo9JvwKH3asPMbGZfGERnuhN0g5ViGEEKI+NeQqmuM0TfPVNM2oaVqApmmzNU37sCq5o2r1zHs0TWulaVqUpmlbGiqWxkQpRXt/F3Yn59LWvS0Hcw5SYb6wVenEpVFjVc1Xz7KqJoCts2VlTRtH+Go05DX7TmkhALB3NtF5UBAx1wWfMbkD0OkUVwxrRd6JYvasTb6EEQohhBCXB3l0agWRfs4cSC2gtWs4pZWlHMk9Yu2QxDlUr6r57TlW1QRw8bckeSW5liSvtODSBClEExHU3gP/Nq5sWX6EsmJ5wCWEEELUJ0nwrKC9nwtllWZsNcsaM/uyZJhmU1CjAHrBOZI23w5w0xxI2wNLJkGlvIkV4iSlFD1GhFGcX872345ZOxwhhBCiWZEEzwpOLrSSk+uGjd5GFlppInQmE34vv0xFejon3nnn3Ae0vhqufwMO/gIrHgetSS8AK0S9ahHsTFgXb2J/P1an4ueZyQWkxudegsiEEEKIpk0SPCsIcrfH0cZAXHIBbdzasD9rv7VDEnVk17EjrmPHkP3lfIr37Dn3ATGToOf9sPlT+GtWwwcoRBPSfWgo5gqNzT+eeZh6ZYWZTT/E8/V/NrP0ze1kJRdewgiFEEKIpkcSPCvQ6RSRvs7sSc6jrXtb4rLi0KR3p8nwnj4dvbs7qc/PQKusPPcBV70AkUPh12dg7/cNH6AQTYSrtz3t+vqzd30K2amnJ24njuez+NUtbPkpgVZdvDHa6lk5dy/mSrMVohVCCCGaBknwrCTSz5m9KXmEu7Ulvyyf5EJZTa6p0Ds70+KJJyjZvZvsBQvPfYBOB8M/goCu8O1kOP53wwcpRBMRc10wBqOOjcviq7ed7LVb8soWivPKuG5aFNfc0Y4rx4WTfjSfbb+e37y9ynIzh7amU1Yic2GFEEI0f5LgWUl7fxeKyipx1gcBsDdzr5UjEufD+frrcOjZkxNvvUV5Wvq5DzDawbgF4OxnWVnzhAzLFQIs5RU6XdOS+O0nSI3PrdFrFxbjzbjnuxPS0QuAsC7ehHXxZvOPR8hMqtvqtGazxq+f7eGXT3bz5XMb2bsuGbNZRkwIIYRoviTBs5J2fpZi2UX53tjqbdmSelmUAWw2lFL4PP8cWnk5aa++UreDHDxh/HegN8G8EZCb1LBBCtFERF/VEntnE798upslr2yhKK+MwVOjuHpSO2wdjDXa9h3XBht7A7/P2UvlOYZqaprGnwv2E7/9BJ2ubomLpx1/fLmPr1/ezPF9WQ15S0IIIYTVSIJnJWHejpgMOvanltClRRc2pWyydkjiPJmCgvCYehf5P6+gYO3auh3kFgy3LIHSPPhyBBTJm0whjDZ6ug8JpSCrlLAYb25+vjuh0V61trVzNNHv5rZkHC9g689Hz3rev384wt61yXS5NoieI8MY8WhnrrmzHWUlFXz/v1h+en8nOWlFDXFLQgghhNVIgmclRr2Otj5O7EnOpbtvdw7nHuZE0QlrhyXOk8edd2IKCSH1hRcxFxfX7SDfDjD2K8iKhwVjoUzeYAoR2duPCa/0rLXX7t9CO3nRplsLti5P4MSx/Frb7PzjOFuWJxDZy5fuQ0MBS89765gW3DyjO1cMCyXpQDYLXtjE2q8PUFJYXu/3JIQQQliDJHhW1M7Phd1JeXTz6QbAplTpxWtqdCYTPjNmUJ6YSMaHH9X9wJA+MPJTy4IrSyZKIXQhAEc32zq37TOmDbaORlbO3Utlec2hmgc2p7J20UFCOnpy5c3hKKVq7DcY9XS5NphbX+xB216+7PojkcWvbjnnkE8hhBCiKZAEz4ra+TmTW1yOky4IFxsXGabZRDl074bL0KFkfvYZpYcO1f3AyKFw/X/hwAr44QEphC7EebB1MNL/1rZkJhWyefk/dfSO7clk5edx+LV25Zo726HTn/nPnL2zif63tGXQlPbknSjm8NY6LJgkhBBCNHKS4FlRe38XAPYmF9DNpxubUjZJPbwmyvvxx9Db25MyYwaa+Tx6AbreAVc+AbFfwsoXGi5AIZqh4A6etO3hw7ZfjpGWkEfqkVx+/ng3bn4OXHd3BwxGfZ3OE9rRC9cW9uxYeVx+BwshhGjyJMGzorY+Tuh1ir3JuXT36U5KYQrH849bOyxxAQzu7ng/+gjFW7aS+91353dwvyegy0RY9xb89X7DBChEM9X7ptbYO5v47bM9/PTeTuydjNx4X0ds7Ax1PofSKToODCT9aD4ph3MbMFohhBCi4UmCZ0W2Rj1hXo7sTs6ju293ADambLRyVOJCuYwYgV2XLqS/9joVWeexOqZSlqGaETfCL0/C9i8bLkghmhkbeyP9x7clN70YpVcMeSAaBxeb8z5P+BU+2DgY2LFSHrIJIYRo2iTBs7J2fs7sSc4lyDkIHwcfSfCaMKXT4fvCDCqLikifOfP8DtbpYcSn0GoALLsXdi1pmCCFaIaC2nkweGoUIx7ujIuX/QWdw2jS066PP0diT5B7oo4r4gohhBCNkCR4VtbO34W0vFIyCsro7tOdzambMWuykltTZRMWhscdk8hd9j2Ff/11fgcbbWHMfAjuDd9Ogb3fN0yQQjRDodGWeXQXI+rKAJRS7PxDevGEEEI0XZLgWVk7P2cAdlfVw8spzWF/1n4rRyUuhufUqRiDWpIyYwbmkpLzO9hkD+MWgH8XWDIJDvzaMEEKIU7j6GZDWIw3cetTKC2W0iVCCCGaJknwrCzK3wWDTrH5SFb1PDwpl9C06Wxt8Z0xg/Kjx8j46Dxq451k4wS3LIYWkbDoVohfXe8xCiFq13FgIOWllcStT7Z2KEIIIcQFkQTPyhxsDEQHurL+cCbe9t6EuoSyMVXm4TV1Dj164DJ0CJmfzj6/2ngn2bnC+KXgEQYLxsHR8xzuKYS4IN5BzviGubBzVSJmKXwuhBCiCapTgqeUekAp5awsZiultimlrmno4C4XvcI82ZWYQ25xOd19u7MtbRvlleXWDktcJO/HH7fUxnv+PGvjnWTvDrctBZcAmH8TJG6t9xiFEKeLHtiS/KwS4mMzrB2KEEIIcd7q2oM3SdO0POAawA0YD7zaYFFdZnqFeWLWYGN8Jt19u1NcUcyOEzusHZa4SAZ3d7wfe4zirVvJWXKBq2I6esNty8DBA74cDik76zdIIcRpgjt64uxpKyUThBBCNEl1TfBU1efrgHmapu05ZduZD1LqWqXUfqXUIaXUE7Xsb6mU+kMptV0ptVMpdV3dQ28+ogNdsTfpWX8og64+XdEpHZtSZR5ec+AyYjj2XbuS/sZ/qci4wN4AZz+Y8AOYnOCLIZAcW68xCiFq0ukUHfoHkhqfS9qRPGuHI4QQQpyXuiZ4W5VSv2JJ8H5RSjkBZx1zppTSA7OAwUAkME4pFfmvZs8AX2ua1gkYC7x/PsE3FyaDjm4h7qw/lIGzyZl2Hu1koZVmQimFzwsz0IqLSXvlIjq9XVvCxJ/+SfKSZLimEA0popcvJls9O1Yes3YoQgghxHmpa4J3B/AE0FXTtCLACEw8xzHdgEOapsVrmlYGLASG/quNBjhXvXYBLttly3qHeXL4RCGpuSV09+3OrhO7KCovsnZYoh7YhIbiMWUKeT/9RMHadRd+IrdgS5Jn5wZfDINj8hBAiIZisjUQ2duPQ9tOkJ91nuVOhBBCCCuqa4LXA9ivaVqOUupWLD1vuec4xh84dQJDYtW2U80AblVKJQLLgfvqGE+z07OVJwDrD2XQ3bc7FVoFW9K2WDkqUV887pqCKTiY1BdewFxcfOEncm0Jty8HBy/4cgQkrK+/IIUQNUT1DwBNY9fqRGuHIoQQQtRZXRO8D4AipVRH4GHgMPBFPVx/HDBH07QAqub3KaVOi0kpNUUptUUpteXEiRP1cNnGp62PEx4OJtYfyiDaKxqTziTDNJsRncmEzwsvUJ6YSPp/37y4k7n4w8Tllrl580dB/J/1E6QQogZnDztCO3mzd10yZSVS+FwIIUTTUNcEr0LTNA3LEMv3NE2bBTid45gkIPCUrwOqtp3qDuBrAE3T/gJsAc9/n0jTtI81TYvRNC3Gy8urjiE3LTqdokcrD9YfzsBGb0Mn706S4DUzDt274TZ+PNlffnlxQzUBnHzg9p8swza/Gg2HVtZLjEKImqKvCqS0qIItyxMuqC5eUV4Z6UdloRYhhBCXTl0TvHyl1JNYyiP8VNXLZjzHMZuB1kqpEKWUCcsiKt//q80xYCCAUioCS4LXPLvo6qBXmCdpeaUcPlFAd9/u7M/eT2ZxprXDEvXI++GHsGkdRvJTT1KRnX1xJ3P0hgk/gmdrWDAWDvxSP0EKIar5hLrQqrM32389xqKXN3M8LqtOx5UWV7Bx2WHmPbOBxa9uYc/afz/fFEIIIRpGXRO8MUAplnp4qVh6414/2wGaplUA9wK/AHFYVsvco5R6USk1pKrZw8BkpdQOYAFwe1VP4WWpd9jJeXiZXOF7BQCbUzdbMyRRz3S2tvi9/jrmnFxSn3uOi/5xd/CA274H70hYeAvs/fczFCHExRo0uR2D74qioqyS79+O5af3d5KTVvsiWBVllWz79SjzntnA1p+PEtLBk5aR7qyev1/m8gkhhLgkVF3fYCqlWgBdq778W9O09AaL6ixiYmK0LVua7+IjfV5bRVsfZz68tRN9FvbhmuBrmNFzhrXDEvUsc/ZnpL/+Or4v/wfXkSMv/oTFOTD/JkjaAje+A53HX/w5hRA1VJRXsnNVIluWJ1BZYaZD/wBirg/Bxs6AudJM3IYUNv+UQGFOKS3beXDF0FC8WjpRWW5mxSe7SdiZQe+bWtNxYOC5LyaEEEKchVJqq6ZpMbXtM9TxBKOx9NitxlLg/F2l1KOapi2ptygFYOnF+3FnCpqmiPGJkXl4zZT7xNspWLOG1Jf/D/uuXTG1bHlxJ7RzhduWwqJb4ft7oTgbet1fH6EKIaoYjHo6Dwoi/AofNi2LJ3blcfZvSqVdH38ObU0nJ60In1Bnrp4UiX8bt+rj9EYd105pz6+z97Bu8UHMlRqdrjn3/3lzpZnUI3k4e9ji6GbbkLcmhBCiGalTD17VEMqrT/baKaW8gN81TevYwPGdprn34P2wI5n7Fmznu7t7srdwOa/+/SorRq7A3/HfFSZEU1eekkL80GHYhIQQNP9LlKFOz1vOrqIMvpsCe76D3tNh4POg1MWfVwhxmvSjeaxbfJCUQ7m4+zlwxdBQgjt4os7wf66y0szvn+/l0JZ0ug8NJWZwcK3tyksriduQzI6Vx8nLsNTgc/a0xS/MFb82rvi1dsXZ0+6M1xFCCNH8XXQPHqD715DMTOo+f0+ch56tPADYcDiTaztZ5uFtStnEiNYjrBmWaABGX198ZzxP0kMPk/HhR3jde8/Fn9RggpGzwdYF1r1l6cm7/k3Q6S/+3EKIGryDnBn+cGdyTxTj7GmHTnf2hEuv13H1xEh0OsWmZfGYK8x0vSGkOlErzC1l1+pEdv+ZRGlRBT6hLnS7MZSSgnKSD+aQsCuTfRtTAXBwMeHX2pXgDp606ebT4PcqhBCi6ahrgrdCKfULloVQwLLoyvKGCeny5uFoQ4SvM+sOZnB3v+542XmxMWWjJHjNlPN115G/ejUZH3yAY+9e2EVHX/xJdXq44X9g5w7r3rTMzxvxiSX5E0LUK6UUrt72dW6v0+sYeHskOr1i808JmCs12nT3Ifb3Y+zflIq5UiM02ovoq1ri28ql+riOAwPRzBrZqUUkH8oh+WAOyQeyObglnbKSStr3lVEeQgghLOqU4Gma9qhSaiTQq2rTx5qmfddwYV3eeod5MHfDUUrKzXTz7cZfyX+haZoMx2mmfJ59lqItW0h67HFCv/sWnYPDxZ9UKbjqebBzg9+ehdI8GPMlmOrh3EKIi6LTKQaMj0CnU2xdcZStK46iN+qI7OlHx4GBuLaoPWFUOoW7nwPufg607+uP2azx06ydrF10AA8/B3zDXC/tjQghhGiU6jzMUtO0bzRNe6jqQ5K7BtQzzJOySjNbjmYR7RVNVkkW6UVWWbRUXAJ6Jyf8Z86k/PhxUl95pX5P3ut+GPIuxK+GL4ZCUd1qeAkhGpbSKfrd0pbuQ0LodmMIE/6vJ1feHH7G5K42Op3i6kmROLnb8vPHuynILm3AiIUQQjQVZ03wlFL5Sqm8Wj7ylVJ5lyrIy023YHeMesX6Q5nVi6ukFKZYOSrRkOy7dsVj8mRyl3xD9qKv6/fknW+Dm+ZCyg747FrIlVpcQjQGSqeIuS6ErteHYOd0YUOobR2MDJ4WRUVpJT9/tIuK8sp6jlIIIURTc9YET9M0J03TnGv5cNI0zflSBXm5cbAx0CnQjfWHMqoTvKSCJCtHJRqa1/334dCnD6kvvUThxnoujxE5BG79FvJT4NOrIT2ufs9/gTRN47afb2N5vEzpFeJCefg5ctXtkaQn5LFmwQHqWt9WCCFE8yQrYTZSvcI82Z2ci73Osqqm9OA1f8pgwP/N/2IKDiLxgQcoPXKkfi8Q0gcmLgetEj4bBEf/qt/zX4DC8kK2p29nQ/IGa4ciRJMW2smLmOuCiduQwu4/5YGgEEJcziTBa6R6hXmgabD9aBHutu7Sg3eZ0Ds5EfjhhyidjsRpd1OZm1u/F/CJgjt+AwcvmDcM9lm35yyzJBOA4/nHrRqHEM1BtxtCCI7yYN3XB0k6kG3tcIQQQliJJHiNVMdAVxxMetYfzsDPwY/kgmRrhyQuEVNAAAHvvUt5UhKJDzyIVl5evxdwC4JJv0CLdrDoFtg6t37Pfx6ySiyLviTmy7xAIS6W0imumtQOZy87fvlkN/lZJdYOSQghhBVIgtdIGfU6uod6sOFQJr6OvpLgXWbsu3TB56UXKdq4kdT/vFz/c2ocPOG276HVAPjhfvjzdbDCvJ3MYksPXnpxOiUV8mZUiItlY2fgumlRVJSb+fnDXVSUyaIrQghxuZEErxHrFeZJfEYhLsYWpBSmyMT5y4zrsGF4TJ5MzqJFZM/7sv4vYOMI4xZCh7Hwx3/gp4ehsqL+r3MWJxM8kIWEhKgvbj4OXD2pHSeO5fPLJ7spKaznUQAXKSetiHVLDlJWcml/3wghxOVCErxGrFeYZYGVwgInSitLq+cricuH1/QHcbxqIGmvvkrBmjX1fwG9EYZ9AL0egC2zYeHNUFpQ/9c5g1N/pmUenhD1J6SDJ33HtuHYniwWvfw3KYfreT7vBSovrWT5h7vY8ftxtq04au1whLVlxUPqbmtHIUSzIwleIxbewglPRxPJGbYAMkzzMqR0OvxnzsQmPJyk6Q9RevBg/V9Ep4OrX4Tr34RDv8HngyHv0qzamlWShVFnBCTBu1S+OfAN3x781tphiEsgql8AIx7tgk6n+O6/29iyPAGz2bojQdYsOkB2aiHeQU7E/n6cvIxiq8YjrOyXp+HbKdaOQohmRxK8RkwpRc9WnsQlWt4AS4J3edI5OBD4wfvo7O05NnkKZccbKBHqegeMWwSZh+HTqyBtT8Nc5xSZxZm0dGqJg9FBErxLZO7euXyx5wtrhyEukRYhzox+uhthnb3Y9H0837+9ncKcUqvEsm9jCvs2pBAzOJjBUzugdLDh20NWiUU0ErnHLR9CiHolCV4jd2UbLzJzHQBILpQE73Jl9PEh8NNP0IqLOTphAmWJDTRfrc01MOlnS6282YPg0MqGuU6VzJJMPOw8CHQKlATvEig3l3M8/zjH8o9RYZb5T5cLGzsDV9/Rjv7j25J2JI+F//mbhF0ZlzSGrJRC/vxqP36tXel6fTCObjZ0HhTE4W0npKTD5Sw/DUrzLunUACEuB5LgNXLXtGuBjc4Ok3KUHrzLnG14OC0//wxzQSHHbr+d8pQGGkbp2xHuXGkppzD/pgYto5BZnImHrSXBk1IJDS8pP4kKcwXl5nL5fXKZUUoR2cuP0U91xcHFhp9m7WTd1wcpLz3/VTZLCsrZuiKBHSuPU1lpPmf78rJKfvlkN0YbPdfc0Q6d3vLWo9PVLXF0t2Ht1wetPnRUWIG5EoqqHjTkX5ppAUJcLiTBa+ScbI1cFdGC8lJXEvNllcHLnW1kJC1nz6YyN5ejE26nPC2tYS7k4g8Tf4bQfpYyCr+/AOZzv5E7X1klWbjbuRPgFEBSQRKVZlnSvSEl5CXU+lpcPtx8HBj1RBei+gewY9Vx5jyxnjWLDpCVUnjOY/Myi1m76ABzn1rPxqXxrFt8kG9mbiUr+ezHrl1oOf9VEyNxcLWp3m4w6ek5IozMxALi1ssDh8tO4QnQqv6u5Mm/vxD1SRK8JmBItB9lJS4czpYhbALsotrT8tNPqMzM5NiE2ylPT2+YC9k6w82LoPMEWPcmLL4NSvPr7fSllaUUlBdU9+CVm8tJL2qgexEAJOQmVL8+knvEeoEIqzIY9fQd04aRj3UhOMqDPWuTWPDCJr777zYObkmjsqLmw5yMxHx++2wPXz67kd1/JhHW2Zuxz3bj2intyc8q4ev/28z2X4/V2gu3f2MKcRtS6HJtEC0jPU7bH9bFG98wFzZ9H09psQwbvqzkp57yWnrwhKhPBmsHIM6tX7gXxpUepBcfRNM0lFLWDklYmV3HjgR+8jHH7pzMsYmTCJo7B4OnZ/1fSG+EG98Gzzbw23PwyUAYOx88W1/0qU/WwPOw88DP0Q+wrKTp6+h70ecWtUvIS8Dd1h1N0yTBE/iEuuAT6kLvm1oTtyGFPWuT+PXTPdg5m4js5UuLEBd2r07k2N4sjDZ6OgwIoOOAQJzcLSs7e/g74hvmyp9f7WfDt4c4suMEAyZE4OptD1jm3a2umnfX7YaQWmNQStFndBu+fmUzW346Qq9RF/+7RTQRBaeMQJEePCHqlfTgNQE2Bj2RXkGYKSMl/9JOjBeNl33nzrT86EPKk5M5NnESFdkNtFCBUtDzXrhtqWW+xCcDYN/yiz5tVkkWQHUPHkiphIZ2JPcIwc7BBLsEyxBNUc3OyUTnQUHc+mIPbri3Iy2CnNi64ijL39/JieP5dB8aym3/15Peo1pXJ3cn2TubuPau9lw1MZLM5EIW/edvdq1OpLy09nl3tfFq6URED192/pFITlpRQ9+uaCykB0+IBtOgCZ5S6lql1H6l1CGl1BNnaDNaKbVXKbVHKfVVQ8bTlPVrFQ7A0j0Nv3S9aDrsu3Yl8IP3KTt2rGGTPICQvjDlT/BoBQvHwaqXL2pe3skePHdbd3zsfTAogyR4DSwhL4Fgl2BCXEJqDNcUAkDpFEHtPbj+no6M/08PrpsWxW3/15OYwcHYOhjPfJxShHf3Ydxz3fALc2XNwgPMe/avWufdnUn3oaHojTrWfyNlEy4bBVVD8t1DpQdPiHrWYAmeUkoPzAIGA5HAOKVU5L/atAaeBHppmtYOeLCh4mnq+oVaErzfDsRZORLR2DhccQUB78+iLD6ehDFjKY2Pb7iLuQbCxBUQfSuseQ0WjIHiC0sqM0v+GaKp1+nxc/STBK8B5ZbmklWSRYhzCMHOwWSWZJJXlmftsEQj5exhR0hHLwxGfZ2PcXSz5Yb7OtLvlnAqyyrpen1IrfPuauPgYkPM4GASdmZwbG/mWduWFJRjrsPqnaKRK0gFOzdwDZIePCHqWUP24HUDDmmaFq9pWhmwEBj6rzaTgVmapmUDaJomKyycgb+zZY5SXHoC2YVlVo5GNDaOvXrRcu4czIWFJIwZS8H69Q13MaMtDH0Prv8vHP4DPu5/QUXRT+3BA6QWXgM7OSQz2CWYYOdgyzbpxRP1TClFuz7+3PFm3zPOuzuTjgMCcfa0Zd3iQ9UJnKZpZKcWsnddMr/P2cu8ZzYw+5G1zH9+I3vXJZ+2IIxoQvJTwdEHnP0gr3EleJWVZvZtTJEHCaLJasgEzx849d1aYtW2U7UB2iil1iulNiqlrm3AeJo0Z5Mz9gZHNEM2P+1qXL8IReNg36kTIV8vwujry/Epd5G9YEHDXUwp6Hon3P4TlBfDp1fB1jmg1b2WVVZJFg5GB2wNljk9AU4BJBZILbyGcjKZC3a2DNEEKZUgGo5Od/6LgemNOnqNak12SiErv4hj+Qc7+ezRdXw1YxN/fLmPY3sy8QxwovuQUGwdjPzx5T6+fPYvdv5xnIoyKbHS5BSkgaM3OPlaXjeiMjnx20+wck4ch7ZKv4Nomqy9iqYBaA30AwKANUqpKE3Tck5tpJSaAkwBaNmy5SUOsfEIdPKnoiif72OTufWKIGuHIxoho78/QV99RfLDD5P6wouUHo6nxROPowwN9F+9ZXe460/47i744QE4+Bvc+A44nHtY1ski5ycFOgWSX5ZPbmkuLjYuDRPvZexI7hEMyoC/k+U5m0EZZCVN0eiEdPQkMMKNA5vScPa0Jbi9B76tXfFt5YJrC/vqVaS7DA7ieFwWW5YnsHbRQbb8fJToqwJp39cfk62139qIOslPg6Ae4OwLWqVlTp5z41hFOelADgBHdmTQppuPdYMR4gI05G/BJCDwlK8DqradKhHYpGlaOXBEKXUAS8K3+dRGmqZ9DHwMEBMTU/cugmbGz9GPEwWH+XtnFonZRQS42Vs7JNEI6R0dCHh/Fumvv0HWnDmUJSTg/9ab6J2cGuaCTj5w63ew8X1Y+QJ80AOGvQ9hV531sMySTDzsaiZ4YFlJUxK8+peQl0CgcyBGnWWxjACnABmiKRodpRTXTetAWUkl9s6ms7ZrGelBy0gPkg9ms+Xno/z17WG2/XKU6IGBdBoUhP4sK3cKK9O0qh68FuBkmYJCfnKjSfCSD1jmlh/dnUlluRm9UX6WRNPSkD+xm4HWSqkQpZQJGAt8/682S7H03qGU8sQyZLMBV4ho2vwc/SjWMgCNH3bIME1xZkqvp8UTj+Pz4gsUbtxIwrhxlCU24PBHnc5SSmHyKrBzhy9Hws+PQ3nJGQ+prQcPpFRCQ0nITaieewdYVtKUIZqiETKY9GdN7v7Nr7UbQ+6PZtTjMfi2cmXT90f4bfYemT/VmJXkQGWp5QHhyaSukczDK8wtJTu1CP82rpSXVpJ4oAFXpxaigTRYgqdpWgVwL/ALEAd8rWnaHqXUi0qpIVXNfgEylVJ7gT+ARzVNO/vyWZcxPwc/iiuK6NjSxLLYf3eGCnE6t9Gjafnpp1ScyCDhptENu/gKgE8UTPkDuk+FTR/CJ/0hdXetTbNKsqoXWAFLjxJIgtcQKswVHMs/RrBLcPW2YJdgjuYdpbIRzXsR4mK0CHHm+rs70GtUGIe3neD3OXGYzZftoJ/GLb+qyHmNHrzGkeAlH8wBoNuQUAw2eo7EnrBuQEJcgAbtc9Y0bbmmaW00TWuladrLVdue0zTt+6rXmqZpD2maFqlpWpSmaQsbMp6mzt/RMnemd4SOfan57EuVJc7FuTlc0Z3ghQsweHpw/M7JnHj3PbTKBnxTb7SDwTPh1m+gKNOS5K17q0ZvXoW5gpzSnBpDNO0MdnjaeUqC1wCSC5IpN5cT4vzPqoYhziGUm8tJLpD6U6J5ib6qJVcMC+Xg5jT++HIfmiR5jU9BVZFzxxbg4AU6Q6OphZe0PxuTrR6fEGeC2rlzZEeG/AyJJkcGFTchvo6WYQxhfhXodYplsY3jl6Fo/GxCQghetAiXIUPImDWL45MnU5HZwJ3lYVfBtA3Q+hr4fQa81xV2LAKzmeySbDS0GkM0QUolNJSTQzFPrp556usjebLQimh+ulwbTNfrg9m3IYU/Fx5AO48Vfs+kstLMwS1plJVU1EOEl1aj68k82YPn5GMZ4u/o02h68JIO5ODb2hWdXkdIRy+K8spIOyoP1EXTIgleE3KyBy+/Ip0+rT35Pja58f3SFo2Wzt4e31dfwffl/1C0dRtHhg2naMuWhr2ogyeMnQ/jl4KdK3w3BT7uS+bBnwFq9OCBJcFLzJdSCfXt5GqZp87Bk1p4ornrekMInQcFsWdNEuu+PnjRSd6WnxL49dM9fPPaVnLSiuopyoaXk1bE54+tI/b3Y9YO5R8FpwzRBMs8vEbQg1eYW0pOWhH+rd0ACGrvgU6nOBKbYeXIhDg/kuA1Ic4mZxyMDiQXJjM02o+knGK2HJXJv6LulFK4jhxJ8KKF6OztOTrhdjI//RTN3MCLEbTqD1P+hBGfQkkuWSseBcC9MKtGswCnANKL0imtLG3YeC4zCXkJuNq44mrrWr3N1dYVVxtX6cETzZZSiiuGhdJxQCA7/0jkr28PX3CSl5FYwLYVR/EPd6Uot4zFr24hYVfTeNO/4dtDlBSUs+GbQxzd00iWOShIA6M92FSt7uzk2yh68JKryiP4h7sCYOtgxK+NK0d2yDw80bRIgteEKKXwdfAluSCZayJ9sDXqZLEVcUFs27Yl+JslOF19Nelv/JfEu++hMienYS+q00GHm+DeLWRGjwXA49tp8M1kyD4KWHrwNDSS8uXnuj4dyT1So/fupGDnYOnBE82aUopeN4XR/kp/tv92jL9/OP8HGuZKM3/Mi8PGwcC1k6O46akYnD1t+en9nWz+6Ui9zM8qL6tk95okSovKL/pcp0o6kM2RHRl0uTYId39Hfv10T+PofcxPtfTeVdU1xNmvUayimXTAMv/OM/CfskIhHb3ITi0iO7XQipEJcX4kwWti/B39SS5IxsHGwNWRPvy0K4WyClkKWpw/vaMj/m+9SYtnnqFg/XqOjBxFyd69DX9hgw2Z/p0A8Og2FeK+h/diYMVTBBot9e9kHl79SshNqDH/7iQplSAuB0op+o5pQ2QvX7YsT2DL8vNL8mJXHif9aD59xrTB1tGIs4cdIx/tQnh3H/7+4QjLP9xFafGFz8sryitj6Zvb+fOr/ZZFYephviCAZtZYv+QQjm42dLkumOumRqHTK5Z/sPOi4q0XJ2vgneTkC2X5UJpvvZiwzL/za+2KTqeqt4V09AQsRc+FaCokwWtifB18SS60jFMfFu1HTlE5aw/K0AFxYZRSuN96C8FfzkOrrCRh3M3kLlvW4NfNLMnEpDPhcPV/4L5t0GE0bPqAwK9uBeB4jpTDrC/5ZflklmTWKJFwUrBLMBnFGeSXWfdNlRANTekU/W5pS3h3HzZ9f4Rtvx6t03E5aUX8/cMRQjp6EtbFu3q7waRn4IQI+oxpzbHdmSx5dQtZKeffw5OdWsg3r20hK6mAsC7eHN52ggN/p533eWpzYHMaJ47lc8XQUIwmPc6edlw7pT256cX89tke687hz08Fp1MSPOeqUglW7MUrzLHMv/Nr41Zju5O7LV4tnWSYpmhSJMFrYvwd/ckvyyevLI++bbxwszfy7TYZziYujl3HjoR8swS7Dh1IfvwJUl/6D1pZWYNdL6skCw87D5RS4OIPQ2fB1PW4BXTH3mzm+Po3YNs8kBptF+3kEMwzDdE8tY0QzZnSKQbc1pawGG/++vYwO1aefaSAZtb448t96A06rhwXbvl9der5lKJD/0CGTo+mtKicJa9u4eCWtDr3wCUfyuGb17dSXlrJsIc6c/Ud7fBt5cKahQfIzyo59wnOoqKsko3LDuPV0ok23Xyqt/u3caP36NYc3ZXJpu+t+CCtIN2ycuZJTlXFzvPrvtBKpbmSjSkb6y2kpIOWNQ3827ieti+koyepR/IozJX54aJpkASvifFztDzlSilIwajXcVNMID/vTuFopowNFxfH4OFBy88/w/3228meP5+jEydRnp7eINfKLM48rUQCLSJRt3xNoFNLjtvYwvf3wge9YP/PUE9Dli5HJxdRqa0H7+SwTRmmKS4XOr2OqyZGEhrtxbrFB9m95swPSPesSyb5YA69RoXh4GpzxnZ+rd0Y/VRX3Hwd+PXTPSz6z2b2b0qlsvLM0ycObknj+//FYudoYuRjMbQIcUanUwy8PQKzWWPl3LiLmtu3Y9VxCrJK6TkyDKWrmZi2v9KfyN5+bFtxlINb6qe38LyUF0Npbp168I7vy6I4v/aHjasTVzP518nsOrGrXsJKOpCDyc5QY/7dSaHRXqBBwk4ZpimaBknwmpiTCd7J4sR39g7BoNfx4Z+HrRmWaCaUwUCLJx7H779vULJ3LwkjR1G0bXu9XyezJPO0EgknBXq0JdHNH0Z/AZVlsGAsfD4Yjm2q9zguBwm5CeiVnkDHwNP2BTgFYFCG6jIKQlwO9Hod19zZjuAoD/78aj9715/ea5SfVcKGbw8R0NaNiJ6+5zyno5stIx7pzMAJlgTt98/38uUzf7Fj5fEadfM0TWPbL0f59dM9eAc7MfLRLrh42VXvd/Gyp/eoMJL2Z7Nz9YWVjCnOL2PriqMEd/AkINzttP1KKfqObYNvKxdWzY3jxLFLPEQ7/2SR87P34OWkF/H9/2JZPX9/rac5uRjX7szd9RJWci3z705y93PA2dNW5uGJJkMSvCamOsGrmofn7WzL6JgAlmxNJCW32JqhiWbE5frrCV64EGVnx9EJE8j66qt6m/gPlh48d1v3WvcFOgWSlJ+EOeJGuGcTXP8mZMXDZ9fAgnGQHldvcVwOEvISCHQKxKg3nrbPqDMS4BQgPXjisqM36Bg0pT2Bke788eU+9m9Krd6naRqr5+9HM2v0v7XtaUMzz3bOtj18GfdsN66/pwPOnnasW3yQL57awMalhynILmXNggP89d1hwmK8GfJANLaOp/+/jOztR3CUB399d/iC5vVt/vEIFWVmeo5oddZYr70rCltHI8s/3ElRXsMNyT/Nv2vgAZjswdalRg/enrWW9znxsSdISzi90Hh6kWWESVzmxf9NODn/rrbhmWBJikOivTi+L6tJFroXlx9J8JoYNxs37Ax2JBX8M6zkrr6tMGvw8RpZmELUH9vwNoQsWYxjz56kvfgSKU8+hbnk4uaFAJg1M9kl2WfswQtwCqDMXGb54603Qtc74P7tMOBZSFgHH/SEpXdDjqy0WRdnKpFwUrBLsPTgicuSwajnuqlR+LdxY+WcvdXDFQ/8ncaxPZlcMbQVzp525zjL6ZROERzlyfCHOzPy8S4EhLux9ZejzH1yPbvXJNHpmpZcM6kdBqO+9uOVot+tbTGa9Pz++d6zDvX8t+zUQnavTaZdHz/cfBzO2tbe2cTgqVEU55fz0/s7ObIzg4qySzDv+WQP3qlDNAGc/Kpr4VWUV7JvQwotI92xdTSyadnpo5SqE7ysi0/wkg6cnH93eo/nSaEdPTFXaBzbk3XGNkI0FpLgNTEna+GlFPzzlCvQ3Z6h0X4s+PsYmQUyAVjUH72zMwEfvI/nPfeQu3QpR2++hfKki1vUJ680jwqt4vQ5eFUCnSxDCWuUSjA5QN9H4IEdcMXdsGsJvNsFfnkaChtJ4d5GqNJcybG8Y7XOvzspxDmEY3nHqJQFbcRlyGDSc/3dHfBp5cJvn+1lz9ok1n59AJ9QZ6L6B1z0+X1CXLj2rihumXEFHfoHMOC2tvQccfq8uH9zcLGh363hnDiWz5blCXW+3oZvD2Mw6eh2w+llUWrjHeTMVbdHkpNayPL3dzL74bUs/2Ane9cnN1yvXkHV3O5Th2gCOPtCnuXvy+Gt6ZQUlhN9TUu6XBvE8bhsEvdn12ieVmRJyA9lH6Ks8uJiPTn/ziPA8YxtfEJdsHU0ymqaokmQBK8J8nP0q9GDB3B3vzBKK8x8tl6exIv6pXQ6vO67l4AP3qfs+HGOjBxF4YYNF3y+zBJLQna2IZpwhlp49u4w6GW4bytE3QQb34e3O8LKl6BInqr+W3JhMmXmsnP24JWZy6qHfQtxuTHa6Lnh3o54Bzmxev5+yksr6X9rRK1zsS6Uawt7+oxpQ0RPvzof06qTN+FX+LD156OkHTl9iOK/Je3PJmGnpai5nZOpztcJ6+LNpDf6MOT+aCJ6+XHieD5/zNvH54+vY8nMLWxdkXDRq3rWUJAKSg/2/3rI5/RPsfPda5Jw8bYjoI0b7fv64+Bqw6Zlh2tMFUgrSsPeYE+FVsHBnIMXFVLSgewzzr87SafXEdzBk4RdmefVqyqENUiC1wT5O/qf9mYszNuRwe19+GLDUXKLy60UmWjOnPr3J2Tx1xi8PDl252QyP/30gublZZVYErEzDdH0cfDBoAxnL3buGgjDZsG0vyBsIKx9w5LorXoZirPPfNxl5mT5g9qKnJ9UvZKmlEoQlzGTrYEb7+tIcAdP+oxug7vf2Yc3Xip9xrTBwdXE73P2Un6W4ZOaWWP9N4dwdLeh44DTF1Q6F71BR2CkO33HtuG2l3sy5pmudLshBM2ssXFpPItf2UxOetHF3Mo/8tPA0Rt0/3oL6uwLhelkHM0hNT6P9n39UTqFwaSn6/XBpMbncXS35QGhpmmcKDpBL/9ewMXNwyvILiU3vfiM8+9OFdrRk7LiCpIP5Fzw9YS4FCTBa4J8HXzJLc2lsLzm5Ou7+4WRX1rBvL8SrBOYaPZMwcEEL1yI06BrSH/jvyRNfwhz4fktApBZbPkDfaYhmgadAV9H37MneCd5t4XRc2HaBgjtB2teg/91hD9egeKc84qrOTq5eMrZhmhW18KThVYuiKZprDiygnKzPFhr6mzsjVx/dwfa9/W3dijVbOwMDJwQSU5aEavmxvH/7J13eFNl+8c/J6t77z1ooS1Q9haQKXsoiANRUXzde77v6/65F65XRcWJiDjYIFPZldUWSil0l+4906ZJzu+P05SWpm3SBWg+15Ur6cnJOU/T9OS5n/u+v98zh3JJisnj3NF8Uk4UkBZfRMapYo5ty2gwNe+FQmW8t89UBEHA3d+BYTNDWPjMMG54djiiCBs/iO0aH7iqvOYCKwYcfEDUc2pPCnKlJFhjIGK0D44eNhxen4qoFymrK0Oj1zDYczAOSodOBXim9N8Z8I90RaGUWdQ0LVz2WAK8KxA/e+nLx2CVYKCfnxNX9/Hgy/1p1GgsKk8WugeZnR1+776L5xNPULl9O2mLFlGXZnppsKFEs7UMHkhlmucrzZAI9+oLi76Du/dDyFj483V4Pxr+eANqy00/zt+M9PJ0HFWOuFi1PnFxsXbBycrJIrTSQY7lH+OJvU+wK2PXpR6Khb8p/n1cGHxNEMnHCtj1TSI7vzrN9i8S2PbZKbb8L55NH8URsyEVrxBHeg8zEjh1Ejc/e2bdP4Cayno2fhBHXU0nFzMq88HBu+V2R180emvOHi8nfIgn1nYXFEblcqmvsPh8FcnHCxr777zsvIhwi+BMyZkODyfnbClWtm333xlQquQERLmSFlfYpcrSFix0NYpLPQAL5uNjL61q5VTlEO4S3uy5+yeEseDTQ6z+K4s7rjKtydqCBXMRBAG3O5ZiHRVJ9iOPkr7wevzeeRv78ePbfW2xuhi5IMfJyqnVfQIcAjhV1AFvI+/+cMMqyI2HP16HP16FQx/BsDslcRZ7D/OPeQWTVpFGsFNwuzLvwY7BlgxeB0ktl9SLTxefZlrItEs8Ggt/V0bN70X0BH90Wj16nSjd9A2P9dLPHoEO7Yq3dBSvYEdm/Ks/mz6OY8snJ5n9wICOZwqr8sFvcMvtDj6crR1PvQb6jm+ZRQ0f5sXx3zOI2ZBKwJ2SqIqXrReRrpGsSVqDVq9FITN/Wpt9tgyfsLb775oSOtCDtLgiCjMr8QxyNPt8Fiz0BJYM3hVIYwbPiCjC0GBXRoS4smJvCnVaiyqehe7FbtQoQn75GWVAAFl330PxlyvbXdUsqS3BxdoFmdD65SfAIYAKTQXldR3MvvlEw40/wL/2Qq+JsP89WN4PtjwBZZkdO+YVSHp5OiGO7S/0hDiFWHrwOoghMO4KqXYLFtrCztkKR3cbnL1scfW1w93fAc8gR7xDnPANc0bZydLM9giIcmXybVHkJJex/csE9B0RGtFpobrQaAZPdPDhVM003F1r8QpuGTjJZAIj5oRSXqAm44j03eBp60mkWyR1uroOVSFUldZSXmha/52B4P7uCAKWMk0LlzWWAO8KxM3aDSu5VYsSTQP3Twwjv6KOX451Ts7eggVTUPr5EbzqexymTqXgrbfIffoZ9HWt92kUq4tb7b8z4O8gyZObVaZpDJ8BUo/e/Ueg/wI4+hV8MAh+uxsKkzp37MucKk0VherCNvvvDAQ7BlOoLqRKU9X9A/ubkVGRAcCZkjNGFzd0VdXUpbT08LJg4UokfJgXY68PJy2uiD9+SDK/TLG6EBAlkZWLyMtTUawNpl9wRqtVByED3PEMdqTykBVKUYW7jTuRrpFA80UWXb2eU3uzObYtvU3Fy+wGsRRT+u8MWNsr8QlzJvFADvF7zlNV2oUKoxaMotaqWZ+83lIWawaWAO8KxOCFd7FVgoGrwtwZ4O/Ep3+moLVI+VroAWS2tvgtfw/3Bx+gfP16MpYsob6gwOi+xbXFbfbfQTtWCR3BPRzmfgwPxcKwZZCwDj4eAT/eDLlxXXOOywxD4GFKBs8QBFrKNM0nvTwdmSCjrK6ssS+oKUWf/I+0hdcj1ltEWCz8PYieEMDQGcEkHsjl8PpUo/tUFKtJPJjLzq9Os/GDWMryGxQ4qxpMzi/2wANO7ctBJVPT2zm+1XMLgsDIeaFQpWRo8WQUMgXBjsFYy61JLE5Ep9Nzen8O3z9/iD9/SOLwulTWv3ui1SAsu6H/zt2E/rumDJ8dgspGwb41Z/nmmYOsfe0Ix7alU5JrnuiYBdPYlLqJ/x74L0mlf++F2a7E0oN3heJr79vM7LwpgiBw74Qw/vXdMTbG5zB/UOfNWi1YaA9BEPC4916swsLIeepp0hdej/9HH2HTv1+z/YrVxQQ5BrV5LH976TPbZQGeASd/mP66ZJoe8ynErIAzmyBiFox/Sirt/Jtg6A0zJYNnsEpIK0+jn3u/dva2YKBeV092VTbDvIcRkxtDYnEi3nbNJ67qo8cQa2qoz81FFRh4iUZqwULXMnx2CDWVGo5vy8DWQUXYUE+yz5aSfUYyJK8okgIqGwclep3Ir28fY/YDA/FQNyyCXFSiqa7UkHy8gL7uCShr2r7uB0S4UuWRT2TGODS1WlTWCvo4R1Bwoo4fNhymoqgWz2BHJiyOoLa6nj3fJ7HmlSNMvj2KoL7NFxezz5bhG+5sdu+iX28XbnphJKV51aTGFpIaW8ThdakcXpeKs5ctoQM96DfeDwdXa7OOa8E4Z4olEZ3sqmwiXCMu8WiuDCwB3hWKr71vm6pRUyK96O1lz//2pDB3gF+XGrZasNAWjlOnogoM5Py995GxeDE+r7yC06yZgCQpX1Jb0m6Jpq3SFjdrt64P8AzYucPE/8Ko+yHmMzj08d8u0EuvkDJLhmxoWwTYByAX5BYlTTPJqsxCJ+qYGjSVv3L/4kzJGSYETmh8Xq/RUHv6NACajExLgGfhb4MgCIy/sQ+1VfXsX3uO/Wslo3ErWwW+4c5ETwzAv48Lrr52lBeoWb/8BOvePc7MKaX4QgubhMRDuei1In2Dz0Ol8cXrppzu9SfDD19P3K4snDxsGL73BuQVNqgCFMy8L5qgfm6NZZ4eAQ5sW3GKTR/FMWRaEMNnhSCTy6gsqaWiUE301R1fBHfxtmPINDuGTAumqrSWtLgiUmMLid2RScrxAhY+MxQrW2X7B2pCbVU95YVqvEIsAi4GDJm71hIbFlrSrSWagiBMEwQhSRCEZEEQnm5jv+sEQRAFQRjaneP5O+Fr50tJbQk19caNR2UygfsmhHGuoIrfE/J6eHQW/ulYR0QQ/PNarPv3I+fxxyl49z1EvZ4abQ21utp2SzShwSqhqpM9eO1h4wxXPwUPx8PV/4a0ffDZ2IbSzdbLhK4E0svT8bf3RyVXtbuvUq7E38HfUqJpJob3K9I1kiDHoBZCK3WnTzeWZmoyMnp6eBYsdCsymcCUpVEMmhLIqGt7sfCZoSx9eywz7olmwMQA3PzsEQQBZy9brn1iCLZOVmzc4k5G3aBmPXiiXiRhXw4+YU64+dhCRS6002uVbHWS+oAS/tqYxo6Vp7FSqdjW5wuG3+fRIIJyYVHbxduOBU8PJXKUD8e2ZrDhfcnPL+dcGQC+ZgistIW9izX9r/Zn7sODmPfoICqLa9n1TSKi3vS+MY1ay7r3jvPzm0cpOm/piQbQ6XWcLT0LQG61JcAzlW4L8ARBkAMfA9OBKOBGQRCijOznADwExHTXWP6O+Nr7ApBX3XrwNrO/D2Ge9rz5exL1ll48Cz2MwtWVoJUrcV64kOIVKzh//wMUFUkZOVdr13ZfH+AQ0H0ZvItpFug90zzQyz/dM2PoYtIr0k0qzzQQ4hhiCfDMpKmRfKRrZIsAryY2VnqgUKDJtAR4Fv5+KJRyRl8XxuCpQXgGObZaLeTgas38xwbjbFfFltJ/cy62rPG5rMQSKgrV9BvvB44+UF8NdRWtnlOtVVOhqcB2bDXB0e5cs6wf4x72J931JGdKjVc2KVVyJi6JZNKtkeSnVbDmlSOc+jNb6r/zM6//zhR8wpwZfV0YaXFFHN9u2v++Tqdn2+enKM2tQWkl5+Av5yyiIkiVEmqtGrAEeObQnRm84UCyKIqpoihqgB+BuUb2exl4A7DIEJmBwSqhNaEVAIVcxtPTIkgrqmb1X/8caXgLlw+CSoX3Sy/i9d//UvXnn1QtfRCPMtHkDF5+dT4anaYHRtqAjTNc/bQU6I1/GtL2wiej4ZdlUHzlKCHqRT0ZFRkEOwab/Jpgp2AyyjPQ6a9Me5UvTn5BbEFsj54zvTwdN2s3HFQORLhFkFedR1ltWePz6rg4lL6+WPXqRX2G5Rps4Z+NraOKedHr8bI9z/YvE0jYJ81fTu3NxsZBSa+BnuAgLV5T0fpEvqBGEvDy9nNh5r3RhA3xJMwlDKVM2a5dScQoHxY8MxRrWwV5qeUd6r8zleiJ/oQN9SRmfSpZZ0ra3FcURfb+kETW6RLG39yHEbNDyUosJfN026+7GL1eJCkmj+ry1pWsrzQMQburtaulRNMMujPA8wOaLr+fb9jWiCAIg4EAURQ3d+M4/pb42F0wO2+LSZGejAx1ZfnOc1TUWlTcLPQ8giDguvhmAj9fAYXFvPa1DrfT7V+k/R38ERG7v0zTGDbOMOEZeCgOxjwEiRvho2Gw4UEovwTjMZPc6lzqdHVmZfCCHYPR6DVX5AppsbqY94+/z7env+3R82ZUZDS+x4bG/6YTTHVcHDYDB6AKCkKTaQnwLFiwUmcxu/9mAqPc+GNVEgd+SSY9vojI0b7IlTIpgwdQ2frcxhDgedle6ONTypWEu4STWNy+H6Wbrz0Lnh7K0BnBDJ7WtuBXZxAEgQmLI3D2tmPHlwlt2ikc/z2D0wdyGTI9iKgxvvQb74ejhw0Hf0k2y2/wxPYMdn51mtUvxXDuaEtV38sZfSulrEklSSgEBWN8xxj1f7ZgnEtmkyAIggx4F3jMhH3vEgThqCAIRwsLC7t/cFcAHrYeKGSKdj/sgiDwnxlRlFRr+PSPKycDYeHvh93o0Zx7604qbIFHXqT0xx/b3N8gDtJpL7zOYOsKU16UAr1hd0LcaslHb+vTUGXcBuJywGBabopFggGDkuaVWKZ5vOA4AHEFcT1a0pRekd6YJTV4cRnEr+rzC9Dm5GIzYACqoEA0588jarU9NjYLFi5LqgpQOrkz457+hA31JHZHJiLQd2xD5s6hIcBrI4NnsCPxtG3upWcokzblGqCyVjBiTijeIU4d+jVMRWWtYPq/+qHV6Nm24hQ6bctg7dzRfA6vSyV8mBcj5oQCIFfIGD2/FyU51SQeNG3RrTCzkr82pBHY1w0nD1u2f5HA9i8TqK3umsX9rDMlfP/sIZKPdf13X9H5Sr5+aj8Hf0lu8VxSSRIhziEEOQZRUltCrdZS8GcK3RngZQNN5dv8G7YZcAD6AX8IgpAOjAQ2GBNaEUVxhSiKQ0VRHOrh4dGNQ75ykAkyfO18283gAfT3d2LeQF++3J9GTpm6B0ZnwYJxcl3gP0vk2I4aRd4LL5L30kut+oN1uRdeZ3DwghlvwgPHIPp6+GsFvD8Adr4ANeaV0PQETXvDTMWw75WopHk07ygABeqCHlvhLa8rp6S2pDHAc7F2wdvOuzGDp46LBcBm4ECUgYFQX099nkXwysI/GFGUfPAcvJArZExZ2pfB1wQyeGogju420j6ODYFeGxm8/GopwGuawQMpwCuvK7/sqhBcvO0ae/8ONKiNGshNLmPX14n4hDkxaUlkM3GY0EEe+PRyImZjGpratheH6jU6tn+ZgI2jiilLo7juicEMnx1CyrECfnwphsyE4g6PXxRF4nZlsfGDOMoL1exdcxaNuusWq8oL1Wz4IA6NWseJHZnE7Wr+nZ9UkkSESwQ+9lLw35b2hIULdGeAdwQIFwQhRBAEFXADsMHwpCiK5aIououiGCyKYjBwGJgjiuLRbhzT3wofex+TJzOPX9MHEXh7u8Uk0sKlo7i2GJWTM4Gfforr0qWU/rCazGV3UZ/fckXQ1doVG4XN5RHgGXAOlAzT7/sL+kyH/ctheTTs/j9Ql17q0TWSVp6Gg9KhXTuKprhYueCocmzM/l1JHMs/hqeNtJp/ouBEj5zTWBAd4RrRmMFTx8YhKJVYRUaiCpTKwCxKmhb+0ahLQadptEiQyQRGzQ9j1PywC/sobcDaud0ePHulPbZK22bbI92kLLopZZo9Ta/BngycEsjJP7NJipEClLKCGrZ8chJ7Vytm3B0tlag2QRAERi8IQ12h4cT2tku8D/6STFl+DZNui8TaTolMLmPYzBAWPD0Ula2SjR/G8ccPSdTXmddjra3XsfubRPavPUdwfzfmPjIIdaWGI1vSzTpOa9RUaNjwQSx6nZ6FzwwldJAH+38+R8oJaU5QrC6mQF1AH9c+ja1Jl1sAf7nSbQGeKIpa4H7gdyAR+EkUxQRBEF4SBGFOd533n4SfvZ9JGTwAfxdblo4J4bcT2ZzKLu/mkVmwYByDB54gl+P15BP4vPYa6mPHSJ40ifMPPkT1oUOIeqmERRAEySrhUpZotoZ7GCxYCfcegrBJsPctKdD743WovfT/X+nlkoJm09Xg9hAEgRCnK09Js7yunLOlZ7m297XYKmw7JLSSV53H8fzjZr0mo0IK1poK2US6RpJenk5NfQ3quDis+/ZFplKhCpYCvHpLH56FfzJVDT1hF3ngtcDRt00vvIKaghbZO4DeLr2RC3JOl1yeysej5oXiG+7MH9+f4XxSKZs+igMBZt0/AGt741553iFOhDeUsrbWw5d+sohTf2YzYHIAARHNFao9Ah24/t9DGTg5gIR92fz4f3+Rc67UpDLWqtI6fnv7OGcO5zFsVgjT/9Uf/z4uRI72IX5XFqV51ea/CU3QqLVs/DCWmvI6Zt03ADc/e6bcHoVXsCM7Vp4mN6W80f8uwjXCEuCZSbf24ImiuEUUxd6iKPYSRfGVhm3PiaK4wci+V1uyd+bhY+dDkbqIOp1pakn3TuiFs42SV7eYVqNuwUJXU6wubmaR4Dx/HqGbN+G6ZAk1f/1F5u1LSZ0+g+KVX6EtLe1Zq4SO4BkJ138Ddx+A0PHwx2uwvD/8+RbUti7z3d2kVaQ19tSZQ7Bj8BWXwTtRcAIRkeHew4n2iO5QgPfO0Xe4e+fd1OtN71VJL09HISjwc7igHRbhGoGIyNmC09SeOoXNgAEAKDw8EKyt0ViUNC38k6lsKK1z8G57PwcfqGhbZOXi/jsAa4U1IU4hl2UGD0AmlzH1zr6obBWsf+8EVSV1zLgnGmdP2zZfN3JeL/SiSMz61BbP1VRo2P1tIm5+9oya28vo6xVKOWMWhDPvkUGIepHf3jnBqucPc+i3ZPLSyo369OWmlLP2tSOU5tUw/e7+DJ8V0qg2OnJuLxRWcvb91HEbB229ji2fxlOSXc20u/rjHSr1QipUcmbeG429sxVb/hfPmVTpd+7j0gcvOy8EBEuAZyKXTGTFQucxWCWYKhvraK3koUnhHEwp5o8ki1iNhZ6nuLa4hUWCKjAQryefIOzPP/B9603k7u4UvPkmyeOvZtb3KdgkZqAXL3MfR+9+sOh7+NdeCBoDe/4P3o+WAj11WY8Opaa+hoKaArMsEgwEOwVToC6gSnPlGOwezTuKUqakv3t/BnkO4lzZObPGr9PrOJR7CLVWzbnSc+2/oIH0inT8HfxRyi6svBuEVjJO7EWsq8Nm0EAABJkMVUCApUTTwj8bgzCVfTsBnqNPmxm8vJo8owEeQJRbVLtWCZcSOycrpi3rh72LFZNvj8KnV/siL47uNgyYEMCZmDwKMysbt4uiyJ7vEtGodUxZGtWixPNi/Hq7cMOzwxl/Y28c3ayJ3ZHFL28c45tnDvDn6iSyzpSg0+k5vT+Hde8eR2El57qnhhA6sLn2ha2jiuGzQsg6XUJ6fJHZ74FeL7Jz5Wmyk8qYeGskQf2azwlsHFTMemAACFCxzpkARQjO1s4oZUo8bD0sVgkmYgnwrmAMZuemlmkC3DQiiBB3O17dkojWYn5uoYcpUZe02hcms7LCafZsgld9T8iG9TgvXIj3iSye/6aO1LvvQnP+MizVvBifAXDjali2BwJGSIHe8v6w6yWoNv+LsCN0RGDFgEF101B+eCVwLP8Y/d37Y62wZqDnQPSinviieJNff6bkDOV1UlntycKTJr8urTytRRDtbeeNk5UTlSeOATRm8ACUQYEWqwQL/2yqDBm8dko0HXylYFDXMqOu0+soVhe3GuBFukZSpC6isObyXcT2CXNmyaujCRti/HcwxpDpQVjbKjnwS3Jj1ixhXw7pJ4sZNb8XbiaatausFfQb78+chwZx+1tXMfn2KLxCnDhzMJcNy2P58rF97Pn+DH59XFj49FDcfI0ft9/Vfrj42LF/7Tm09ab39YmiyN4fz5JyopAxC8LoM8J4sO/sacvMe6OR1aiYmLCEeo10Dh87H0sGz0QsAd4VjK+dFOBlV7dudn4xKoWMp6b14VxBFWuPXQETZgt/G+p0dVTWV5pkcm7duzfez/4X9S8fsepqGZqYo6TOnEXhhx+hr70CJJL9BsNNa+Bf+6DXRNj3rhTobXumzdKjrsCggtmRDJ6hrDO1vGUp0OVIdX01iSWJDPEaAkC0ezQyQUZcQZzJxziUewgAO6WdyYGhXtSTWZHZIogWBIEI1wiUp1NQeHmh9PFpfE4VGER9Ziai7so0krdgodNU5oPSFlTtBCOOvoB4oWevCcW1xehEHd52xgODRqGVyziLB5jVHw1gZatk2KxgspNKyThVTGleNQfWniMgypXoCf4dGoO1nZI+I7yZfnd/lr4zlul396fXYE9GzAll1n3RWNsZ7wsEkMtljF0UTkVRLbE7TG+jOLIpjYS92Qy+JpCBkwPb3NclyJrd4d9hXeLCji8T0OtFfO18LQGeiVgCvCsYD1sPFILC7HT1NX29GRrkwjvbz1JdZ/FlstAzlKglO4GmPXjt0dd/MBtHKzj4zo04TJpE0ccfkzpzFpW7dl0ZfaQ+0VKP3n1/QdRciPlMslfY+DCUpnfLKTMqMhAQCHRs+8vTGAEOAShlSs6VmV6qeCmJLYhFJ+oY6i2569ir7Al3DjdLSfNgzkH6uPRhiNcQThaZlsHLrc5Fo9cQ5NjSJDnSNRKvtAqsBvRvtl0VFIRYX482/8oyH7ZgoebECWqOHev8garyJIGV9oIbg1WCESVNg8l5axm8CNcI4PJU0uwsfcf54exly8Ffktmx8jQKlVyyVpCZFywaQ6mSEzrQg0lLIhk6IxiZvP3wICDClV6DPDi2LZ3KkrYXXvU6PUe3pnNkczqRo30YOc94v2BTksuSSXGNxXOynrS4IvavPYe3vTd51XmXf9vGZYAlwLuCUcgUeNl5ca70HFq96YGaIAj8Z2YkRVV1rNh7ZazUW7jyKa6VfHjMke63VdrSx6UPMbpk/N59h8BvvkFma8P5++4n61//QpOe3k2j7WI8esP8T+HB4zDwZohdJRmmr70NznfBxKkJGRUZ+Nj5YCW3Mvu1SrmSMOcwzhSf6dIxdRdH848iF+QM9BjYuG2g50Dii+LR6dvPlNXU13Ci4ASjfUcT7R5NWnkaFZr2xXEMQjTGsqRRMj+8ykRqejdfVVcFSQG3pQ/PgjH0op71yesvSxPn/P97hexHHu189rkyv32BFbhgdm7EC8/ggddagGentCPYMfiyz+B1BLlcxqj5vSjNq6Ews5IJiyOwczb/Ot+VjL4uDFGEQ7+2NCg3kJ9ewc9vHCNmfSphQzy5+uY+JmUwk0okBc2RU/swYHIAJ/ecxzUllHp9PcXqjvv6/VOwBHhXOFFuUfxx/g+m/DyFd4+9a3Jp1aBAF2ZG+7Bibyp55ZffF4qFvx8ltVIGz5QSzaYM8BhAfKE0YbcbMZyQX3/F65mnUR8/QersOeS/9Rbaop7pb+s0LsEwezk8FAej7ofkXfDFRFg5Hc5sBn3nVyUzKzI7lL0zYPByuxIypMfyj9HXrW8zP6yBngOprq8muaz1CYeBo/lH0eq1jPQdSX8PKeN2quhUu69rq88xLFv6G2YENp94qQINAZ6lD89CS04UnOC/B/7L1rStl3oozRD1eupSUtAWFFB98FDnDlaV375FArSZwcuvaTvAA+ka9nfM4AGEDHCnzwhvBk8LInSQR/sv6GYc3W0YfE0Q544WkH22uRdsnVrL3tVJ/PzGUarL67hmWT+m3tnXpOwgSP3Rtgpb/B38GX1tGIF93aj5wxGvymCTPaD/yVgCvCucN8a9wfIJy+nn3o9vE75l7rq5LN6ymF/O/tKuktzT0yLQiyKvbvl7Xghb47vT33Ek78ilHsY/DsOKm9kBnucAarQ1jRN2QanE9dZb6bV1C44zZlCy8iuSJ04i94UXrhwRC0dfmPoyPHoarnkNys/DjzfBR0PhyBegqenQYUVRJKMyw2jpoKlEuEZQWlfaOJG6XFFr1ZwsOtnYf2fAkM0zpUzzUM4hrORWDPYcTD/3foBpQivp5emtGsk7ns1FK4M41+bXX4W3N4JKdeV8Ri30KIaFhdPFl5eHW/3584gNfc/lv/3WuYOZGuDZuoFcZTSDV1BTgEKmaLPUP9ItkpzqHMpqyzox2MsTQRCYfHsUo0wocewpBk8NxMHVmn1rzqHX6RFFkXNH8vnh+cOc2ptN/6v9ufmFkYQN8TSr9zCpJIk+rn2QCTJkMoGpd0Rh7aJgatJSsvIsfXjtYQnwrnCUMiWTAifx4cQP2blwJ48NeYxKTSUvHHqBiWsn8p/9/yGvOs/oawNcbfnX+F5siMvhr7SSHh75paFSU8nbR99m5amVl3oo/zgMJZrm9ODBhQn7xf5mCg8PfN94ndAtm3GaO5fyX34lZdp0zj/yCOqEhK4Ycvdj5QCj7oUHT0jG6dZOsPkxeK+vpLxZbrqAEkBpXSmVmkoCHTqewTOIFJwpubzLNE8WnkSr1zb23xnws/fDw8aD2MLYdo9xOPcwgz0HY62wxlHlSIhTiEl9eOkV6QQ5BhmdrNTGxVPgZ0tCZfM+RkEmQxkYgCbTUqJpoSUJRdI163IrLaxLTgHAul8/KnftQlfRQX9PTQ3UVbSvoAlSj56Dd6s9eJ42nsiE1qevBruSy+29NCCKIrszd5vlu3k5o1DJGbMgjOLsKmI2prHxwzi2f5mAnbMVC54eyrhFvVHZKMw6pl7Uk1SaRB+XPo3brGyVTF7WB5XOmqxf9OjqLX14bWEJ8P5GuNu4c1u/21g3dx3fz/iemaEz2ZGxgzu339lqvfI943vh52zD8xsS0Bkxu/y7cTTvqCSjXhhvadLtYYrVxdgqbLFR2Jj1Oj97P9xt3FudsFuFhODz8kv02rUTtzuWUr1vP+nXLSBz6R1UHzp0RZQaIldAv+tg2W64fSsEjrqgvLnmFkjbByb8HpkVUnaoIxYJBvq49EFAuGwnRwaO5R9DQGCg58Bm2wVB2tae4Xl+dT7JZcmM8h3VuK2/e39OFp1s9zOTXpFu9D0WtVrUp05R0yeApNKkFtcYVWAQ9ZYSTQtGSCiWAryzpWdN6h/tKeqSpcoJz8cfQ6yro2Lrto4dyGCR0J4HngEHX6NeeK2ZnDflcg/wdmft5qE9D7Enc8+lHkqXETrIA/8IF45vyyAvtZyxi3qz4OmheAY5duh42VXZVNdX08e1T7PtgcFeHOrzK/o8a/b+dLYrhv63xRLg/Q0RBIEBHgN4ftTzfDblM/Kr87l7591Uaipb7GujkvOfmZEk5lbwQ8zff2U5Ji8GgApNRWMfjYWewZjJuSkIgsBAj/Yn7EpPTzwfe4ywPbvxeOxRas+dJfP2paQvWEjFtm1Xhjy9IEDQaLjxB6lPb/T9kL4PvpkFn4yGoyuhrvXSa4N/XWcyeLZKW4Icgy57oZWj+UeJcI3AUdVyAjHQYyDZVdmNinvGOJx7GIDRvqMbt0W7R1NSW0J2VeuZU7VWTV51nlGBlbpz5xBrarAeEE11fTXnK5tb0agCJS88sQt6LS38fSivKyezMpNgx2DUWvVl5UNZl3wOhbc3tiNGYBUe1vEyzcqGkm9TMnggmZ0bsZTJr8lvN8BztnbG1873sr2GbUzZCEBKecolHknXIQgCExZHMGRaEDe/MJLoCf7IOqHuaRBYMaiiNqU+pJiiiCRO78shYZ95VS7/JCwB3t+cQZ6DeG/CeySXJXP/rvuNKnRN7+fN6F5uvL39LCXVmkswyp7jcM5h/Oz9AMzyyrLQeUrUJWaXZxoY6DmQ81XnKVK3L6Yid3DAfdkywnbuxPulF9FXVZH98COkzJhB6Y9r0NfVdWgMPY5LEEx5CR5NhDkfgUwOmx6Bd6MkP72illYGGRUZyAU5fg5+nTp1pGvkZV2iWa+rJ64wrkX/nYFBnoOAlmW9TTmYcxBXa1fCXcIbtxmEVtoq02wrS6qOk64pviOvBlpmEFRBgYh1dWgLWg88LfzzMHxOFvRe0OznywFNcgpWvXohCAJO8+ahjo2lLi3N/AMZPO3MzeA1yaaLomhSgAdSqfnl9D4aKK8r58/zfwIXPEv/Lji62zByXq8uUfY8U3IGmSAjzDmsxXO+dr6cDNlNYF9X9v54lrzU8k6f7++IJcD7B3CV31W8dtVrnCg4weN/Pt6i7lsQBF6Y05eqOi1vb0+6RKPsfgprCkkpT2Fh74U4qByIK7QEeD1JcW2xWRYJTRngMQDArL+ZzMoKl+uvJ3TLZvyWL0fu4EjeCy+QPGkyRZ+t6HgvSU+jtIHBt0im6Uu3Q/hk+GuFJMjy1QyI/wnqpYWbzMpMfO19UcpaN6g1hQi3CHKqcyivuzy/OE8Vn6JOV9dqgBfhGoGV3KpVoRW9qOdw7mFG+Y5q1ssT7hKOldyK+MLWDc/TKlo3klefiEXu7k5Y5BgUgqJFkKwKksRvLEqaFppiEFiZFToLlUx12ShAino9dampWIVJk2zH2bNBJqN83XrzD9YY4JmRwauvgdoL16Cq+irUWnWrJudNiXSNJL0ivV2xuZ5mW9o2tHotPnY+jXYrFlqSVJJEiGMI1grrFs9523mTU5PNlKV9sXexYutnJ6kub7lwK4oipXnVxO/JYtuKkxxal0JpXnVPDP+ywBLg/UOYFjKN/478L3+e/5PnDjzXojekt5cDt44KZvVfmZzKvjwndZ3FUJI1yncU0R7RlgCvhylWd6xEEyQ7EKVM2aGsqyCX4zjtGoLX/kTg119h3acPhe+9R/KEiZLFQmlp+we5HBAECBwhibE8chomPQ8V2fDrMninD2x9msySs52ySDBgKIu5XLN4x/Il78DBXoONPq+UK+nn3q/V//GzpWcpqS1hlM+o5q+TKYlyi2ozg2eYlBl7n9VxcdgMGICVwopQ59AWE3VlYEOAZxFasdCE08WnCXAIwM3GjXCX8Mvm/64+OxuxtharcCnAU3p6YnfVGMrXrze/5L0yD2QKSSHTFBq98C704bVnct4Ug1hUUunltWi9IXUD4S7hTAqcRHpFukULoBWSSpNa9N8Z8LX3pVJTiVZZx4x7otHU6tj22Sl0Wj3qSg1nj+Sx69tEvv33QX54IYZ9a86Rn1bBie2Z/PBCDGtfP8rJP85TW/X3ELlpDUuA9w/i+j7X88CgB9iUuok3j7zZQkjgocnhuNqqeH5DwpUhTGEmMbkxOFk5EeEawQCPAaSUpRjtS7TQ9Wj1Wsrqyjoc4KnkKqLcokxSRmwNQRCwGzmSwC+/IOTXX7AfP56Sr74mZdp0Sr77HrH+CrrYO3jB2EfhgROwZD30moB45AsyylIIyjoBJ1aBpuMrlQaRgstlonkxR/OO0supV5slv4M8B5FYnIhaq27x3KEcyc+rqcCKgf7u/UksTqReZ/zzYDCSv1gsSFtaiiY9HZsBUrY5wjWCxJLEZtdSpY83KJXUW8zOLTQhoSiBvm59ASkwOV1y+rL4Dq47JwmsqHpdkOR3nj8fbV4eNTEx5h2sKh/sPEFm4rSz0QvvQh9eeybnTWkUWrlMsqEgLQ7FF8YzJ3QOIU4hqLXqxt/JwgXK68rJrc5tNcDzsZOC/9zqXNz87Jm0JJK81HK+++8hVj6xnx1fniYtthCvYEfG39SHxS+P4tbXxnDra6MZsyAMXb2evT+e5aun9rP1s5OkxRWi0/39Am1LgPcPY1n/ZdwSdQurElfxafynzZ5zslHy1LQIjmWUsi720jaudvWXmyiKxOTFMNx7ODJBxgCPAYiIJkmiW+g8ZXVliIgd7sEDSTgjoSgBja7zfaLWUVH4vfsOIet+wzoqkvxXXiF1/nyqDhzo9LF7FJkMQq+GhV9TfN9BamQyAutqYf298HZvWHcfpB8wSYGzKS7WLnjZel2WPSxavZYTBSda2CNczECPgWhFrVHj8kM5hwhzDjM6Uezv0R+NXsPZUuMKbenl6UZ9BmvjpbJOm4FSgBfpGklJbQmF6sLGfQS5HJW/v6VE00IjJbUl5FTnXAjwXCOp1FReFkbOBgVNQ4kmgP3EicgcHSn7bZ15B6vMM11gBYxm8EwxOTfgYeuBu437ZXUN25S6CZkgY0boDEKcQgBILU+9xKO6/GgUWHFpKbACzQM8gLAhnoycF4qzlw0j5oSy4KmhLH17LNP+1Z9+4/xw8pAW4+ycrBg4OZAbnh3O9f8ZRv/x/uQml7Hlk5N88/QBkmLyLouFla7CEuD9wxAEgceHPs6cXnP4X+z/+OLkFxzJO8L+7P3sytiFnWs8oSGnefnPL/g87iuTTH+7mpr6Gmb9NovvTn/XZcfMqMggrzqPkT4jAWmVXkCwlGn2EI0m5x3swQNJaEWj13TpF7Z1794ErlyJ/8cfIdZpyLrjTrLuvQ/NFZhhSa+XegqDZ30sWS30nQen18HXM+CDgfDnm1BmemAR6Rp5Wa1+GzhTcoYabU2r/XcGWuvbrNXWciz/mNHsHUhKmgDxRS378ERRlCwSjPXfxcWBXI5NP8kwvTU/QYOSpgULcMH/rq/7hQAPLo/MkyYlGYWXF3IHh8ZtMisrHGdMp3LHDnRVZvS3VRWYLrACFwK8io6VaIL0Xl4uxvF6Uc+m1E2M9BmJp61nY4D3dxNa6QoM18zerr2NPm8I8Jp6PA+ZFsy8RwYzdEYwXiGO7Sp4egQ4cNX14dz6+hhm3BuNo7sNO786zdZPjffzXYlYArx/IDJBxoujX2RCwATeP/4+S39fyj077+HhPx7m6f1PU2j9LfUuv/BB7Lvcsf0OsiqyenR8357+lszKTLakbumyY8bkSuUkI3xGAOCgcqCXc682xRQsdB2NAV4HSzThwoS9PbsEcxEEAYdJkwjdvAmPRx+l+vBhUmbNpuDtt82bwFxiMiuloCHQKUiyWpj7MTx+FuZ/Bs6BsOcVyVfvm9kQ+wPUti0yE+EWQXpFutESx0uJof+uvQDP2dqZEKeQFkIrxwuOo9FrWvTfGfCx88HN2s3o4lZxbTFV9VXGFTRjY7Hq0xuZrS1Ao0HvxRN1VXCQZJXwN1opttBxEooTEBAaA7twl3DkgvyyCEzqziU3y94ZcJ4/H7G2lsptZnjiVeWBvWmBGQBKa7BxhcoLmcyCmgJcrFywkpum0hjpFklqeeplcQ07nn+c7KpsZveaDUiLnY4qR0uAZ4Sk0iQ8bKQMrDE8bD1QyBTkVHU+yy2XywiJdufaJ4Yw+towMhNKWP1SDGePXPnZPEuA9w9FIVPwztXv8MXUL/hy6pd8N/071s5ey/p56/n9ut+ZaPsxdWmPIyDn2YPP9lgjcEltCV+d+goruRUJxQmU1JZ0yXFj8mLwsfNp5g82wGPAP8bwPK4wjrt33G3UJqMnKK7tfAbPw9YDP3u/bsu6ylQq3O9aRq+tW3GaOZPiL74kZdJk8l59ldqky99QNaMiA4VM0bi6CYDKDgbcALduhIfiYcJ/pCzeunvgrTDJRP30+kYVzqZEuEagF/WtlipeKo7mHSXQIdCkVfxBnoOIK4xr9j9+KOcQSpmy1QBREAT6e/Q3Wr5tEFgJcQxptl3U6VDHxTf23wHYq+wJdAhskcFTBgYiqtVoCwuxYCGhOIFgp2DsVfYAWCusCXEKueT9rxcraDbFOjoaVUiI6WWaOi1UF4GDGRk8kPrwKpqXaJqavQOIco1CL+o5V9rSUqan2Zi6ERuFDRMDJgLSdSbEKaRRldfCBZJKklrN3oGUpPCy9Wos0ewKZDKBQVMDuf4/w3DysGXHl6fZtuIUNRVXrnWYJcD7B6OUKRnhM4LhPsMZ6DmQCNcIQp1C8bX35b/TRmAleuNWt4Bj+cdYfWZ1j4xpRfwKanW1PD/qeUREDuYc7PQxdXodMbkxjPAZgSBcSNsP8BjwjzE835q2lQM5By5Zz6EhUHe16XgPHkhlmnEFcd26sqb08sT39dcIXvsTtqNHUbr6R9LmziVt0SJK165FV3V5yixnVmTib++PQqYwvoNLEIx/Eh6MhTt2wJDbIPMw/LQE3g6H3+6B5J3SZIwmQiuXkVmwXtRzrOBYu/13BgZ6DKS8rryZHPmhnEMM8hyErdK21ddFu0eTXpHewibCcK0Icmreg1eXkoK+uhrbgQObbTcIrTRF1aCkaRFasQDNBVYMRLlFXfLeMYOCpiqsV4vnBEHAaf581MeOmVbOXl0AiKZbJBhw8GmRwTMnwDOUSV/qctdabS3b07czJWhKs+tOiFOIJYN3EfW6elLKU1rtvzPgY+fTpQGeAVcfO657YjCj5vci/WQRq1+KIfnYlelbagnwLBjFw8GKJ6b14fTZPoTZD2P5seWNBr/dRVZlFmuS1jA/bD4zQ2fiau3KgezOi16cKT1Dhaaisf/OQGOPThcann944kN+Svqpy47XVRhKUVvzBetuitXFKGVKHJQO7e/cBgM8BlCgLuiWC/vF2PTvj/977xH+5x94Pv0U+upq8p59jnPjxpHzn/9Qc+LEZVXCkVGZYVT8owWCAAHDYcabkon6Lb9B5Bw4sxm+v06yXNj0CD55Z3BUOV7yiWZTzpWeo1JT2W55poGBngMBGtVXi9RFJJUmtdp/Z8BgeH6xQEt6eTpWcqvmWVIuGJw3zeCBNMHMrsqmQnOhHFYVJFURWPrwLBTUFFCoLqSfe79m2yNcIyhSF1FYc+myvAYFTWMZPACnObNBEChfb4InXmVDr5TZGTyfFhk8LzvTg0QfOx+crJwu+TXsj6w/qKqvYk6vOc22hziFUKQuanZ9+KeTUp6CVq9ttOppDV97326bB8jkMgZfE8T1/x6Go5s1v39+im0rTlGvMdMa5BJjCfAstMriEUEMD3Yj+fQ05DIFzx7o3lLNj058hEJQcM+Ae5AJMkb7juZgzsFOn/NwjuR/Z+i/MxDsFNylhuf1unq+SfiG1/56jeTS5C45Zleg0Wkay32OFxy/JGMorpU88JpmUDvCQI+BQNf34bWFwtUVt9tuI3TjRoJW/4DjjOlUbN1Gxo03kTpzFkWff059/qWVutaLerIqssz3wJMroNdEmNfQr7doFYSMhbg1CN/PJ7KyhDOpv8PZ7aC99KUqR/OPAjDUy7QMXrBjMM5Wzo0LG029MNuin1s/BIQWQivpFekEOgY2M0cHKcCTOzujDGoeYBsmKQZVOAClry8oFBYlTQsXBFYuyuA1Cq1cwsCkLqXtAE/p7Y3d6NGUr1uPqG/nO7qqIQNijsgKgIMvVBeCrp56XT0ltSVmZfAEQbgshFY2pGzAy9aLYd7Dmm03lHpbDM8vYJirtGaRYMDbzpuCmgLq9d1nb+Tma891Tw5hxNxQdPU6FMorK2S6skZroUeRyQTeWBCNps4Br/pFHC84zg+JP3TLuRKLE9mStoXFUYsbV+jG+I2hpLak0+UVMbkxhDmHtWjYlQmyLjU8P1t6ljpdHVq9lhcPvXjZ9PYlliRSr6/H09aTuII4dPqeX4Uqri3ulEWCgXCXcGwUNp3yw+sogiBgO2gQvv/3f4Tv3Yv3yy8hd3am8J13SZ4wkcw7l1G+eTP62p7vcyyoKaBWV0uQgwkZvNZQWkPkLFj4NTyZAotWEWEfwDltJfU/LJR69n69CxI3dcpjrzMcyz+Gj50Pvva+Ju0vCAIDPQY2LggcyjmEs5Vz4wS6NexV9oQ6hbYQWsmoyDCuoBkbi82AAS0WMAwBXtNrmKBQoPLzs2TwLHCq+BRyQd5iMmv43FzKPjxNcksFzYtxmj+f+pwcav460vbBqhoyeOaIrICUwUOEyjwK1FKQ6GVrXplnpFskyWXJrfpadjdF6iIO5hxkVuisFgtDFiXNliSVJGGjsGmml2AMXztf9KK+27PcMrmModODmXFvdKcXqHuabg3wBEGYJghCkiAIyYIgPG3k+UcFQTgtCEK8IAi7BEHoxOzEQncQ4m7HY1N7E5cYRh/H4bx//H0yKrq+d+T94+/jZOXE7f1ub9w22nc0AgL7s/d3+Lh1ujpOFJxoUZ5poCsNzw2r/fcPvJ/YwtjLplTTUJ65OHIxVfVVJJf1fHaxRF3SKYEVAwqZgmj36B7N4BlDbm+Hy8KFBP+wil7btuL2r7uoS0kh57HHOTd2HLnPPd+jJZyG8mmzM3itobSByFlEjHwQjSCQNvcDiJwN57bDmpvhzVBYtRCOfAnlPeOZKYoix/KPmZy9MzDQcyDpFemU1JZwKOcQI31GtphoGcMgtGL4G9br6zlfeb5FgKerqECTnNLof9cUdxt3PGw8WgqtBAVekVYcPUVNfQ1ltWWXehjdTkJxAr2ce2GjsGm23SDQcyl7x1pT0GyKw+RJyOztKf/tt7YPVtlQ4WB2D17DQk5lrtkWCQaiXKOo10t9XZeCrWlb0Ym6RvXMpvg5+KGQKSwBXhOSSpMIdw5HLpO3uZ+hTL4rlDRN4UoL7qAbAzxBEOTAx8B0IAq4URCEqIt2OwEMFUUxGvgZeLO7xmOh49xxVSgDAlxISZRKNZ878FyXZqcO5x7mQM4BlvVfhqPKsXG7q7Urfd36dirAiyuIo1ZX26I808AA964zPI8vjMfDxoO7ou9ipM9Ilh9f3syn5VIRXxiPj50PU4OnApemTLNYXdwpi4SmDPAcwNnSs9TU13TJ8TqLKjgYz4ceImzXTgK/WonDxAmUb9hAxo03kTxpEvmvvyEFe+2VMXUCg/iHsexSZ2gUWnF0aSjjPAdLNsDQpVB0DjY/Cu9FwadjYc+rkH0cuun3TCtPo6S2xOT+OwOGPrxfz/1Kobqw3fJMA/3d+1NWV8b5yvMAnK88j1bUtrBIqI6RLFhsBhsfV4RrBLGFsRzPP05uVS5avRZVYBD1GRmXVQ/n5cSLh17khs03dGv51aVGFEVOF51uUZ5pwJhAT0/RloJmU2TW1jhOn07Fjh3oq9vI6lflSZYHCpV5A3E0eOFlm2Vy3pRLLbSyMWUjfd360su5pViNUqYk0CHQEuA1IIoiZ0rOtFueCeBj39zs3EJLujODNxxIFkUxVRRFDfAjMLfpDqIo7hFF0TBLOwz4d+N4LHQQuUzgrQXRVFXbEaC/keMFx1mVuKpLjq0X9bx37D187Hy4IeKGFs+P8RtDfFF8CzU7Uzmcexi5IG911b+/h2R43hV+ePGF8UR7SGn850Y+h06v49WYVy/5JO5k0Un6u/fH184XT1vPHhdaEUWRktquyeCB1IenE3UkFCd0yfG6CkEmw27UKHzfeIPw/fvwefVVrMN7U7JqlRTsTZhI3iuvUnPsWJcHe5kVmVjJrcwSIDCFYMdgrOXWFyZHciWEjodpr8GDJ+DeGJj8AihtYe9b8PkEeDcC1t0Lp34BdWmXjcXQf2dugNfXrS8KmYKvE74GaNX/7mKiPZobnhsqFy4Ooit/347cxQXbIYONHmeI1xCyKrO4ddutTP1lKkO/H8rnpZvQ19Tw4pZH+OD4B91SFXGlIooiMbkxZFdlsyN9x6UeTreRW51LaV1pqwGeQaCno999naEtBc2LcZo/D7GmhortbfytKvPNF1iBCxm8ihwKqjtWohngEICd0u6S9OGdLT1LYkmi0eydAYtVwgVyq3Op1FS2K7ACUg+e4TUWjNOdAZ4f0NQh+3zDtta4A9jajeOx0Al6eznw4MRwjpwKJdJpJO8ff79LGoO3Z2zndPFp7h90v1Hz0qv8rkIv6hvFEcwlJjeGfu79Gj2GLsZgeN7ZPrzS2lIyKzPp7y6p7wU4BnDPwHvYk7WHXZm7OnXszlCkLiK7Krsx8BzsObjHA7wKTQVaUdslPXhwYeJ9qcs020Jub4/ztfMJ+OxTeh/Yj++bb2Ddrx9la9aQcfNiksdfTd5LL1F9+DCiVtvp82VUZhDgEGBS6aE5yGVyerv0Nt4LJAjgGQFXPQJ3/A6PJ8O8TyFojKTI+fNSqZTzy6nw55udzu7F5MbgbuNumlJoE6wV1kS5RVFeV06wY3Djym97hDmHYaOwaczuG653Tc+vr6ujas8eHCZPRlAYt6dY2m8p6+et59PJn/LcqOdY2m8pzr2krELemVhWnlrJQ7sfumx6di8156vON/pmfnP6m0u+QNZdGBRa+7obD/CiXKWCp6YCPd1Frba2Wb9pewqaTbEZNAiFjw+VO3e2vlNVvvn9dwC2ruASDH+tIL8iC2u5dbMqH1OQCbJLlg3dlLIJhaBgWvC0VvcJcQohqyLrb52tNhXDZ92UDJ6NwgZXa1dLgNcGl4XIiiAIi4GhwFutPH+XIAhHBUE4Wmgxh71k3H11LyJ9nEhNnIZSpuLZA89SrC7mZOFJtqRuYUX8Cp498Cy3b7udKT9PYeQPI3nuwHOtrpzV6+v54PgHhLuEMzNkptF9+rn3w1Hl2KEyzUpNJaeKT7VanmmgKwzPDZNAQ/ABsCRqCRGuEbwa8+olk0E2ZCYNlhCDPAeRV51HblXPXRSL1Q0m511Uoulk5USoU+glEVrpCHJHR5zmzCHg448IP3gQ33fexmbgQMp+/Y3M227n3JiryHnm31Tu3oO+rq5D58isyGy3Kb2jRLpFcqbkTPv/H3ZuMPBGWPgVPJkqee2NfRx09VL55ucTJL+9X5ZB7A/N5M/bQ61Vsy97HxMCJnSoF8Kgvjrad7TJr1HIFES6RjZOfNMr0nG1dsXJyqlxn+oDB9BXV+NwzTWtHkcQBEKdQhnjN4aFvRfy4OAH+deM5wB4PfRhXh7zMinlKZ0qRf87YVi4WdRnEaeLTzdmbv9uJBQnoJAp6O1i3NA5wq1BoKcHApO3jrzFTVtuIrU8FWiioNmr/QyeIAg4TJgg/S+o1cZ3qso3X0FTOjjM/wzKMilI3YGnrWeH/v8jXSNJKknqUYExnV7H5tTNXOV3VZvffSFOIWhFbWMp+D+ZM6VnEBAIdw43aX9vO+8enctcaXRngJcNBDT52b9hWzMEQZgM/AeYI4qi0dmNKIorRFEcKoriUA8Pj24ZrIX2UcplvLUgmtJKG0KEm4ktjOXqn67mpi038dS+p/jwxIccyD6AXtQz3Hs4kwInsS19G4s2LWLxlsVsSt2ERndBav2Xs7+QVZnFw4MfbrWhViFTMMp3FAeyD5i9kns07yh6Ud+qwIqBrjA8jy+MRybImpXbKGQKXhj9AsW1xSw/trzDx+4M8YXxKGSKxpKHwV5SGVlP9uEZVuO7KsCDBsPzwrgrLusht7fDaeZM/D/8gN6HDuL34QfYjR9H5c6dnL/3Xs6NGs35hx+hfPNmdFVVJh1Tp9eRVZlldmbLVCJcI6iqryK70gwxFZlc8tqb+B+4aw88kQzXfi5ZMqTugXX3SKWc/xsFv/9HMljXtN5TuT97P2qturGP1FwMn/sxfmPMel20RzSJJYlodBrSytOMlGf+jtzJCbsRw806rtLXF+RyNBnpTAuZhqetJ98kfGPWMf6uxBXGYauw5dEhj+Ji5cK3Cd9e6iF1CwnFCfR26Y1KbrwvzdXaFS9br24P8FLKUvj53M8ArDu3DmiioOloWrbMftJExNpaqg8davmkKEoBnkMHy8cDR8K4JymoysZT7JjQRZRbFLW62k59x5tLTF4MBeoCZvWa1eZ+BqsEQ3B9JXMw+yA3brqRKo1p310Xk1SSRJBjUDMz+Lbwtes+L7y/A8ZrSrqGI0C4IAghSIHdDcBNTXcQBGEQ8BkwTRTFK9Mq/h9GPz8n7h4fysd79Nwx/SGCPawIcAjA394fPwe/FmpgTw1/ivXJ61mTtIZn9j3DW0fe4rrw65jVaxafxH3CUK+hjPUb2+Y5x/iO4ff03zlbetak1L2Bw7mHsZZbN2avWqOp4XmoU6jJx29KfGE8vV16t7gw9XXry+LIxXx7+ltmhs40u3+os8QXxdPHpQ/WCmsAwp3DsVPacaLgBDNDjWdNuxpDgNdVJZogZWR+Pfcr6RXpHf6bXWpkNjY4TpmC45QpiBoN1X8doXLHDip37aJy2zYEpRLbUSNxmDQZh4kTULSyuJVXk0e9vr7rFDQvoqknV4BjQDt7t4KdO0RfL930esg/BSm7pdtfn8Ohj0BuBUGjIGQ8hF4NPgOkQBH4Pf13XKxczFbQNDAhYAIfT/q43WvNxfR370+9vp6kkiQyKjIYHzC+8Tm9RkPlrt04XDMVQak067iCSoXS15f6zEyUMiW3RN7CO8feIaE4odWerH8KsQWxRHtEY6u0ZVHEIj6N+5S08rRGSfm/A3pRz+mi00wLab10D6T/ve4WB3nn6DvYKezo49qHDSkbeGDwAyYpaDbFbtgwZPb2VO7ejcPEic2fVJeCTtOxDJ6BcU+Qn7GGgQXnoDRdKts0A8M17HTxaaNiJ93BxpSNOCgduDrg6jb3M4g2XelCK/W6el6JeYXMykz2Ze9jesh0s49xpuQM/dz7mby/t503B3Kkxf8rUeWyu+m2DJ4oilrgfuB3IBH4SRTFBEEQXhIEYU7Dbm8B9sBaQRBiBUHY0F3jsdB1PDAxnDBPB7YeDGFe6A1cHXA1YS5hLYI7AEeVI7dE3cKGeRv4dPKnRLtH88XJL5i7bi4ltSU8MuSRdv8xr/K7CsDsEqaY3BiGeA1pdYXUQGcNz/WivlHIxBj3DbwPP3s/Xjz0YrMMZnej0+s4VXSqWdmoXCZngMeAHu3DayzR7CKRFZCUNEEKyq9EjuUf46VDLzVmIAWVCvurxuDz4guE//kHQau+x+WWW9CkZ5D3/POcGzee9BtupPiLL6hLaz4RMAh0dFcGL8wlDLkg7zpPLpkMfKLhqofh1g3wVDos/gWGL5MMkXe9KJVzvhkCP96M+vD/2Jv1B5ODJqOQdWxNUibIGOc/zuxJgOF/52DOQYpri5tl8KoPHkRfVYVjG+WZbaEKCmo0O1/QewH2Snu+OfXPzuJVaao4V3aOQZ6DALihzw2oZCq+O/3dJR5Z15JVmUVlfWW7wXykWyTpFendphh8KOcQ+7L3cVf0XSyJWkJxbTH7M/c2KGiaHggJKhX248ZStecPRN1FZZBVDRYJHc3gAaJMToFcwFOnl7w4deb1LQc7NYhF9VAfXnV9NbsydzE1eKpRbYGmOKgc8LDxuOIDvDVJa8islBas9mTuMfv1hTWFZFdlt+tR2hRfe1/UWvUlESK6EujWHjxRFLeIothbFMVeoii+0rDtOVEUNzQ8niyKopcoigMbbnPaPqKFywFrpZw3F0STW1HLkz/Ho9O3XzopE2SM8RvDh5M+ZMu1W1jabykPDHqgWfDRGh62HvRx6cOBnAMmj7GwppCU8pR2++8MY4t277jheXp5OlX1Va3+LrZKW/478r+klafxxckvOnSOjpBcloxaq24xrkGegzhXeq7H+gKL1cXIBBnOVs5ddsxgx2CcrJy6zKS+p/k64WvWnl1rdNFCkMuxHTIEryefoNfv2wjZsB6Phx5E1GopePsdUqfPIGXmLAreeRd1bCyZZd0b4FnJrQh1Du2+yZHKFsImwzWvwL2H4LGzcO0Xku9ebhz7976EWlfH1CM/wm93Q+xqqOgZ7yMvWy88bDzYlLoJaP4eV/6+HZmDA3Yj2y4Bbw1VYCCazExEUcReZc+C3gvYnrGd7Kqe8RW8HDlZdBK9qG/smXSzcWN2r9lsSNlASW3JpR1cF5JQJCkAt5etiHCNQC/qOVt6tsvHoNPrePvo2/jZ+3Fj5I1c5X8VbtZu7PxrdYOCpukZPAD7iZPQFRejjrtIkbrSYHLe8QCvtK6Uer0Wr4i5kBUjKfaagUKmoLdr7x6zStievh21Vs28sHkm7R/qFNolonWXivK6cj6N/5SRPiOZ3Ws2+7L3mW0svyNDUmFtL+PZFIMXnqVM0ziXhciKhSuPwYEu/GdGJFtP5fHKZvMumv4O/jwy5BHuir7L5NeM8RvDifwTVNe34bXTBIPqpikBHnTO8NwQZLQVrF7ldxUzQmbw+cnPe6zW3iDvPsC9eYnqYM/BiIg9lv0qqS3BxcqlXeNSczAE5ZezkmZrqLVqDudIn88fEn9oc19BELDu3Rv3u+8m5Oe1hO3Zjdez/0Xh6UHxV1+RfsON9Ln9Le75XcDmSCJ6TfdkiCNdI7sug9ceDl4QvRDmfgwPn2T7oPm4yG0Y6jUEzv4O6+6GdyPhw6Gw+XFI3NildgxNEQSB/u79L/gMNpRTiRoNlbt24TBxIoLKTG+vBlRBgegrK9GVSmO/OfJmBAS+P/19Vwz9iiS2MBYBgf4eF6ohlkQtoU5Xx5qkNZdwZF1LQnFC48JJW0S5SUqa3bG4siFlA2dLz/Lw4IexkluhlCmZ02sOOSclX0dzSjQB7MeNBYWCqt0XqUaXpkv3DsbVa6s0Ve2a2jeanIdfA9E3wN43IdM8ZW3DNawn+rY3pGwgyDGo3fYQA8FOwaSVp12xirEr4ldQUVfB40MfZ0LABKrqqziSd8SsY2zP2E4vp15mldAaFJFzqntmwe9KwxLgWegwd44NZemYEFYeSOOLfd0btFzldxVaUWuyXUJMbgxOVk4m+amAFOCJiI3S1eYQXxSPg8qhXZPpJ4c9iUqm4rO4z8w+B8BPST+xJXWL6eMqjMfFygV/h+b2kv3c+6EQFD1Wpnm29Cy+9r5dftyBngNJKU+54sozDuUcolZXywjvERzIOWBWwK/08cH15psJ+uoryX7hrTfJCrVn9Ckd5/91N+dGjuL8Qw9TvnEjuvKue18iXCMoUhdRpC7qsmOaglpXy58Fx5jUayaKRd/BEynwr70w5WVwCYLYVbBmsWTHsOJq2P4snN0OtV2XnTYEG3JBToC91INYHRODvqICh2kdK88EUAZKPZOaDCkD623nzfSQ6fxy7pcr7jPdVcQVxBHmEoaDyqFxW6hzKGP9xvLjmR+p03VMZdYcdmbsZE/mnm5VXDxVdIo+rn1Qytru3fSy9cLZyrnLF1dq6mv48MSHRHtEc03whc/wvLB5+BVKAZApCppNkTs6YjtsKJW7LyrPO/kzuIZKNyM8s/8ZbtpyU5s2AYYAz8vWC2a8Bc6Bkhqvuszk8UW5RVFVX9XtapXnK89zNP8oc3rNMbkkPMQphMr6ysZ+9SuJrIosfjjzA/PC5tHHtQ8jfUZio7Bhd9Zuk49RWFPI8fzjZotoGTJ4edV5Zr3un4IlwLPQKf47M5IZ/b35v82JbIrvvlWUgR4DsVPacSC7/TJNURQ5nHuY4d7DTfYFMxied6TkL74wnmj36HbP5WbjxqKIRWxL32a2sXFWRRavxbzGG0feMLn04WThSen3uuhLxlZpS4RrRI8oaaaXp3Oy6CRTgqZ0+bENZVxdYVLfk+zJ2oOD0oFXx76KSqZqN4vXGnInJ5xmz2bF9Y58/85kAlZ8huOsWdQcP0bOE09ydsxVZNx+OyXffU99Tuf+Nw0LJT1V4mTAoJ7ZOAmVySTxlTEPSn17T2XA7Vth/FOgsIHDn8APC+GNIFgxoUsCvmh3KTPv7+CPUi5NyCt+/x2ZnR12Y8xT5WyKKigYgPrMzMZtt/a9FbVWzdqzazt83CsVvagnrjCu8f+6Kbf2vZWS2hI2pWzq1jGU15XzxJ9P8OCeB5m9bjarEleZXDViKjq9jsSSRPq5tS8mIQhCtwitfJPwDYXqQp4Y+kSz74dQ51D6VzlT7qhA5uDQxhGM4zBxEprU1At9wsUpkLEfBt4sWR5cRJWmiv3Z+8mqzGJb2rZWj2uYwHvaeoK1o1TCXZENmx+VVDpNwHANO13SvYbnG1M2IiAwO7R1c/OLMQgIXYl9eO8dfw+lTMn9g+4HJN/R0b6j2ZO1x+SM5K7MXYiITA0yL8BzsXLBWm5NTpUlg2cMS4BnoVPIZALvXj+QYcEuPLomjpjU7lmBUsqVjPAewf7s/e1eNDIqMsivyW/XHqEpHTU8r6mvIbksuVlJUVssiVqCSqYyuxfvk7hP0IpaSmpL2Ht+b7v7V2gqSClPaZycXswgr0GcKjpldp28uWxK3YSAwIyQGV1+7H7u/ZAL8ivGDw+kyd3e83u5yv8qPG09mR4ynQ0pGzrcD6nVa8muzCbALRT7cePweelFwv/8k+AfV+N2++1oCwrJf+UVkidOIvXaayn8+GNqz5wxuxTIMDnqsTLNBranb29bPVOhgqDRcPXTsHQrPJ0JSzZI/nsKa4j5tEnAdzVsewYS1l3oCzKBvu59ERAa++/E+nqqduzEfuJEZB0szwRQ+vuBTNYotAKSwe9o39GsSlzVo4JMlwMpZSlU1Vcx0HNgi+eGew8nwjWCb09/260ldnvP70Urarl/4P24Wbvx+l+vM3ntZN488maXZX7SK9JRa9WtGpxfTIRbBOfKznXZtbqgpoCvEr5iatBUo+91eJk1aW66xhJ/c3CYOAGAqt0N2ZvYVSDIYOBNRvffn7MfrV6Lo8qRL05+0erftqCmAJkgw93GXdoQMAyufgZO/QJxP5o0tjDnMBQyRbcuUulFPetT1jPcZ3hj+aApGJSgr7QA70TBCXZk7OD2vrdLwXcDEwMnUlBT0KoH8sVsz9hOqFMoYS7mlQULgiB54Vl68IxiCfAsdBprpZzPlwzF39WGZd8eJbnA/D42UxjjN4bc6tx2L4KHciUvHnMCPOiY4XlCcQJ6Ud9qIHUx7jbuLOi9gE0pm0wWU0gpS2FT6iZuiboFDxsPfkv+rd3XGEpNW+sLHOw5mDpdXbeuZoqiyKbUTYzwGYGXXccb7FvDVmlLb5feV1QfXlxhHCW1JUwMkKTEb468GbVWzW/n2v+bGiOnKgetqG1mci7IZNgMHIjnY4/Sa/MmQrduwfOJx5FZWVP00cekzZtP8oSJ5Pz7P5Rv3oy2pH3xCgeVA/72/j2mQgdQq63lz/N/MilokunqmSpbCB0v+e8ZAr5bN8K4J0BpB0e/grW3wjt9YHm0pMh35AvIOwWtlOTZKe24OfJmZoVKflbVf/2Frrwcx06UZwLIVCqUPj5ommTwQMpWFamL2Jy6ud1j1Ovr/zblSYaFGmMZPEEQWBK1hNTy1G41hN+ZsRNPW0+WRS/juxnf8cOMHxjrP5bViauZ+dtMHtnzSKdL2w3XZlPtMKJco9DqtSSXJXfqvAY+OvER9fp6Hh78cIvnRL0e2+wS8j0VHbomKf38sIqMpHLXbknpMvYHSUDJ0XiJ/u7M3bhYufDMiGdILU9ld6bxsr6CmgLcrN2aXwfGPgqBo6Us3vr74dSvUNP6tUwlVxHuHN6tAd7x/ONkV2Uzt9dcs17naeuJjcLmigrwRFHk7SNv42Hjwa19b2323Di/ccgFuUllmkXqIo7lH+uwx6mPnY/F7LwVLAGehS7B2VbFN7cPR6WQc+vKIxRU1Hb5OUyxS9h7fi/vHXuPMOcwAhzM8+zqiOG5IePXmkWCMW7teyuCIPDVqa9M2v/j2I+xVdqyrP8y5vSaw77sfY09Ca0RXxiPgNCqSpth5fZEfvf14Z0oOEF2VTaze5leqmIuY/zGcCTvCDG5Md12jq5kT9YeFDJF42c50i2SwZ6DWX1mdYd6fkyxSLAKCcHtjjsIXv0D4fv24v3yS9hER1O5cyc5jz3OudFjSL32WgrefluS/q8z3ucU6daDQisYKc/sCEobCBkHE/4Nt2+WAr47d8M1r0qlnql/wObH4NMx8HoQfDVDMl6PXwtF5yTPPiQ/T4OvU+Xv25HZ2naqPNOAKiiwsQfPwCifUfRx6cPXCV+3udiUWZHJ4i2LmfLzFBZtWsRPST912GD4ciC2IBZXa9dWr9sGQ/juMj5Xa9UczDnIpMBJjeX2/T368+a4N9l63VZu73s7f+X9xZKtSziYc7DD50koTsBGYdNuz7aBSDdJNr4r/veSSpJYl7yOmyJuMuppWZ+djaiuxalPf7ambe2QPYPDhAmoT5xAe3w9VObCoFuM7levr2f/+f2MDxjP9ODpBDoE8vnJz41WFxTUFEj9d02RyWHBlxA+BU5vgJ9vv9CLu/NFSNsL2ubXski3SBJLErtNzGR9ynpsFbZMCpxk1utkgoxgx+ArKsD7Pf134ovieWDQAy38f52tnRnkOajVgL0puzJ2oRf1HW7j8LW3mJ23hiXAs9BlBLja8tVtwyit0XD710eoqjPPq6Y9fO19CXUKbTXAW31mNQ/sfoBgx2BWTFnRYc8rc9Ql4wvjCXYMxtna2eTXeNt5My9sHr+e+7XdQO108Wl2ZOzglqhbcLF2YV7YPPSino0pG9sdVy/nXs3ECpribuNOkGNQt/bhbUzdiI3ChsmBk7vtHMv6LyPYKZhn9j1DaW33KCl2FaIosidrDyO8R2Cvsm/cfnPkzWRXZfPn+T/NPmZmpZT9MdXkXOHujsvChfh/8D69Dx0k+Kc1eDz0IHJbO4q/+ZbMpXdwdvgIMpfeQfEXX6BOSEBsCHIiXCMk/64OKM12BHPMzetzcsh+4klKfvih7cmbQgX+Q2DUfbDoO3gsCR6MhfmfwYAbJEPmI1/Ar3fCR0Ph9UD4aqYU9MX9iHj+OJU7tmN/9dXIrK07/TsqG6wSmiIIArf2vbXNbNXm1M0s3LiQ85XnuSv6Lur19bx8+GUmrp3IcweeI64w7opT5IstiGWAx4BWr9tKmZKbI28mJi+mWxYaDmYfpFZXa3Ry7m3nzcNDHmbHgh24WbuxOnF1h8+TUJxAlFuUyarCAQ4B2CntTC53aw1RFHn76Ns4Wjm2qmBdlyxlCQeOmEWNtqZRut4c7CdNBFGk6pfPwdYdehs3cz+ad5TK+komBExALpOztN9SThefNho859fkNysBbMTRF67/Fp5MhTt2SGWbCms48D58MxveCIb194FWKneOdI2krK6sW7LeNfU1bE/fztTgqS0CHlMIcQq5YgK8Ol0dy48vp7dLb+b0Mu5uNjFwIsllyWRVZrV5rO0Z2wl2DCbcObxDY/G286a4trhHBJiuNCwBnoUupb+/Ex/fPJgzeZXc8/2xLg/yxviN4Wj+0WYrizq9jjePvMmrMa8yzm8cX0/7Gg9bD7OPHeIUYpbhuSiKbRqct8XSfkvRi/p2s3gfnfgIR5UjS6KWAJKc8mDPwaxLXtfqBM7UcQ30GEhsQWy3TAQ1Og2/p//OxMCJHfqyMxVbpS1vjnuTsroynj3w7GU9qU0rTyOjIoMJAROabZ8YOBFvO+8Oia1kVGRgr7TvkIm8IJdjEx2N+z33EPT9d/Q5fAj/Tz/BedH1aAsLKHj7HdKvW8C50WM4//AjDDxUiEeZSFJJktnnMhdTyzNFUaR0zU+kzp5DxebN5L/0MjmPP4G+2kRhDEEA1xApuJv5Nty5E545D3cfgDkfwYBFoK2Fvz6H3/5FzSvXoCstw0G/C35aAn+8IWUPilNaLfFsC1VQMPrycnRlZc22TwuZhpetF18nfN1se019Dc8deI6n9z1NH9c+/Dz7Zx4Y9AC/zP6FVTNWMT1kOtvSt7F4y2Ku3XAtqxJXXRFZvWJ1MZmVmUZ7wppyXfh12Chs+Cah6w3hd2XuwsnKiSFeQ1rdx1Zpy7Xh17I3e2+HysLq9fUklSSZXJ4JUnanj0ufNoPaKk0Vzx54ltu23cbLh15mVeIqYnJjKFIXNV4T92Xv43DuYe6OvhsnKyejxzEEeP2HziDQIdCkdoCLsY6KQuHlSeXRs9L/lcJ4n+qerD1Yy60Z5TsKgDm95uBl68XnJz9vsW+rAZ4BuQIChsPVT8HSbfBUOtywGvovhBPfw9rbQKtpzIaa0pqgF/UcyTuCVm/aHGZX5i5qtDVml2caCHEKIac6B7VW3aHX9yQ/JP5AdlU2jw99vNWFCsP3XFum58XqYo7mH2Vq8FSzF+QNGBS62wva155dy3vH3uOjEx+xIn4FX5/6mlWJq/gp6SfWJa9jZ8bODmWsL2dMbGywYMF0JvTx5LX5/Xnq13imvPsnL87py9S+3l1y7Kv8ruK7099xNP8o4/zHodaqeWbfM+zK3MVNETfx5LAnO+y3Zq7heW51LkXqIpPM2i/G38GfmaEz+fnsz9zZ/07cbFpO0GMLYtmXvY+HBj/ULBM3L2wezx2UVumNTYiyKrMoqytrd1yDvQazPmU96RXpjSpeXcXe83up1FSapSTWUSJcI3hs6GO8/tfr/HDmB26OvLnbz9kRDP0IFxu5KmQKbuhzA8uPL+dc6TnCXUxfycyoyCDQMbDDX45NkdnZ4XD11ThcLY2vvqCAmsOHqT54iOpDh3DYls/HQN2vD5AzegK2w4ZhO3wYSj+/Ljl/UwzlmW2pqmnOZ5P33LNUHzyE7ciR+Lz8EhVbtlL4/vvUnU3C7/0PsArtwOdargTvftKNhvIyXT0Up1Dxf68hqI5hPzgScuOl4I6GRQWFNbj3Bs9I8IiQ7j0jwSlQUv80giqowSohMxMbZ+fG7UqZkluibuHto2+TUJRAX/e+nC09yxN/PkFaeRp3Rd/FPQPuaQx+BUEg2iOaaI9onhj6BFvTt/Lz2Z95/a/X2ZW5i5XXrDT/fehBDNdcY/13TXGycuLa8GtZc2YNDw1+CG+7rvleqdfX88f5P5gQMKHdfs/rel/HFye/4JdzvzQqB5pKSlkKdbo6swI8kEoLfz33Kzq9rsX3W2pZKg/teYisyiz6uvVla9pWKusvZNmdrJzo5dSL7KpsAh0CWdRnUavn0SSnoPDyQuHkxPzw+bx//H0yKjLaLAG/GEEQcOjrRdmfeegjrzeaRTBUM4zyHYWNwgaQhNRu63sbbxx5g+P5xxnsNRiQSmcrNZXm9XFbO0LEDOnm3R+2PA4/307v+Z8gE2QkFie2W0b589mfefnwyyzrv4wHBz/Y7inXp6zHz96vcdzmYvgOzqjIMNne6VJQWlvK5/GfM9ZvbGNwbgx/B396u/Rmd9ZulvRdYnSfXZlSeaa56plNMVgl5FTltPo5/Sv3L1469BIKQYFWbD1gt1faMzdsLov6LOryOdGlwJLBs9AtXD8sgJ/vHo2TjZK7vjvGXd8eJaes8ytTQ7yGYC23Zn/2forURSzdtpTdmbt5athTPDPimU6baZtjeG6Q5+9IgAdSeWGdro7vTn9n9PkPT3yIm7UbN0U0VyC7JvgabBQ2ra6ummK8DjDIcxBAt/jhbUzZiLuNu8lG853lpoibGOc/jneOvtMjGaaOsCdrD33d+hqdqFwXfh3WcmtWJa4y65gZFRkEOZg++TIHpacnTnPm4Pv6a4T9sYfQLZv5cYYD+b42VO3eTe6//03K5CkkT5hI9hNPUrrmJ+pSu8as16CeOcx7WIvnRL2e0tWrSZszB3VsHN4vvkjgVytRBQTg/q+7CPzic7RFxaQvXEjF79s7PRYA5EpEt3Aqj6VgP3EKsiWr4aFY+Hc2LNstZfuG3Ql2HpC+H3a9CKtvgPcHwGv+kmXD+vslG4e0vY1iEKpGL7zMFqe8Lvw67JX2fJXwFT8l/cRNm2+iQlPBiqkreGDQA60GIvYqexb2XsiaWWt4ZMgjHMk7ctkLEcUWxqKQKUxSllwcuRg9en440zF7EWMcyTtCpabSpN4pP3s/xviN4ddzv7bp3WaMhKIEAJMVNA1Eukai1qrJqGzer7kzYyc3br6RCk0Fn0/9nFUzV3HgxgPsXribFVNW8PTwpxsnzyIiTw9/utHqwxh1ycmN/nezQ2cjE2SsT15v1lgRRewdUhB1MqqTjYueJJYkkled16Ka4bre1+Fi5dIsi9doct5WBq8thi+D6W/CmU3YrLuPUMeQdsWi6vX1fHnySxSCgi9OftFuj3duVS5/5f7F3F5zTbZmupgrxSrhk7hPqNHW8NjQx9rdd0LABE4UnGi1fcJQntnbpXeHx9OeF55Or+Oto2/hY+fDoZsOEb8knuOLj3P4psPsW7SPXQt3se26bay8ZiXj/MexJmkNc9bNYdn2ZezK2GVyBvdyxBLgWeg2hgS5sPGBq3h6egR7zxUy5d0/Wbk/DZ2+4xNAK7kVw7yHsStzF4u3LCalPIXlE5azOGpxl4x5gKdkeG5KE31cYRzWcmuzMi5NCXYKZlrwNFafWd3C2Phw7mH+yvuLZdHLWpQ42iptmRY8jW1p24yWFMQXxmOrsKWXU9tGtcGOwbhYuXA8v2v78Mpqy9ibvZcZITNMVz/sJIIg8PKYl3G2cuaJvU9cdqUWhTWFxBfGt5jQGHC2dmZm6Ew2p26mrLbMpGPW6+rJrc41uf+uMwiCgFVoKPkzBvPZjc6EHzpIyIb1eD37X2wGDqT60CHynn+e1BkzODtyFOk3Lyb3+Rco+e57qg/HoC023T6lVlvLH+f/MFqeqcnKIvO228l78SVsBg4kdOMGXBZd3yyDaDd6NCG//oKqVy+yH3qI/DffQtR2/ku65tgxdMXFzdUzVXbgNwQG3wLXvAK3/AqPnpb8+ZZuh9nvw+AlYGUPSVtg29NSb9CbIfBOBMp9j4MAmsPrJcGXktTGfiFDoPZ7+u+8fPhlhnoN5efZP5ulDryozyIcVA58e7p7hEm6iriCOKLcorCSW7W7r7+DP1OCprA2aW2XlZ/uztyNjcKG0b6jTdr/+t7XU6guZG9W+5Y1TUkoTsBB6dBM9dYULvah1Ol1LD+2nEf+eIQw5zDWzFrTuBgiCAIeth6M8h3FzZE389yo5/hm+jfsWriLsf5jWz2HqNdTl5qKVbgkVe9l58UY3zGsT15vngDU+aPYqZKR2aio3L3L6C57svYgE2SMDxjfbLuNwoZbom5hf/b+xt+1mcl5RxnxL5j2OiRuILKqhMR2+hk3pWwipzqH18e9TpBjULs93htTNyIidkpQLMgxCAGB1PLUDh+ju8mqzGJt0lquDb+WXs5tzy8AJgROQC/qjVo7ldSWcCTvCFOCpnSqAsTL1gsBgZxq4154G1I2cKbkDA8PfhhrhTWCIKCUK7FT2uFs7YynrSd+9n4M8x7GG+PeYMeCHTw46EHSK9J5+I+Hmf7rdFbEr6BIXdThMV4qLAGehW5FKZdx9/he7HhkPEODXXlp02nmfXyAk+fL239xK4zxG0NBTQG12lq+uuYrJgZO7LLxDvceTqhTKB+e+LBd36GTRSeJcotCKWt9RbQ97oy+kxptTbPMjSiKfHj8Q7xsvVjQe4HR180Lm0eNtobtGS0zFPFF8fR3799uNlMQBAZ5DuryDN7v6b+j1Wu7VT3TGK7Wrrw69lXSy9N588ibPXru9vjj/B+A9IXXGjdF3kStrpZfzv1i0jGzqrLQi3qzyqc6S5RrFKllqdTpNVj37o3rzTfjv/w9wvftJXTLFrxffBHHa64BUaRi61byX3mFzNtu49yYqzg7ajQZtywh55l/U7B8OaWrV1O5ezfqhAS0RUWNYi77M/diXVrD9NpwKnftonT1agqWLyfn6WdInTOX2oQEvF9+iYAvv0Dp52d0nEofH4K+/w6Xm26kZOVKMm+7HW1hYad+98ptvyNYW2M/tvVJciM2zhA4AobcBtNfl6wankiBx87CLb/B1P+D0KuR1RWhtNVRtvUPSp69Ed07g+H/POHdKFg5jcXp8fRROvOo1zj+F3QtbpWFUGd6UGOntOP63tezM2MnWRVtix1cKup19ZwqOtVueWZTbu97O1X1VSb/r7SFXtSzO3M3V/ldhbXCNOGcsf5j8bL14qezP5l8HlEUOVFwgij3KLMntKHOoahkKs6UnKGstox7dt7Dl6e+ZGHvhXw17asuKVWtz8lBVKtRhV3wIrs2/FoK1AUcyDlg+oFOfIdgbYv9uHFU7fkDUdcyONyduZuBHgNxtXZt8dwNETdgr7RvzOI1MznvDCPvgWteJbIglUJ1EYWVxnsodXodX5z8gkjXSKYGTeWt8W+12eMtiiIbUjYw1Gso/g7+HR6eldwKP3u/bs/gJRQn8NGJjzqk2vzlyS+RCTLuHnC3SftHuUbhZetlVE3TUJ7ZKZVkpNJeD1sPoz2xNfU1fHjiQ6LdoxtVkNvD3cadZdHL2HrtVpZPWE6IYwgfnviQuevmXnHepJYePAs9QoCrLV/fPoxN8bm8uPE0cz/ezw3DA1kyKogIb0ezjjW712zyqvO4MeLGxgbbrkIhU/DY0Me4b9d9/Jj0I7dEGZd41ug0JBYnclOkcQNXU+nt0puJARP5PvF7lkQtwV5lz97ze4kviuf5Uc+3uqI9yHMQQY5B/HbuN+aFzWvcXqut5WzJWW7rd5tJ5x/kOYjdWbspUhddMJHtJBtTNxLmHEYflz5dcjxzGOkzkqX9lvLlqS8Z7Tu6w946Xc2ezD342fu1qRTW26U3w72H82PSj9za99Z2s5+ZFeYpaHYFw32G8/nJz1mXvI4bIm5o3C5l+EKa9byJooi2oJC65HNokpOpS06mLjmF6kOHpGDr4omfUoncwQGf0hI+EwFeptFaWi5H4e6O/dixeD3zNEqf9k2EZSoV3s89h82AAeQ+/wKp8+bjMHUKtoMHYzNoMEo/X5Mn2qJeT8WO7diPHYvMzs6k17RAEMDBS7r1urAo5d13L4XvvE3+sXMUJnjiOCwYF08HrIVSPLOO8XPFeRDj4fD3F45l7QxOAeDkB07+kpqgo+G+4aaUeptuiryJb05/w7env+U/I//TsbGbiU6v439x/2Nq0FT6uLZ9HUgsSUSj17QrsNKUvu59GeY9jO9Of8dNkTd1apHtZNFJCtWFZi0UKmQKrut9Hf+L/R9ZFVlGLQcuZlPqJpLLklkcaX61iVKmJNwlnL3n97I9fTuF6kJeHP0i14Zfa/axWqPu3DkArHpdCPDG+4/HxcqFdcnrGOc/rv2DaKolP7qoedgPmEbF7ztRx8VjO3hQ4y7nK89ztvQsjw993OghHFQO3BhxI1+c/ILU8tSuyeAZGHUfkTXZcH4jiZvvw2PhT5JASxN+T/+dzMpM3rv6PQRBaLfHO64wjoyKDO7od0enhxfqHNqtAd75yvPcs+MeSutK8XfwbzZ3aI/cqlzWp6znuvDrTA62BUFgQsAE1iWvQ61VN/ZbglSGH+QY1KnyTAM+dj5GrRK+SviKQnUh7179rtmLKgqZgkmBk5gUOIm08jSSSpNQyY0LBl2uWAI8Cz2GIAjMHuDLuN4evP17EmuOZPFDTCYDA5y5cXgAs6J9sbNq/yPpqHI0qf67o4z1G8to39F8EvcJs0NnG7VASCpJQqPXdLj/ril3DbiL3Zt282PSjyztt5QPT3xIgEMAc8NaV+MSBIF5YfNaNMEnliSiFbUmG68P8pK+eGMLYpkc1Hk7g6yKLOIK43h48MNdLrxhKvcNuo+/8v7ihUMv0M+9X5cvAphLTX0NMbkxXN/n+nbfk5sjb+ahPQ+xO3N3u8FpowdeN/XgGWOE9wiGeg3lk7hPmNNrTpsKqYIgoPTyROnlCRd5xok6HdqiYrQF+Wjz86nPk+41ZSV8n7sR/5D+zB21FIWHJwovTxRubgjyjvXXOs2di1VEBAVvv0PFho2Urf4RAIWnJzaDB0sB3+DBWEf0QVAYv/6oT5xAV1iEwzWdW202hv3YcdiPHYf65ElKf1hN+ZYtlO2rw2bQIFxuehWHyZOQ1RVD+XnpVnH+wuPy85B5CGqNVETYuoGjL54OPsxUuLHu7Fru09vh7BQEdp5g7wX2nmDlIAWfFyGKIhWailYVF9vil3O/sCJ+BXuy9vDTrJ/aXKww9AcO8Bhg1jlu63sb9+26j21p2zpVLbArYxcKQWFaANOEa8Ou5bO4z1h7bi2PDnm0zX0rNBW8ffRt+rv3Z374/A6NM9Itkp/P/oyXrRffTv+2VY/TjmJQ0LQKu1B6p5QrmdVrFqvPrKaktsRoxq0Zp9eDphIG34K9Sz9QKKjas7tZgPdH1h8ArZarAyyOWsx3p79j5cmV2CntsFfad5kac8TYf8PqjZzJPcK43/4lWaQ0BHl6Uc/nJz8nzDmsWcB/U8RNHMw5yDtH32Go19BmixbrU9Zjo7DpksXEEMcQYnJjjIrpNGXt2bXYK+1NzkqBpLT6wO4H0Ik6wpzD+Dj2Y6aHTDepLBpg5amVIEoK4OYwIXACPyb9yOGcw40VLKW1pRzJO8Lt/W7vknmCr50vp4pPNduWV53H16e+ZlrwNLMWj4wR4hRyRYquWAI8Cz2Ok42Sl+f149Epvfn1RDar/8rkqV9O8vKmRGYP8OXG4QH093O6ZAGCIAg8PvRxFmxcwCdxn/DMiGda7BNf1CCwYmIg1RZ93fpyld9VfJvwLe427iSVJvHqVa+2uyo9p9ccPjzxIeuT1zeqfBmEX/p7mGbdEOUq9b0cLzjeJQHeptRNCAjMDJ3Z6WN1FKVMyRvj3mDhxoU8ve9pVl6zssd6AY1xIOcAGr3GpAzBeP/x+Nn7sSpxVbsThsyKTJysnMzyYOwsgiDwyJBHuHnLzXyT8A33DLynY8eRyy8Ef/0vfFZ3Zexi1R/rWTHlPhzaUGgzF+s+fQj8fAWiTkfd2bPUHD+O+vgJak4cp3LbNmknhQKlpycKXx+UPr4ofXxQ+vqg8Pamcus2BJUK+waF0e7Apn9/bF7rj9dTT1L22zpKf1xNzhNPIndxweGaqThOnYrtsHkISiPXBU01VORKwV9FDlRkS/fl2VCVx63qAta7KPkp5h3uKq9o/lq5lRQM2rlJvmV27mDrzod1mXxVkcA3EcuI9hgAtq5g4yrdK1qfFJbXlfPhiQ/xtPHkXOk5fj33K9f3ub7V/WMLY/Gz9zO7BG+s31jCnMP4KuErZoXO6tD3hSiK7MrcxQifETiqzKsk8bLzYrz/eNadW8f9A+9vc3X/oxMfUVZXxv8m/6/DIhwLei9AQOC+gfcZVV3uLAYFTblj8/dhfth8vjv9HZtTN7da0dLI8e/AtRcEjkIuCNgOG0rlrt14PnZhQXZ31m7CnMParDxwtXZlQe8F/HjmR/q49uma7F0D9ip7ghyDSLQLglM/Q2GSJMTSfyG7cw+SXJbMG2PfaPZ3MvR4L9iwgMf/fJw1s9Zgq7SlVlvLtrRtTA6cjJ2yg5n9JoQ4hVCnqyO3OrfVcs/YglheOvQSANlV2dzR7452P/tavZYn9j5Benk6n075FIA7t9/Jj2ekapH2KKwp5NdzvzInbI7ZC6bDvIbhoHRgT9aexgBvV+YudKKuU+qZTfG292Zn5k70or7x7/bB8Q/Qi3oeHvJwl5zjSsQS4Fm4ZLjYqbjjqhCWjgnmWEYpq//K4rcT51n9VyZRPo7MjPZhTJg7/f2ckMt6NtgLdwlnQfgC1iStYVHEIkKdQps9H18Yj6etp3nSzW3wr+h/ccvWW3jx4Iv0curFjJAZ7b7G09aTq/yuYn3yeu4beB9ymZy4wjj87P1MLrdUypX0d+/PifzO9+GJosjG1I0M9x7eZfLlHSXAIYBnRz7L0/ue5v5d93NH/zsY6jX0kiwa7Mncg5OVU6NqaVvIZXJujLiRt4++TWJxYqNvkzG6U0GzLaI9opkSNIWvE75mYZ+FXVbaCxfMzY2pZ3YFglyOdWQk1pGRcLNUalWfl4f6+HFqzyRRn5eLNicX9fHjVOTnQxNxFvvJk5Dbd34S1x5yZ2fcbr8N11uXUH3oEGVrf6Z8/QbKflyD3MkJ+4kTcZg6BbsxY5CpGoIKlR24h0k3I4QDY3bczQ9Wp7l10ftYqUuhqhCq8qC6CGqKpVt1EZSmcbS+nC/c7REFgefjPmRNdh7NwheVfUOw5wI2LlLJqI30+NOqM1TUlbOm7328cf53Pjz2Hte49MXJ0R9UDs0sI0RRJK4gjqHe7ZvZX4zBEP7ZA89yMOcgY/zGtP+ii0guSyazMtOkSa4xru9zPbuzdrMrc1er2ZTTxael75E+i8y2R2hKX7e+9B3V8de3R1MFzaaEu4QT7R7NV6e+YnrI9Nb/34uSIfMgTHq+MSPsMHES+a+8Ql1aGlYhIZTXlXM8/7hJWaBb+97Kj0k/klCcwCifrlvsAUmV9GTRSbj2c8kUfeODiDueZUVAAEF2vkb7wlytXXlt7Gss276MN468wYujX2RP1h6q6quYE2bc7NtcmippGgvw6vX1vHjoRbztvBnkMYj3j79PeV05jw55tM3vtrePvs3+7P08P+r5RmXr0b6j+fzk51wbfm0zGyZjfJ3wNTpRx5397jT7d1LKlVzlfxV/nv+zMTO5I2MHAQ4BXWYH4WvnS72+nmJ1MR62HiQUJbAxdSN39LsDP3vjfdr/BCwBnoVLjiAIDA12ZWiwK8/NjmJDbDY/HT3PW78n8dbvSThYKxgV6saYMHfGhLnTy8OuRybq9w26jy1pW3jn6Dt8POnjZs/FF8abXVLUFgM9BzLcezh/5f3F/YPuN9nuYX7YfB45/wgHcw4y1n8sJ4tOMsij/UCiKYM8B7Hy1Epq6ms6VQYTVxhHVmUWd0Xf1eFjdCUzQ2dSUFPAylMrWfr7Uvq49OHmyJuZETrD5LKUzqLVa9mbvZdxfuNMziLOD5/Px7Ef81HsR3ww4YNWPwsZlRkM9TJ/YtwVPDDoAXZn7mZF/Ar+PeLfXXJMg3rmzNCZPZpxVXp7o5wxA8cZzRdVpDLSIupzctDm52MzqGP+Vh1FkMmwHzMG+zFj0KvVVB84QMX27VTu3En5b78hs7PDfvx47K8ejzIgAKWvLwp391ZLWW/rdxvLti9jc3Vam71blZpK/rNhAQGCnAciF/PEkdf4Yvzd3Os5UrJ3UJdATakUEKpLpVt5NtSWkVpfyY++HlxXWUXEpid5SqVkka83n/44g6dKygBB8iizdgJrJ3Kt7CiQFTAwJxE2Py6Vi1o7gpXhZi9tU110r7QBQWBmyEw+PP4hX536qkMB3q7MXQgIHRbqGuU7Cj97P35K+slogKcX9bxy+BVcrFzM9szrSQwKmi7XLzT6/LOjnmXxlsU8ufdJVkxZYfz/M/Z7EOQw8EJfusPECeS/8gpVu3djdccd7D2/F52oM+n99rbzZm6vufxy7pfOC6xcRKRbJNvSt1He5xqc+i+EzMPsO/QWiXXneDk3DfmqhVJWL3wqNLn+jvAZwZ397+Tzk58zymcU61PW423nzXDv4V0yrqYBnjHF028TviW5LJkPJnzA+IDxOFk58XXC15TXlfPcqOeM/l1+SvqJVYmruCXqlmaibQ8PfpjrN13PV6e+atPnr6S2hLVn1zIjZIZJvabGmBg4ka1pW4krjCPUKZSY3Bhu63tbl83jDFYJudW5uNu48+aRN3G1duXO/uYHpH8nLAGehcsKJxslt4wK5pZRwRRV1XEwpZiDyUXsTy5i++l8ALwcrRjdy51ofyeifByJ9HXE0brjTfat4Wrtyl3Rd/HusXc5mHOwUUK7WF3M+arzbRrGdoRnhj/DzsydJnkxGTA0wf+W/Bu9XXqTV51HdJR5ZaODPAehE3WcLDrZKd+6TambsJZbMyVoSoeP0dXc3u92boy4kc2pm/k+8XueO/gcy48vZ2HvhSzqswgPW49uPf+JghOU15W3qZ55MY4qRx4c9CBvHHmDV2Je4dmRz7b4IqzV1pJXndejAitNCXEK4brw61ibtJZbIm/p8Be/AVEU+V/c/9o1N+9JpDJSL5ReXVce1lFkNjY4TJ6Mw+TJiBoN1TExVG7fQeWuXVRs2XJhx6Zlpt4+KH18UHh6IndxoZ+LM1erg/jt4BfMCZyBwsq4YuRrMa+RX5PPN9O/YYDHAP4ojufztN+ZPPCONgURRFHkzZ13Y1MYz/3Xrwa9nojacq5N/JofhWMsjL6TUL1M6hesLYPacmLrJIXEgYVpkBEPtRUgmqDuJ8hBZY9SZcfN9la8py7g9NdTiFK5StlMlZ0UDCptQWULSsO2Jo+VtuxK2cwAlwjcdXqoq5T2N8NLVSbIWNh7IcuPLye1LJVQ5+aVHr+e+5X4onhevepVs0tAe5JGBU0jGTyQbBqeHfks/z3wXz488SGPDHmk+Q46LcSuhvAp4HChekPp54dVRASVu/fgdscd7Mnag6eNJ1FuUSaNa2m/paxLXtcpdUpjRLpKlRGJJYmM9BmJGDiSz07Z4Cv3YuaQm+D4N5KPpVMABI0G30HgMxC8+3PPwHuIyYvhxUMvUqOt4Y5+d3S47PZiXKxdcLZyJq2ipdDK+crzfBr3KZMCJzV+n/x7xL9xsnLis/jPqNRU8sa4N5qVCh/KOcSrMa8yzn8cjw1prlsQ6RbJ9JDpfHf6O26IuKHVIPq7099Rq63lzuiOB0tX+V6FQqZgT9Ye0ivSpfLMLhRA87FvMDuvziG/Jp/jBcd5duSz2Kvsu+wcVyKWAM/CZYu7vRVzBvgyZ4BU851ZXMP+5CIOpBSx71wRv53Ibtw30NWWKB9Honwd6evrSG8vB3ydbTpd2nlz5M2sSVrDW0feYu3stShkCqm0g44bnLdGmEsYYS7GS6xaQylXMjN0Jj8m/ciohp4lc8c1wHMAAgInCk4w3Hs4OlGHVq9Fq9eiE3XU6+sRRRF3G/dWV9zqdfVsS9/GhMAJXdKL0JVYK6y5rvd1XBt+LTF5MXx/+ntWxK/gy1NfMj14Oo8Pe7x98YCLMJSjOls5tynOsDtzNyqZijG+5mUXFkctpkhdxJenvsTF2oUHBj3Q7PmsSkny/lKUaBq4e8DdbEzdyAcnPuCt8W91+Dh6Uc/rf73O6jOrWdB7gVk+b/9EBJUK+7FjsR87Fu/nn6MuNRVtXh71ObnU5+ZSn5uDNjcPdWwsFdu2NSszvbfh/txrg5DZ2SF3dUXu5ITc0RG5sxPZQjl2pYd4OWQ0QXuTqXAs4GHVJLKL9rJ83VO8O+tTVI7OyKxaZsD3Ze/jQM5Bnhz2JK5eF/oqH/Dpx++/zuItbQ6fTP6k2WtOHH4Fm5T1hN93EGQKEEWoV0NdhRRwGW6aKskeoq6i4XGl1HeoqWJhXQUr1PF8LZbzZkVt43Y0NVBfDaLe6Pt4XiHnTIAfjxeXwvEm6rZyK1BaS8GeouG+2c820q3h8TwBPkLG2j/+zVM+Exq3l4palp96n6FOYcxSeEBunPScwkq6l6su/GxGUNkd1J6SBCqswlpX+Z0bNpe4wjhWnlpJtEd084XI5J1Sue+glj16DhMnUvTJJ5x/9r8U2P7B1ePmmRwQBToG8uOsH/G376YAr1gK8GLyYogviufZkc+i7HM9jHsczmyG+J8gbS/Er5FeKMhQuvfmDa8IFuo06EU9c90Hg7auzb5UcwhxCmmhpCmKIq/EvIJMkPH08KcbtwuCwP2D7sfJyok3j7zJvbvu5f0J72OntCO1PJXH/niMEKcQ3hj7htFKkAcGPcCOjB18Gvcpz416rsXz5XXlrD6zmqnBU1u0qZiDvcqeEd4j2J25mwCHAPzt/Rv/Bl2BIYOXWZHJb+d+I8w5rEsVZq9ULAGehSuGQDdbbnIL5KYRgYiiSGFlHQm5FZzOabjlVrAtIa9xf5Vchr+LDYFutgS52hLoZkewmy1Bbrb4Ottgq2r/46+Sq3h0yKM89udjjWIB8YXxyAV5m/1RPcn88Pl8n/g9H534CKVMaXZdu6PKkXCXcD6O/ZiPYz9udT9/e3/mhM1hTq85Lera92bvpbyunNmhPet9Zw6CIDDSZyQjfUaSWZHJD2d+4OezPxNfFM8nkz8hwMG0LJROr+ONI2+w+sxqAK72v5qnhj/VYpVZFEX2ZO1hhM+IDpW+PjT4IcrqylgRvwJnK+dmAgcGi4Se9MC7GA9bD26JuoUV8Su4re9t9HU3vz9Iq9fy3IHn2Ji6kdv73s4jQx65ZOJKVyKCQoF1797Q23hmTdTr0ZWXoyspQVdSQl1JEct3vYSfzoE5blejKylFV1GOrrwcdXYWFJ5nXq2I7OABcrngfSYV4ZaS9sbV0nmVSmQODsjs7ZHZ2SHY2lBUdYb/WFkz9twZ8u3fQGZnh8zWFpmdLf8uG8Ovp7ZwqPpTBgSOkLbb2pKScpQhDlHIxYa/uSBIWTaVbbNMUFs4AAuOvM33id/z0OLfml+bRFGafGuqpWDPEPRpatidsQ0yNjBxzL9BppICy3q1tK+2FuprLmwz3GqKLjzW1kJ9LW5aNZNdHVivO8mDcduwafBKW+7uSrW9Hf9J2IcQ29IHrBkyRZOgz0q6b/FYJQWfcmXDrWG7THHhsVwh/SxTXvRYKQWRgrzhXoZOraEyJonyffHUnE5HZm+Dle4MJGQ0UVUVGh4LIJPztNsITtvH8N+9zxA24gWCHAKl8x5dCXYe0NtI79qSW6jPPk/Zxo38p1aDbtt2CuY54jRnttGev4vpqj6tpjhbO+Nr59topv5Z3Gd42nhesA2QK6HvPOkGUJkHObGQcwJyY/FPP8QH2jJOq1QErWwQFLPzAEeDbYmfZFVi7yX1ptq6NvaoYu3cwpqhKSFOIY1Kowa2Z2xnf/Z+nhz2pNH+9luibsHJyonnDjzHnb/fyWtjX+P+XfejlCv5aNJHrWayAhwCWNh7IT8l/cQtUbe0UIpclbiK6vpqlvVf1ub7aQoTAyfy8uGXyarM6jL1TAMOKgfslfZ8e/pbyuvK+WzyZ5dUWO1yQTBm3Hg5M3ToUPHo0aOXehgWLlOq6rQk5VVwNr+KjOIaMoqrySiuIbOkhqo6bbN9HawUeDlZ4+VohZeDNZ6ODY8drXGzU+Fqp8LFToWTtYI7dywlvSKdTfM38cgfj1BRV8FPs003ue1ubth0AwnFCUR7RLNqxqr2X3ARR/KOcCD7AAqZ4sJNuPBYq9fyR9YfxOTFAJIh/NywuUwOnIyt0pZH/3iU4/nH2blw5xV1YY0tiOW+XfehlCn53+T/tVs6VKer45l9z7AjYwdLopbgaevJx7Efoxf13BV9F7f1va2xROZs6Vmu23Adz496vlXD+vbQ6XU8/ufj7MzcyatXvdooB7/y1EreO/YeB2882G6DfHdSpalixq8z6O3Sm8+nfm7Wl7ZGp+GJP59gd9ZuHhj0AMv6L7MEdz3ANwnf8PbRt/lx5o+NQble1HP3jruJLYzlp1k/ESB3R19ejq6iAl1lJbrKSr7561Oy889yR8iNONUr0FVWoa+qQl9dTU5hCkXFWQTJPVFp9OiraxBraswal6BSIbOxQbCxabi3RmZtg8zaCsHaBpm1NYK1dZN7KwQrawQrFVWChndOfsTQwFHM77cIQWWFzEqFYGUl3VQqZA33hp9v37WMKm01v8zpvFn6kZzDLN2xjJeHPsU8/6uJLYjjloNPc3vgdB4NmQtatRRo1jfc6+qke20taDUN9w0/6zQXblqNtG+zx1rpZ3096Oob9m2412ulx62UuYp6qMqzoiLdlspsa0SdgMpBi1NwDU7BapR27ZfH5ijkXO/rjYdOx6qcfGwNc8jRD8DU/2v1df+3+z8U7djKw4WDUR88BHo91lFROM6Zjf2YMchdXJA7ORlXie0GHt7zMCllKbww+gVu23YbTw17isVRZngUVuRC4RlJsbY8u8G+JPvCz5rK1l9r5QQ2zk36TR0ab1/X5/FOxSn2hy3FydqVSrmcuaf/h7uVMz8MfQ6FtUNDVrkhs6ywkQJSQWBP5h4e//NxdKIOmSBj5TUr27UIKFYXM+PXGYzxG8O7V7/buL1KU8XUX6Yy1GsoH0z8wPT3pRUKagqYtFbK+ja99nQV1264lnOl57jK76oWlQJ/ZwRBOCaKotFmfEuAZ+EfgSiKlFRrSC+uIbOkmtzyWgoq6sivqCWvQnpcUFlLvc74/4OjUx6i73Jc6qdQrtyHr3wMIxyX4WijxNFa0XCvxNFGgYOVEjsrOfbWCuytFNgo5d0+cV1zZg3/F/N/LI5czFPDn+q28+RU5bAhZQPrk9dzvuo8tgpbJgdNZmvaVhb1WdSt5+4uUstSuXvn3ZTXlbN8wvLGUteLqdBU8ODuBzmWf4wnhj7Bkr5LAMlv580jb7IjYwfBjsH8e8S/GeU7is/iPuPj2I/Zff3uTilNanQa7t11L0fzjrJ8wnKuDriaFw6+wJ6sPfy56M8OH7erWJW4itf/ep1PJ39qstBFTX0ND+15iMO5h3l6+NMtzIMtdB9Vmiqm/DyFsX5jeXP8mwB8f/p73jjyBs+Neo6FvY0LbRTUFDBv3Tx6u/Zm5TUrG8vsitRFzP5tNoO9BjcToxL1ekS1Gn1NDfqaGo6k7ee9/a9xS8hCJriPIjnnJKtOrOTGkGsJUnoj1qrR16jR19aiV9cgqmvR19U23NdJxzLc19Yi1tZ2+r3Qy2UorKylwK9J8CcolU3uldK9UtXkccNNYXis4MeUn1GorFkQdQPfJf1AtVjLvwbfh5W1reSvqFA07K+QhHDkCgSFXHpOLt1L2+UgCNJjmezCvUzWTIFUepPFZo/1dXVS0F1ega6yHH1FObqKcvRVlWgLCqj8cz+6kjLkTo44Th6H0zUTsI4MR0AvRX+ir40DxwAAFeVJREFUCIhNji1euNfrGgPJg0Xx3H36M2a6DeDVwDkIiNB7mhSwGHufRT0Tf5rIUO+hvD3+bbSFhVRs3Ur5ho2N5aEGZPb2yJ2dm91ktrbIbKwRrKxb3ltbXfj7Nf3bqVQNf7OL/o4qFYJCwYqTn/NR7EcM8hxERkUG267b1syIu9PUlkuqtOqyC2JE6pImj0ublCFfKEn+U6jjfg9nvsvJY2CdhlfcXPjJwZ4fcvLpq9EYP5cgaywhPmJjw/P2AvfX2zBDcGhSFmx1UXmwVeP9/yrP8En5SX4IuJb+DgEgt+KLoiO8n7uHH/veT1/HkOZZY0MW2ZAdbu3xRWWhN2++mZLaErZcu6XL50T377qf/dn7+WXOL/Rybj8z/HfBEuBZsGACer1IaY2G/Io6Sms0lFRfuJXWaDhY/hH5+oMgiNiULaa2dCCVdVra+xeSCWCnUmBnpcDOSo5dQ9Bnq5Jjq1Jgo5Ie26jk2CoV2KhkWCvljTcbpRxrpazhXo6VQoaVQo6VUoaVQtq3VlfFfbvu5bGhjzHYq/vV/kRR5HjBcTakbGBb2jZqtDX8NOuny6Zs1Vzyq/O5Z9c9pJWn8X9j/q+Fj19edR737LyH9Ip0Xr3qVaOKeQeyD/BqzKtkVmYyLXgayWXJ2CptO5RRvZjq+mru+P0OksuS+WzKZ3x04iN0oo5vp3/b6WN3Fo1Ow5x1c7BX2vPT7J/a7a+p0FRw7857OVl0kpdGv8TcsLk9NFILBt49+i7fnv6WzdduRl2vZtGmRYzyHcWHEz9sc+L127nfeO7gc/x3xH9ZFCGJTL1w8AXWJ6/nt7m/EewU3OprRVHknl33EF8Qz6ZrN7E2aS0fxX7EgRsPdEiARBRFxPp6xNpa9LW1pBYm8dC2e1jSaxHzAmYgajRSQFinQdRoEDV1jT+fzD7G3rRdLAyZj6vcHr3GsE+9dF9fL90Mjy/eptVe+Lm+HlGrhfp6s3+HnkRmb4/d6NE4zZ2D/dixCCpV+y9qg0/jPuXj2I/5z4j/cEPEDW3uG1sQyy1bb+GNsW8wI7S5Wm1daiq1iYnoysoabuXSffmFx40Bf21ts57SziDKZdTJ9GjloLKxw87WuVmQL2sa9FtZSRngxscqBNVFgaVK2fx1TQNOhaLZwgCGhYGGAP/CAoCCzKrzzFo3i5eGPkWYnQ83//kINwZM5pnQ65qXGmsNpcO1DY8vum8tQ3xxplhbRzV6ZgT40ktTz5d5BagFgWkBvvSt0/BJfmEn3mWhoYRYCvrOK5XUyxWE0BD8yZQNzyuaPDY812Sb4Wd5k58Fwz7Sz7HacnL1dUy3D2l1n+bbGu4FmZH9ZU3KmRu2KazAp2t1F7qCSxbgCYIwDXgfkANfiKL4+kXPWwHfAkOAYmCRKIrpbR3TEuBZuFTkV+cze91s1Fo1m+ZvIsgxCL1epEqjpbymnoraesrV9VTX6aiqq6eqTkd1nZbqOi2VtdJ9tUZLjUZHjUaHWqOjWqNF3eRnjc64IIApqOQyVIqGWyuPrRQylHIZSrmAUn7heaW8+XalXIZCLqBquDc8p5Bd+Fkhk+511FKmySfIsRcKmbSPXCaglAsN99LPCpnQcC9DLpd+lgkN9z3sc2iMCk0FD+1+iKP5R3l86OON3ljJpcncvfNuquqreH/C+20qjdbp6lh5aiVfxH+BRq/hocEPdZlUc2ltKUu2Lvn/9u48SM66zuP4+9s9mcl9kZCTcEZYXBSQRe4NBAU2YEDiEkBIsUshrpS4tewKFIhaKmKpuIuWJyxkQYQNBCKiHJHKwi6GcEU5whWuCQlJSDIhx8x0P893/3h+3f30zPRMJnN0pvN5VU318/zuZ+bJr/N9TtZvXw/AzGkz+dZxlS+J6k+/W/k7rnz8Sq4//npO3+/0iuXWb1/PpY9cysqmlXzvhO9x8t4n9+MopWDN1jWcds9pnP2Rs1m+bjlrt63lns/c0+WZZnfnC498geXrlnPf7PvY2LKRuQ/M5cKDL+SKv7miy35XblrJZxd9lrOnn817W99jzdY1LJy9sLc2i0sfvZQVH6zgoTkPdfoqlC8++kXeanqrV88kbGrexCl3zSRqbeGYCUfxg2NvgHwE+SQATP8QRW2WIzzKQz6PxzHEMR5FUFyOIY6SvDbjTY/fGhqSM2CF+yOHjyA7YjiZ4cMrvj5jZ8Uec9niy3hy9ZPceuqtnb426MZnbmT+i/NZMndJj58m6rlcEqiHwN63by8G3nEhSM+lgvVCQJ4O0nM5tm7bxN0v3MFQr0+eKpuPkvqFAwItLcStLUk7LS2l9ZbW4npfyWfA6rLkMk5kzoghY8jU1UFdFsuGgDCbSZbDWV/LZpP8TBarS4KTUl4mOWOcyZTKZjNYpvCZ4ZVNr/LUumeZOfV4NuY2s/SD5Zyx14lMHDIWzJOztMXPODnriwMxZg4eJXlEqbwI8xhIfowoKRfKJ3WS/dyIgAg8LMf5cKlxjHkE5LE4n7TlEXg+Sfc4tZwL/QDh1tFkvIXlkB7S0uWg3T+tcsP2hH99rXf/0L2gKgGemWWBV4FPAY3AMuBcd38pVeafgI+5+6VmNhc4y907ffa8AjyppvkvzufBNx/kzll39slll/kopjkf05xLAr6WfMT21pjmfGE9piUf0ZKLS8v5mJZcUqY1Hxd/WvJJwJgsJ5+5KCYXeXG5NWqfloti4n4+sW8GWUsCwPRPIQjMFoLBrJG1JCAsfmZol5YxinWyId0sKZtJlzVC+WTdrZXlzT/jvfxSpjfMYnL9Efzflu+TtXpOHHUVYwftW2zbCvXDp5lhYf3D/Gpe2rKYT4w+k2F1I4tlaFuHUp1Mpny9+Emp7abWddy04nI2ta7j9Kn/wClTzy+Owyj0UVoujQmgbZul/grL6TEUylC2XqqbCfu/GTjOl5fM48PcZm6ZuYCGunoMaGrdxBtNr/L6pld4bdMKnl//DNtyW/nOsT/gyAnhUthi/+XtF8ZBcRxtx2aF7+WwDdU/SDCQXP341fx25W8BuOmkm5ix14wdqrdqyyrOuv8sDp9wONtz24v3Ju/ovaA3PHUDv17xa+oz9czabxZfP+brO7kF7S1dvZSLH7640/tet7Ru4YS7TuC8g87boaC0O6554hp+/+bvWTh7YdVeYdKfmlqaOOeBc5KHJR39NaYOn8qk4ZPaXep4xsIzmDhsIr/89C+rNNKOXfLwJZw47UTOPejcbtctnkEunv1NB4bJMh2c6U3qhPVCUJ8PAX9YX/Dy3WzbvhmP8vztpOOZOnRSciAgl8ejCM/nIIrxOIJ8lBwMiJLPpI1wMCBK5cVx8QCCR/lS/Sgu5m9r2ULGwdzJxEbWoctLlGpN8Qsx+Y4PX57UjRnJAUueqPLg2qtWgHc08HV3PyWsXwXg7tenyjwUyjxpZnXAGmC8dzIoBXgifS+KnVwUk4+dXCHwi518CAbzcUw+SpWJYqLYycdOPnKiOC4u50O9yD0pE3mxbKFcXFh3J4q8WLbsx0vl4mI+xeX0ZxxTbCP2Ql7ypVxoy51UeSf2pE7sEblR9+MjHwfAW8cTr76YODcmOaDuhTar87fJ1K9l8OS7aV4zm7i5Z++f603ZYa8xdNrN5DYfAsRkB68iU7+pmB/nRhM1T6Z1/Qzi5r79z2/FILB42JaOA0lKgWLpaG+b9FITZWVL8WWpXKqJUv8V2iirkwpoO27LytbpJD8d95Z+G5Cva2TtiO8ytPUYxmw7r12blcYCsLn+MTYMTh4yNa75fEbmjivrqG0b6bTYtvHmkGuJbSsTW+YxKjqm4hgrLHbQdmGQzut13yK2ZiZF5fcSFopvs7dZm32AA/JfZTjlrwVo93vtoK+O85OUiO3kaGIIE9vkV67dddtt8yvX76psu8bb9tWub+s0H+DD+C2ey3+biNIZrUGMZIiNY7CNo56RNMaPcmDdhexVV/kdqZ38itpvR7txdtJWB/k9abvr/Pb/niv33bFl237E6vxTTKg7jE8OvaLDg1c9HncHae+2/i/Ltv0YgBOGX8v4QR8FdyyOMY+Tz8JyuGczWS8vk6FNXkgnLGfcIfZSXqqtTLjvM0n39v1DcpYvlElOLKb6o7ztpK1UnnvpM1XfQthR3mYpz4YO5Ywftn+VRLV1FuD15ePupgDvptYbgbbXNhXLuHvezJqAPYD16UJmdglwCcC0abV/VEyk2pIzaOGSnt55vc+A4v5pbn/5dp59/1muO/o6Rg8eXaFcEugVgj4Pyx6CxeT7qbxM+P4J+YUyqTZI7gctHDxNtwuFcmcldcMYwvdlsS+n1I+TGleqfBhKsQ6k2gnLhXwolC+vW9ieJP0QfvPOct7gacYMmsyEwYcwoWF/JjTsz56D92NwZmRqzOH3V6n9Nuvp33c6P4y6mFZoKF2/1HZ5HTrcPlLLpfSy/lNl0v0Xtqe8TqrtCuXLxpRqpNSWd9h2pXw66KfdduDAR5gSf5eGhnEwOFNx3GVth/724FPk/AViWplWPwMGle67bDsuyuoCjGRydDaN2TsYnTmQQal7NtuPsX16oY9iWmHfDeXH+qm81/AL3q6r/MqXungMtOzNFkr3c3W0rR113ja/PDuDM5rNNHeY39F2lLfV+VGj9vU7/x11q+0uEirXHsNIvkGUXUOc3UCU3UCc3cC27AdsybxJnN0ADGLN6gNYG2+s0Hcn29H5sNu31cXfqztte6e1O/+ddz3uygXyI8bDyAY2vD2LP0Tvd6Nmoe9u/q2L6XvDxL0gbuDxt0ZhrGpfptttG8ldWtnOO+88a4f6JtPms1ttd54/bkQ9u+5LoDrWl2fw5gCnuvvFYf0C4JPuflmqzAuhTGNYfyOUWd9Rm6AzeCIiu6pcnKM1at3lXnYvvS/2mNjjnX4tSlNLE6MaRvXyqJL/BK5sWklrVOGJg8CEYRMYO3hsr/ct7cUek4tznd4TKeXycZ6tua198u+jKy1RC4YVX/cju7ZqncFbBaSvH5oa0joq0xgu0RxF8rAVEREZYAZlBjEo0z/vsZLqylimyyemdqav/vNqZrvVY9J3dRnLKLjrprpMXVWCO0B/qxqy87Nz15YB081sXzOrB+YCi9qUWQTMC8tzgD92dv+diIiIiIiIVNZnZ/DCPXWXAQ+RXHx7i7u/aGbfBJ5290XAzcB/mdnrwAaSIFBERERERER2Ql9eoom7Pwg82Cbta6nlZuBzbeuJiIiIiIhI9/XlJZoiIiIiIiLSjxTgiYiIiIiI1AgFeCIiIiIiIjVCAZ6IiIiIiEiNUIAnIiIiIiJSIxTgiYiIiIiI1AgFeCIiIiIiIjXC3L3aY+gWM1sHvF2l7scB66vUt+wetI9Jf9B+Jv1B+5n0Ne1j0h921f1sb3cf31HGgAvwqsnMnnb3I6o9Dqld2sekP2g/k/6g/Uz6mvYx6Q8DcT/TJZoiIiIiIiI1QgGeiIiIiIhIjVCA1z2/qPYApOZpH5P+oP1M+oP2M+lr2sekPwy4/Uz34ImIiIiIiNQIncETERERERGpEQrwdoCZnWpmr5jZ62Z2ZbXHI7XBzPYys8fM7CUze9HMLg/pY83sETN7LXyOqfZYZWAzs6yZPWdmD4T1fc1saZjT7jKz+mqPUQY2MxttZgvMbIWZvWxmR2suk95mZv8cvi9fMLM7zWyw5jPpKTO7xczWmtkLqbQO5y9L/EfY3/5sZodXb+SVKcDrgpllgZ8ApwEHA+ea2cHVHZXUiDzwL+5+MHAU8KWwb10JLHb36cDisC7SE5cDL6fWbwBudPcDgI3AP1ZlVFJL/h34g7sfBHycZH/TXCa9xsymAF8GjnD3vwaywFw0n0nP3Qqc2iat0vx1GjA9/FwC/LSfxtgtCvC6diTwuruvdPdW4DfA7CqPSWqAu69292fD8ock/yGaQrJ/3RaK3QacWZUBSk0ws6nALOBXYd2Ak4AFoYj2MekRMxsFnADcDODure6+Cc1l0vvqgCFmVgcMBVaj+Ux6yN3/B9jQJrnS/DUbmO+JPwGjzWxSvwy0GxTgdW0K8G5qvTGkifQaM9sHOAxYCkxw99Uhaw0woVrjkprwI+DfgDis7wFscvd8WNecJj21L7AO+M9wKfCvzGwYmsukF7n7KuD7wDskgV0T8Ayaz6RvVJq/BkRcoABPpMrMbDhwD/AVd9+czvPkMbd61K3sFDM7HVjr7s9UeyxS0+qAw4GfuvthwFbaXI6puUx6KtwDNZvkgMJkYBjtL6sT6XUDcf5SgNe1VcBeqfWpIU2kx8xsEElwd4e73xuS3y+c7g+fa6s1PhnwjgU+Y2ZvkVxefhLJvVKjwyVOoDlNeq4RaHT3pWF9AUnAp7lMetPJwJvuvs7dc8C9JHOc5jPpC5XmrwERFyjA69oyYHp4SlM9yQ29i6o8JqkB4V6om4GX3f2HqaxFwLywPA+4v7/HJrXB3a9y96nuvg/J3PVHdz8feAyYE4ppH5Mecfc1wLtmdmBImgm8hOYy6V3vAEeZ2dDw/VnYzzSfSV+oNH8tAi4MT9M8CmhKXcq5y9CLzneAmf0dyX0sWeAWd/92dUcktcDMjgMeB/5C6f6oq0nuw7sbmAa8Dfy9u7e9+VekW8xsBnCFu59uZvuRnNEbCzwHfN7dW6o4PBngzOxQkgf51AMrgYtIDiJrLpNeY2bfAM4heQr1c8DFJPc/aT6TnWZmdwIzgHHA+8B1wH10MH+Fgws/Jrk8eBtwkbs/XYVhd0oBnoiIiIiISI3QJZoiIiIiIiI1QgGeiIiIiIhIjVCAJyIiIiIiUiMU4ImIiIiIiNQIBXgiIiIiIiI1QgGeiIhILzOzGWb2QLXHISIiux8FeCIiIiIiIjVCAZ6IiOy2zOzzZvaUmT1vZj83s6yZbTGzG83sRTNbbGbjQ9lDzexPZvZnM1toZmNC+gFm9qiZLTezZ81s/9D8cDNbYGYrzOyO8IJcERGRPqUAT0REdktm9lfAOcCx7n4oEAHnA8OAp939o8AS4LpQZT7wVXf/GPCXVPodwE/c/ePAMcDqkH4Y8BXgYGA/4Ng+3iQRERHqqj0AERGRKpkJfAJYFk6uDQHWAjFwVyhzO3CvmY0CRrv7kpB+G/DfZjYCmOLuCwHcvRkgtPeUuzeG9eeBfYAn+nyrRERkt6YAT0REdlcG3ObuV5Ulml3bppzvZPstqeUIfeeKiEg/0CWaIiKyu1oMzDGzPQHMbKyZ7U3y3TgnlDkPeMLdm4CNZnZ8SL8AWOLuHwKNZnZmaKPBzIb250aIiIik6WiiiIjsltz9JTO7BnjYzDJADvgSsBU4MuStJblPD2Ae8LMQwK0ELgrpFwA/N7NvhjY+14+bISIiUsbcd/bKExERkdpjZlvcfXi1xyEiIrIzdImmiIiIiIhIjdAZPBERERERkRqhM3giIiIiIiI1QgGeiIiIiIhIjVCAJyIiIiIiUiMU4ImIiIiIiNQIBXgiIiIiIiI1QgGeiIiIiIhIjfh/oPA6cakv9BkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_lists = [a_train_loss_list, b_train_loss_list, c_train_loss_list, d_train_loss_list, e_train_loss_list]\n",
    "plt.figure(figsize =(15, 5))\n",
    "for exp, train_loss in zip(experiments, loss_lists):\n",
    "    # print(epoch, len(train_loss))\n",
    "    sns.lineplot(range(1, epochs+1), train_loss, label = exp)\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Train loss graph\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03e30155a8bc2aebd4337705006146e77759413953328d6ea8a447f30ad5fd64"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
